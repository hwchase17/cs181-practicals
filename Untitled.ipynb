{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import util\n",
    "\n",
    "TRAIN_DIR = \"train\"\n",
    "\n",
    "call_set = set([])\n",
    "\n",
    "def add_to_set(tree):\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        call_set.add(call)\n",
    "\n",
    "def create_data_matrix(start_index, end_index, direc=\"train\"):\n",
    "    X = None\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    i = -1\n",
    "    for datafile in os.listdir(direc):\n",
    "        if datafile == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        if i < start_index:\n",
    "            continue \n",
    "        if i >= end_index:\n",
    "            break\n",
    "\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str, clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(util.malware_classes.index(clazz))\n",
    "\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        add_to_set(tree)\n",
    "        this_row = call_feats(tree)\n",
    "        if X is None:\n",
    "            X = this_row \n",
    "        else:\n",
    "            X = np.vstack((X, this_row))\n",
    "        print i\n",
    "    return X, np.array(classes), ids\n",
    "\n",
    "def call_feats(tree):\n",
    "    good_calls = ['sleep', 'dump_line']\n",
    "\n",
    "    call_counter = {}\n",
    "    for el in tree.iter():\n",
    "        #print el\n",
    "        call = el.tag\n",
    "        if call not in call_counter:\n",
    "            call_counter[call] = 0\n",
    "        else:\n",
    "            call_counter[call] += 1\n",
    "    print call_counter\n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_feat_array\n",
    "\n",
    "## Feature extraction\n",
    "def main():\n",
    "    X_train, t_train, train_ids = create_data_matrix(0, 5, TRAIN_DIR)\n",
    "    X_valid, t_valid, valid_ids = create_data_matrix(10, 15, TRAIN_DIR)\n",
    "\n",
    "    print 'Data matrix (training set):'\n",
    "    print X_train\n",
    "    print 'Classes (training set):'\n",
    "    print t_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    X_train, t_train, train_ids = create_data_matrix(0, 5, TRAIN_DIR)\n",
    "    X_valid, t_valid, valid_ids = create_data_matrix(10, 15, TRAIN_DIR)\n",
    "\n",
    "    print 'Data matrix (training set):'\n",
    "    print X_train\n",
    "    print 'Classes (training set):'\n",
    "    print t_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data matrix (training set):\n",
      "[[  2.00000000e+00   0.00000000e+00]\n",
      " [  2.53000000e+02   3.43300000e+03]\n",
      " [  0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00]\n",
      " [  3.00000000e+00   6.35000000e+02]]\n",
      "Classes (training set):\n",
      "[ 8  6 12  8 10]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a03e77341a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ts' is not defined"
     ]
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=list(set([1,2,2,3]))\n",
    "x.extend([4,5])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_feats(tree):\n",
    "    global features\n",
    "    good_calls = ['process','sleep', 'dump_line']\n",
    "\n",
    "    call_counter = {}\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        if call not in call_counter:\n",
    "            call_counter[call] = 0\n",
    "        else:\n",
    "            call_counter[call] += 1\n",
    "    features.extend(call_counter.keys())\n",
    "    features=list(set(features))\n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_feats(tree):\n",
    "    global features\n",
    "    good_calls = features\n",
    "\n",
    "    call_counter = {}\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        if call not in call_counter:\n",
    "            call_counter[call] = 0\n",
    "        else:\n",
    "            call_counter[call] += 1\n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data_matrix(start_index, end_index, direc=\"test\"):\n",
    "    X = None\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    i = -1\n",
    "    for datafile in os.listdir(direc):\n",
    "        if datafile == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        if i < start_index:\n",
    "            continue \n",
    "        if i >= end_index:\n",
    "            break\n",
    "\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str, clazz = datafile.split('.')[:2]\n",
    "\n",
    "        # add target class if this is training data\n",
    "        \n",
    "\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        add_to_set(tree)\n",
    "        print(i)\n",
    "        for sub_tree in tree.iter():\n",
    "            if sub_tree.keys() !=[]:\n",
    "                this_row = call_feats(sub_tree)\n",
    "                if X is None:\n",
    "                    X = this_row \n",
    "                else:\n",
    "                    X = np.vstack((X, this_row))\n",
    "                ids.append(id_str)\n",
    "                try:\n",
    "                    classes.append(util.malware_classes.index(clazz))\n",
    "\n",
    "                except ValueError:\n",
    "                    # we should only fail to find the label in our list of malware classes\n",
    "                    # if this is test data, which always has an \"X\" label\n",
    "                    assert clazz == \"X\"\n",
    "                    classes.append(-1)\n",
    "\n",
    "    return X, np.array(classes), ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_feats(el):\n",
    "    global features\n",
    "    global ts\n",
    "    ts=el\n",
    "    good_calls = features\n",
    "\n",
    "    call_counter = {}\n",
    "    call = el.tag\n",
    "    if call not in call_counter:\n",
    "        call_counter[call] = 0\n",
    "    else:\n",
    "        call_counter[call] += 1\n",
    "    huh = el.keys()\n",
    "    for call in huh:\n",
    "        if call not in call_counter:\n",
    "            call_counter[call] = 0\n",
    "        else:\n",
    "            call_counter[call] += 1\n",
    "    #features.extend(call_counter.keys())\n",
    "    #features=list(set(features))\n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename_hash',\n",
       " 'recv_socket',\n",
       " 'create_open_file',\n",
       " 'apifunction',\n",
       " 'sleep',\n",
       " 'executionstatus',\n",
       " 'open_scmanager',\n",
       " 'shareaccess',\n",
       " 'style',\n",
       " 'struct',\n",
       " 'wantedsize',\n",
       " 'targetpid',\n",
       " 'create_mutex',\n",
       " 'snapshotfile',\n",
       " 'enum_values',\n",
       " 'get_computer_name',\n",
       " 'read_value',\n",
       " 'open_service',\n",
       " 'displayname',\n",
       " 'clsid',\n",
       " 'copy_file',\n",
       " 'enum_modules',\n",
       " 'bind_socket',\n",
       " 'enum_keys',\n",
       " 'wantedaddress',\n",
       " 'delete_value',\n",
       " 'creationflags',\n",
       " 'set_value',\n",
       " 'write_value',\n",
       " 'processes',\n",
       " 'startreason',\n",
       " 'name',\n",
       " 'hwnd',\n",
       " 'message',\n",
       " 'create_socket',\n",
       " 'allocationtype',\n",
       " 'starttime',\n",
       " 'windowname',\n",
       " 'dump_line',\n",
       " 'dump',\n",
       " 'servicename',\n",
       " 'load_dll',\n",
       " 'create_window',\n",
       " 'com_create_instance',\n",
       " 'port',\n",
       " 'get_file_attributes',\n",
       " 'index',\n",
       " 'find_file',\n",
       " 'open_file',\n",
       " 'section',\n",
       " 'get_username',\n",
       " 'create_service',\n",
       " 'filename',\n",
       " 'query_value',\n",
       " 'check_for_debugger',\n",
       " 'create_file',\n",
       " 'move_file',\n",
       " 'httpverb',\n",
       " 'open_key',\n",
       " 'send_socket',\n",
       " 'vm_write',\n",
       " 'delete_file',\n",
       " 'commandline',\n",
       " 'get_system_time',\n",
       " 'key',\n",
       " 'terminationreason',\n",
       " 'srcfile_hash',\n",
       " 'dstfile',\n",
       " 'protect',\n",
       " 'socket',\n",
       " 'thread',\n",
       " 'vm_protect',\n",
       " 'all_section',\n",
       " 'socket_type',\n",
       " 'creationdistribution',\n",
       " 'get_windows_directory',\n",
       " 'threadid',\n",
       " 'hook_address',\n",
       " 'enum_processes',\n",
       " 'filetype',\n",
       " 'offset',\n",
       " 'open_url',\n",
       " 'owned',\n",
       " 'height',\n",
       " 'classname',\n",
       " 'download_file',\n",
       " 'com_get_class_object',\n",
       " 'kill_process',\n",
       " 'size',\n",
       " 'load_image',\n",
       " 'servicetype',\n",
       " 'hook_module',\n",
       " 'create_process',\n",
       " 'service',\n",
       " 'local_port',\n",
       " 'top',\n",
       " 'parameteraddress',\n",
       " 'width',\n",
       " 'progid',\n",
       " 'inprocserver32',\n",
       " 'tokenhandle',\n",
       " 'md5',\n",
       " 'get_system_directory',\n",
       " 'milliseconds',\n",
       " 'filesize',\n",
       " 'username',\n",
       " 'successful',\n",
       " 'find_window',\n",
       " 'vm_allocate',\n",
       " 'listen_socket',\n",
       " 'connect_socket',\n",
       " 'applicationtype',\n",
       " 'enum_share',\n",
       " 'count',\n",
       " 'interfaceid',\n",
       " 'set_file_time',\n",
       " 'start_service',\n",
       " 'terminationtime',\n",
       " 'value',\n",
       " 'winsock_result',\n",
       " 'show_window',\n",
       " 'open_process',\n",
       " 'impersonate_user',\n",
       " 'exstyle',\n",
       " 'behavior',\n",
       " 'server',\n",
       " 'address',\n",
       " 'httpversion',\n",
       " 'create_thread_remote',\n",
       " 'process',\n",
       " 'pid',\n",
       " 'file_hash',\n",
       " 'open_mutex',\n",
       " 'file',\n",
       " 'showwindow',\n",
       " 'localfile_hash',\n",
       " 'change_service_config',\n",
       " 'read_section',\n",
       " 'hookid',\n",
       " 'localfile',\n",
       " 'enum_window',\n",
       " 'srcfile',\n",
       " 'ascii',\n",
       " 'hostname',\n",
       " 'set_windows_hook',\n",
       " 'desiredaccess',\n",
       " 'tid',\n",
       " 'create_directory',\n",
       " 'trimmed_bytes',\n",
       " 'target',\n",
       " 'destroy_window',\n",
       " 'connect',\n",
       " 'get_host_by_name',\n",
       " 'set_file_attributes',\n",
       " 'buffer_len',\n",
       " 'revert_to_self',\n",
       " 'create_key',\n",
       " 'user',\n",
       " 'create_thread',\n",
       " 'data',\n",
       " 'sha1',\n",
       " 'url',\n",
       " 'end_address',\n",
       " 'dstfile_hash',\n",
       " 'remote_addr',\n",
       " 'parentindex',\n",
       " 'delete_key',\n",
       " 'flags',\n",
       " 'starttype',\n",
       " 'remote_port',\n",
       " 'remove_directory',\n",
       " 'left']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ElementTree' object has no attribute 'tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b00bc514be22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-648419d60b71>\u001b[0m in \u001b[0;36mcreate_data_matrix\u001b[0;34m(start_index, end_index, direc)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0madd_to_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mthis_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-45365c328af0>\u001b[0m in \u001b[0;36mcall_feats\u001b[0;34m(el)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcall_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcall\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcall_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcall_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ElementTree' object has no attribute 'tag'"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "X_train, t_train, train_ids = create_data_matrix(0, 1, TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_feats(tree):\n",
    "    global features\n",
    "    global ts\n",
    "    good_calls = ['process','sleep', 'dump_line']\n",
    "    ts = tree\n",
    "    call_counter = {}\n",
    "    n_el=0\n",
    "    n_items=0\n",
    "    for el in tree.iter():\n",
    "        ts = el\n",
    "        n_el+=1\n",
    "        call1 = el.tag\n",
    "        if call1 not in call_counter:\n",
    "            call_counter[call1] = 0\n",
    "        call_counter[call1] += 1\n",
    "        huh = el.items()\n",
    "        n = len(el.getchildren())\n",
    "        n_items+= n_items\n",
    "        for call,value in huh:\n",
    "            \"\"\"call2 = call1 + \" : \"+call\n",
    "            if call2 not in call_counter:\n",
    "                call_counter[call2] = 0\n",
    "            call3 = call1 + \" : \"+call + \" : \"+value\n",
    "            if call3 not in call_counter:\n",
    "                call_counter[call3] = 0\n",
    "            call_counter[call3] += 1\n",
    "            call4 = call + \" : \"+value\n",
    "            if call4 not in call_counter:\n",
    "                call_counter[call4] = 0\n",
    "            call_counter[call4] += 1\"\"\"\n",
    "            if value not in call_counter:\n",
    "                call_counter[value] = 0\n",
    "            call_counter[value] += 1\n",
    "            if call not in call_counter:\n",
    "                call_counter[call] = 0\n",
    "            call_counter[call] += 1\n",
    "            ncall = str(n)+call\n",
    "            if ncall not in call_counter:\n",
    "                call_counter[ncall] = 0\n",
    "            call_counter[ncall] += 1\n",
    "    call_counter[\"n_el\"]=n_el\n",
    "    call_counter[\"n_items\"]=n_items\n",
    "    features.extend(call_counter.keys())\n",
    "    features=list(set(features))\n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apifunction', 'NtTerminateProcess'), ('targetpid', '2224')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "X_train, t_train, train_ids = create_data_matrix(0, 3086, TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1955353"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call_feats(tree):\n",
    "    global features\n",
    "    #global ts\n",
    "    good_calls = features\n",
    "    #ts = tree\n",
    "    call_counter = {}\n",
    "    n_el=0\n",
    "    n_items=0\n",
    "    for el in tree.iter():\n",
    "        ts = el\n",
    "        n_el+=1\n",
    "        call1 = el.tag\n",
    "        if call1 not in call_counter:\n",
    "            call_counter[call1] = 0\n",
    "        call_counter[call1] += 1\n",
    "        huh = el.items()\n",
    "        n = len(el.getchildren())\n",
    "        n_items+= n_items\n",
    "        for call,value in huh:\n",
    "            \"\"\"call2 = call1 + \" : \"+call\n",
    "            if call2 not in call_counter:\n",
    "                call_counter[call2] = 0\n",
    "            call3 = call1 + \" : \"+call + \" : \"+value\n",
    "            if call3 not in call_counter:\n",
    "                call_counter[call3] = 0\n",
    "            call_counter[call3] += 1\n",
    "            call4 = call + \" : \"+value\n",
    "            if call4 not in call_counter:\n",
    "                call_counter[call4] = 0\n",
    "            call_counter[call4] += 1\"\"\"\n",
    "            if value not in call_counter:\n",
    "                call_counter[value] = 0\n",
    "            call_counter[value] += 1\n",
    "            if call not in call_counter:\n",
    "                call_counter[call] = 0\n",
    "            call_counter[call] += 1\n",
    "            ncall = str(n)+call\n",
    "            if ncall not in call_counter:\n",
    "                call_counter[ncall] = 0\n",
    "            call_counter[ncall] += 1\n",
    "    call_counter[\"n_el\"]=n_el\n",
    "    call_counter[\"n_items\"]=n_items\n",
    "    #features.extend(call_counter.keys())\n",
    "    #features=list(set(features))\n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, t_train, train_ids = create_data_matrix(0, 2300, TRAIN_DIR)\n",
    "X_valid, t_valid, valid_ids = create_data_matrix(2300, 3086, TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-55dad1b69555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3086\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-ceb238c3f4a8>\u001b[0m in \u001b[0;36mcreate_data_matrix\u001b[0;34m(start_index, end_index, direc)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, t_train, train_ids = create_data_matrix(0, 3086, TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test, t_test, test_ids = create_data_matrix(0, 3724, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9446.0"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.DataFrame(X_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 3 elements, new values have 1137 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-519-191dc625e9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhuh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhuh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhuh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhuh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/properties.pyx\u001b[0m in \u001b[0;36mpandas.lib.AxisProperty.__set__ (pandas/lib.c:42548)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m   2217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[0;32m-> 2219\u001b[0;31m                              'new values have %d elements' % (old_len, new_len))\n\u001b[0m\u001b[1;32m   2220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 3 elements, new values have 1137 elements"
     ]
    }
   ],
   "source": [
    "huh=pd.DataFrame(X_train)\n",
    "huh.columns=features\n",
    "huh['Id']=train_ids\n",
    "huh['t']=t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "huh1=pd.DataFrame(X_test)\n",
    "huh1.columns=features\n",
    "huh1['Id']=test_ids\n",
    "huh1.to_csv('test_data_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "huh.to_csv('train_data_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('train_data_1.csv')\n",
    "t_train = X_train.t\n",
    "train_ids = X_train.Id\n",
    "del X_train['t']\n",
    "del X_train['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=pd.read_csv('test_data_1.csv')\n",
    "test_ids = X_test.Id\n",
    "del X_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['set_file_attributesdesiredaccess',\n",
       " 'delete_filedesiredaccess',\n",
       " 'read_valuefile_hash',\n",
       " 'vm_protecttargetpid',\n",
       " 'recv_socket',\n",
       " 'create_open_file',\n",
       " 'processapplicationtype',\n",
       " 'threadtid',\n",
       " 'processmd5',\n",
       " 'sleep',\n",
       " 'enum_processesapifunction',\n",
       " 'open_scmanager',\n",
       " 'create_windowwindowname',\n",
       " 'create_open_filefiletype',\n",
       " 'create_directorysrcfile_hash',\n",
       " 'load_dllsuccessful',\n",
       " 'create_fileshareaccess',\n",
       " 'bind_socketsuccessful',\n",
       " 'open_fileshareaccess',\n",
       " 'connect_socketremote_addr',\n",
       " 'set_file_attributesflags',\n",
       " 'delete_valuekey',\n",
       " 'create_directoryfiletype',\n",
       " 'set_file_attributessrcfile_hash',\n",
       " 'vm_protectaddress',\n",
       " 'get_file_attributessrcfile',\n",
       " 'recv_socketsocket',\n",
       " 'copy_filefiletype',\n",
       " 'send_socketsocket',\n",
       " 'dump_lineascii',\n",
       " 'load_imageaddress',\n",
       " 'create_mutex',\n",
       " 'com_create_instanceprogid',\n",
       " 'connectsuccessful',\n",
       " 'create_windowstyle',\n",
       " 'find_filefiletype',\n",
       " 'set_value',\n",
       " 'get_computer_name',\n",
       " 'read_value',\n",
       " 'write_value',\n",
       " 'write_valuefile',\n",
       " 'load_imagefilename_hash',\n",
       " 'create_socketsuccessful',\n",
       " 'com_get_class_objectinprocserver32',\n",
       " 'query_valuekey',\n",
       " 'read_valuesection',\n",
       " 'write_valuefile_hash',\n",
       " 'open_urlserver',\n",
       " 'destroy_windowhwnd',\n",
       " 'com_get_class_objectclsid',\n",
       " 'set_windows_hookhookid',\n",
       " 'connectservice',\n",
       " 'processusername',\n",
       " 'dump_linedump',\n",
       " 'enum_keys',\n",
       " 'send_socketbuffer_len',\n",
       " 'delete_value',\n",
       " 'destroy_windowwindowname',\n",
       " 'set_file_timeflags',\n",
       " 'enum_values',\n",
       " 'open_service',\n",
       " 'processes',\n",
       " 'trimmed_bytes',\n",
       " 'create_windowhwnd',\n",
       " 'create_processcommandline',\n",
       " 'create_threadtargetpid',\n",
       " 'create_mutexname',\n",
       " 'show_windowsnapshotfile',\n",
       " 'com_create_instance',\n",
       " 'set_windows_hookhook_module',\n",
       " 'create_open_filesrcfile',\n",
       " 'vm_protectwantedsize',\n",
       " 'create_filefiletype',\n",
       " 'read_valuefile',\n",
       " 'recv_socketsuccessful',\n",
       " 'open_urlurl',\n",
       " 'load_imagesuccessful',\n",
       " 'load_imageend_address',\n",
       " 'processstarttime',\n",
       " 'connect_socketwinsock_result',\n",
       " 'set_windows_hookthreadid',\n",
       " 'connect_socketsuccessful',\n",
       " 'create_processsuccessful',\n",
       " 'trimmed_bytescount',\n",
       " 'load_dll',\n",
       " 'create_window',\n",
       " 'kill_processapifunction',\n",
       " 'open_filesrcfile',\n",
       " 'com_get_class_objectinterfaceid',\n",
       " 'get_host_by_namebuffer_len',\n",
       " 'get_file_attributes',\n",
       " 'processfilesize',\n",
       " 'vm_protectsize',\n",
       " 'processstartreason',\n",
       " 'open_processsuccessful',\n",
       " 'find_file',\n",
       " 'open_file',\n",
       " 'get_username',\n",
       " 'get_host_by_nameremote_addr',\n",
       " 'remove_directorysrcfile',\n",
       " 'query_value',\n",
       " 'open_keykey',\n",
       " 'connect_socketremote_port',\n",
       " 'find_filesrcfile_hash',\n",
       " 'query_valuedata',\n",
       " 'create_file',\n",
       " 'open_processtargetpid',\n",
       " 'copy_filecreationdistribution',\n",
       " 'find_windowwindowname',\n",
       " 'open_key',\n",
       " 'send_socket',\n",
       " 'open_fileflags',\n",
       " 'get_host_by_name',\n",
       " 'delete_file',\n",
       " 'dump_line',\n",
       " 'bind_socketsocket',\n",
       " 'delete_filesrcfile',\n",
       " 'set_valuedata',\n",
       " 'find_windowclassname',\n",
       " 'check_for_debuggerapifunction',\n",
       " 'get_system_time',\n",
       " 'enum_valueskey',\n",
       " 'load_imagefilename',\n",
       " 'processindex',\n",
       " 'open_urlflags',\n",
       " 'create_processfilename',\n",
       " 'create_windowtop',\n",
       " 'create_open_fileflags',\n",
       " 'thread',\n",
       " 'all_section',\n",
       " 'get_host_by_namewinsock_result',\n",
       " 'open_urlsuccessful',\n",
       " 'create_socketsocket_type',\n",
       " 'com_create_instanceclsid',\n",
       " 'show_windowhwnd',\n",
       " 'read_sectionfile',\n",
       " 'get_windows_directory',\n",
       " 'set_file_attributessrcfile',\n",
       " 'create_filedesiredaccess',\n",
       " 'open_scmanagerdesiredaccess',\n",
       " 'delete_filesrcfile_hash',\n",
       " 'delete_filefiletype',\n",
       " 'create_socketsocket',\n",
       " 'create_processapifunction',\n",
       " 'processfilename',\n",
       " 'enum_processes',\n",
       " 'create_mutexowned',\n",
       " 'set_file_timesrcfile_hash',\n",
       " 'remove_directory',\n",
       " 'write_valuesection',\n",
       " 'processpid',\n",
       " 'impersonate_useruser',\n",
       " 'com_get_class_object',\n",
       " 'load_dlladdress',\n",
       " 'kill_process',\n",
       " 'set_valuekey',\n",
       " 'delete_valuevalue',\n",
       " 'load_image',\n",
       " 'create_filesrcfile_hash',\n",
       " 'create_filecreationdistribution',\n",
       " 'create_process',\n",
       " 'load_dllfilename_hash',\n",
       " 'find_filesrcfile',\n",
       " 'processexecutionstatus',\n",
       " 'vm_protectwantedaddress',\n",
       " 'vm_protectprotect',\n",
       " 'open_filedesiredaccess',\n",
       " 'copy_filedstfile_hash',\n",
       " 'processfilename_hash',\n",
       " 'sleepmilliseconds',\n",
       " 'find_fileflags',\n",
       " 'create_windowwidth',\n",
       " 'get_system_directory',\n",
       " 'copy_fileflags',\n",
       " 'create_keykey',\n",
       " 'create_windowheight',\n",
       " 'set_file_timefiletype',\n",
       " 'connectserver',\n",
       " 'set_valuevalue',\n",
       " 'create_socket',\n",
       " 'com_create_instanceinprocserver32',\n",
       " 'find_window',\n",
       " 'set_windows_hookhook_address',\n",
       " 'create_open_filesrcfile_hash',\n",
       " 'connect_socket',\n",
       " 'copy_filedstfile',\n",
       " 'connectport',\n",
       " 'create_windowleft',\n",
       " 'get_file_attributesfiletype',\n",
       " 'get_file_attributesflags',\n",
       " 'destroy_windowclassname',\n",
       " 'delete_keykey',\n",
       " 'processterminationtime',\n",
       " 'open_urlhttpverb',\n",
       " 'set_file_time',\n",
       " 'open_serviceservicename',\n",
       " 'vm_protect',\n",
       " 'open_url',\n",
       " 'find_filedesiredaccess',\n",
       " 'create_threadthreadid',\n",
       " 'read_valuevalue',\n",
       " 'copy_filesrcfile',\n",
       " 'show_window',\n",
       " 'open_process',\n",
       " 'impersonate_user',\n",
       " 'write_valuedata',\n",
       " 'open_filefiletype',\n",
       " 'copy_filedesiredaccess',\n",
       " 'connect',\n",
       " 'com_create_instanceinterfaceid',\n",
       " 'remove_directoryfiletype',\n",
       " 'impersonate_usertokenhandle',\n",
       " 'create_filesrcfile',\n",
       " 'copy_filesrcfile_hash',\n",
       " 'create_open_filecreationdistribution',\n",
       " 'process',\n",
       " 'write_valuevalue',\n",
       " 'enum_keyskey',\n",
       " 'check_for_debugger',\n",
       " 'open_mutex',\n",
       " 'dump_lineoffset',\n",
       " 'load_dllend_address',\n",
       " 'processterminationreason',\n",
       " 'create_threadaddress',\n",
       " 'set_file_timedesiredaccess',\n",
       " 'read_section',\n",
       " 'create_fileflags',\n",
       " 'processsha1',\n",
       " 'create_open_filedesiredaccess',\n",
       " 'load_imagesize',\n",
       " 'enum_window',\n",
       " 'com_get_class_objectprogid',\n",
       " 'recv_socketbuffer_len',\n",
       " 'get_host_by_namesuccessful',\n",
       " 'set_windows_hook',\n",
       " 'create_directorysrcfile',\n",
       " 'get_system_timeapifunction',\n",
       " 'open_processdesiredaccess',\n",
       " 'query_valuevalue',\n",
       " 'set_file_attributesfiletype',\n",
       " 'open_filesrcfile_hash',\n",
       " 'connect_socketsocket',\n",
       " 'vm_protecttarget',\n",
       " 'open_processapifunction',\n",
       " 'destroy_window',\n",
       " 'copy_file',\n",
       " 'delete_fileflags',\n",
       " 'set_file_timesrcfile',\n",
       " 'open_mutexowned',\n",
       " 'create_processtargetpid',\n",
       " 'set_file_attributes',\n",
       " 'read_sectionsection',\n",
       " 'create_windowexstyle',\n",
       " 'get_host_by_namehostname',\n",
       " 'create_key',\n",
       " 'get_file_attributessrcfile_hash',\n",
       " 'open_mutexname',\n",
       " 'get_file_attributesdesiredaccess',\n",
       " 'remove_directorysrcfile_hash',\n",
       " 'create_thread',\n",
       " 'create_processfilename_hash',\n",
       " 'read_sectionfile_hash',\n",
       " 'create_threadparameteraddress',\n",
       " 'connectapifunction',\n",
       " 'open_filecreationdistribution',\n",
       " 'kill_processtargetpid',\n",
       " 'create_processshowwindow',\n",
       " 'create_open_fileshareaccess',\n",
       " 'get_host_by_namesocket',\n",
       " 'load_dllfilename',\n",
       " 'open_urlapifunction',\n",
       " 'open_servicedesiredaccess',\n",
       " 'delete_key',\n",
       " 'create_directory',\n",
       " 'get_usernametokenhandle',\n",
       " 'load_dllsize',\n",
       " 'vm_protectbehavior',\n",
       " 'bind_socket',\n",
       " 'processparentindex',\n",
       " 'create_windowclassname',\n",
       " 'open_scmanagerservicename']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000,criterion =\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"max_features\": [1],\n",
    "              #\"max_depth\": [None, 10]#,\n",
    "              #\"min_samples_split\": [1, 10],\n",
    "              #\"min_samples_leaf\": [1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 38.46 seconds for 1 candidate parameter settings.\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid=param_grid,cv=5)\n",
    "start = time()\n",
    "grid_search.fit(X_train, t_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.grid_scores_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89371354504212575"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_tr=RandomForestClassifier(n_estimators=1000,max_features=None).fit(X_train,t_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp =zip(model_tr.feature_importances_,range(0,len(model_tr.feature_importances_)))\n",
    "imp.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[706,\n",
       " 1082,\n",
       " 218,\n",
       " 89,\n",
       " 241,\n",
       " 457,\n",
       " 940,\n",
       " 1115,\n",
       " 131,\n",
       " 598,\n",
       " 473,\n",
       " 396,\n",
       " 385,\n",
       " 172,\n",
       " 446,\n",
       " 625,\n",
       " 146]"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['com_get_class_object', 'dstfile_hash',\n",
       "       'create_thread_remote : parameteraddress', 'query_value : data',\n",
       "       'get_windows_directory', 'destroy_window',\n",
       "       'listen_socket : local_port', 'create_thread',\n",
       "       'vm_protect : target', 'read_value', 'terminationtime',\n",
       "       'read_value : file', 'process : md5', 'milliseconds',\n",
       "       'create_mutex : owned', '0host', 'filetype'], \n",
       "      dtype='|S39')"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat =np.array(features)[included]\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[706]\n",
      "0.634802333117\n",
      "set([706, 1082])\n",
      "0.649708360337\n",
      "0.634802333117\n",
      "set([218, 706, 1082])\n",
      "0.740440699935\n",
      "0.649708360337\n",
      "set([218, 706, 476, 1082])\n",
      "0.739144523655\n",
      "0.740440699935\n",
      "set([218, 233, 706, 1082])\n",
      "0.740116655865\n",
      "0.740440699935\n",
      "set([218, 569, 706, 1082])\n",
      "0.739468567725\n",
      "0.740440699935\n",
      "set([218, 706, 1082, 439])\n",
      "0.739468567725\n",
      "0.740440699935\n",
      "set([218, 706, 332, 1082])\n",
      "0.738172391445\n",
      "0.740440699935\n",
      "set([218, 89, 706, 1082])\n",
      "0.744329228775\n",
      "0.740440699935\n",
      "set([218, 89, 706, 1082, 241])\n",
      "0.832793259883\n",
      "0.744329228775\n",
      "set([706, 457, 241, 89, 218, 1082])\n",
      "0.869086195723\n",
      "0.832793259883\n",
      "set([706, 457, 829, 241, 89, 218, 1082])\n",
      "0.866169799093\n",
      "0.869086195723\n",
      "set([706, 282, 457, 241, 89, 218, 1082])\n",
      "0.868438107583\n",
      "0.869086195723\n",
      "set([706, 457, 940, 241, 89, 218, 1082])\n",
      "0.870382372003\n",
      "0.869086195723\n",
      "set([706, 457, 940, 783, 241, 89, 218, 1082])\n",
      "0.869410239793\n",
      "0.870382372003\n",
      "set([706, 457, 940, 241, 210, 89, 218, 1082])\n",
      "0.868762151653\n",
      "0.870382372003\n",
      "set([706, 457, 940, 241, 89, 218, 1115, 1082])\n",
      "0.873946856773\n",
      "0.870382372003\n",
      "set([706, 457, 940, 241, 534, 89, 218, 1115, 1082])\n",
      "0.873946856773\n",
      "0.873946856773\n",
      "set([706, 795, 457, 940, 241, 89, 218, 1115, 1082])\n",
      "0.873946856773\n",
      "0.873946856773\n",
      "set([706, 457, 940, 241, 89, 218, 1115, 1082, 63])\n",
      "0.874594944913\n",
      "0.873946856773\n",
      "set([706, 457, 940, 241, 310, 89, 218, 1115, 1082])\n",
      "0.873946856773\n",
      "0.873946856773\n",
      "set([706, 457, 940, 241, 469, 89, 218, 1115, 1082])\n",
      "0.872002592353\n",
      "0.873946856773\n",
      "set([706, 131, 457, 940, 241, 89, 218, 1115, 1082])\n",
      "0.878159429682\n",
      "0.873946856773\n",
      "set([706, 131, 457, 940, 241, 339, 89, 218, 1115, 1082])\n",
      "0.879131561892\n",
      "0.878159429682\n",
      "set([706, 131, 457, 940, 477, 241, 89, 218, 1115, 1082])\n",
      "0.877835385612\n",
      "0.878159429682\n",
      "set([706, 131, 457, 940, 241, 598, 89, 218, 1115, 1082])\n",
      "0.882372002592\n",
      "0.878159429682\n",
      "set([706, 131, 457, 940, 241, 149, 598, 89, 218, 1115, 1082])\n",
      "0.880751782242\n",
      "0.882372002592\n",
      "set([706, 131, 457, 940, 1039, 241, 598, 89, 218, 1115, 1082])\n",
      "0.879779650032\n",
      "0.882372002592\n",
      "set([706, 131, 145, 457, 940, 241, 598, 89, 218, 1115, 1082])\n",
      "0.879455605962\n",
      "0.882372002592\n",
      "set([706, 131, 457, 940, 241, 598, 121, 89, 218, 1115, 1082])\n",
      "0.876539209332\n",
      "0.882372002592\n",
      "set([706, 131, 457, 940, 241, 598, 89, 218, 1115, 1082, 286])\n",
      "0.882372002592\n",
      "0.882372002592\n",
      "set([706, 131, 457, 940, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884640311082\n",
      "0.882372002592\n",
      "set([706, 131, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.886260531432\n",
      "0.884640311082\n",
      "set([706, 131, 457, 940, 396, 241, 597, 598, 473, 89, 218, 1115, 1082])\n",
      "0.887232663642\n",
      "0.886260531432\n",
      "set([385, 706, 131, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.888204795852\n",
      "0.886260531432\n",
      "set([385, 706, 131, 457, 394, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.885936487362\n",
      "0.888204795852\n",
      "set([385, 706, 131, 457, 940, 396, 241, 1050, 598, 473, 89, 218, 1115, 1082])\n",
      "0.883020090732\n",
      "0.888204795852\n",
      "set([385, 706, 131, 677, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884316267012\n",
      "0.888204795852\n",
      "set([385, 706, 131, 424, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.880751782242\n",
      "0.888204795852\n",
      "set([385, 706, 131, 457, 940, 396, 241, 818, 598, 473, 89, 218, 1115, 1082])\n",
      "0.883992222942\n",
      "0.888204795852\n",
      "set([288, 385, 706, 131, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884640311082\n",
      "0.888204795852\n",
      "set([385, 706, 131, 165, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884964355152\n",
      "0.888204795852\n",
      "set([385, 706, 131, 645, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884316267012\n",
      "0.888204795852\n",
      "set([385, 706, 131, 457, 940, 396, 241, 949, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884316267012\n",
      "0.888204795852\n",
      "set([416, 385, 706, 131, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.882047958522\n",
      "0.888204795852\n",
      "set([736, 385, 706, 131, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082])\n",
      "0.885612443292\n",
      "0.888204795852\n",
      "set([385, 706, 131, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1082, 895])\n",
      "0.884964355152\n",
      "0.888204795852\n",
      "set([385, 706, 131, 457, 940, 396, 241, 598, 473, 89, 218, 1115, 1084, 1082])\n",
      "0.883668178872\n",
      "0.888204795852\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.889825016202\n",
      "0.888204795852\n",
      "set([385, 706, 131, 457, 940, 1026, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.889176928062\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 396, 241, 178, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884640311082\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 598, 473, 1048, 89, 218, 1115, 1082])\n",
      "0.887880751782\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 13, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.886260531432\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 188, 1082])\n",
      "0.889500972132\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 598, 473, 1112, 89, 218, 1115, 1082])\n",
      "0.885936487362\n",
      "0.889825016202\n",
      "set([385, 706, 131, 134, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.888528839922\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 878, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.888528839922\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 681, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884964355152\n",
      "0.889825016202\n",
      "set([385, 706, 131, 753, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.885288399222\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 733, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.888852883992\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 396, 241, 626, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.883668178872\n",
      "0.889825016202\n",
      "set([385, 706, 131, 456, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.888204795852\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 884, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884640311082\n",
      "0.889825016202\n",
      "set([385, 706, 131, 582, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.889500972132\n",
      "0.889825016202\n",
      "set([385, 706, 131, 585, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.887232663642\n",
      "0.889825016202\n",
      "set([385, 706, 131, 49, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.889825016202\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 943, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.886908619572\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 675, 598, 473, 89, 218, 1115, 1082])\n",
      "0.884316267012\n",
      "0.889825016202\n",
      "set([385, 706, 131, 840, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082])\n",
      "0.886260531432\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892417368762\n",
      "0.889825016202\n",
      "set([385, 706, 131, 457, 940, 723, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893389500972\n",
      "0.892417368762\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446, 415])\n",
      "0.889825016202\n",
      "0.892417368762\n",
      "set([385, 706, 131, 457, 940, 396, 241, 172, 755, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891121192482\n",
      "0.892417368762\n",
      "set([385, 706, 131, 1093, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.889500972132\n",
      "0.892417368762\n",
      "set([385, 706, 131, 457, 940, 942, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893389500972\n",
      "0.892417368762\n",
      "set([385, 706, 131, 457, 1079, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.888528839922\n",
      "0.892417368762\n",
      "set([385, 706, 131, 457, 940, 143, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892093324692\n",
      "0.892417368762\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894361633182\n",
      "0.892417368762\n",
      "set([385, 706, 131, 625, 457, 193, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 232, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893065456902\n",
      "0.894361633182\n",
      "set([512, 385, 706, 131, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892417368762\n",
      "0.894361633182\n",
      "set([385, 706, 131, 228, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.890473104342\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 172, 661, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.890473104342\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446, 1055])\n",
      "0.891445236552\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 209, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.885936487362\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 172, 117, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893713545042\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 985, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891121192482\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 890, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.888852883992\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 653, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893713545042\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 781, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893065456902\n",
      "0.894361633182\n",
      "set([385, 706, 131, 5, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 60, 1082, 446])\n",
      "0.891445236552\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 172, 1086, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.890149060272\n",
      "0.894361633182\n",
      "set([385, 706, 131, 1078, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892093324692\n",
      "0.894361633182\n",
      "set([385, 706, 131, 581, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.890797148412\n",
      "0.894361633182\n",
      "set([385, 706, 131, 601, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 98, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 461, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891445236552\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 745, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.889500972132\n",
      "0.894361633182\n",
      "set([385, 706, 131, 521, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.890149060272\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 172, 169, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.890149060272\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 754, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892417368762\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 172, 596, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.889825016202\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 215, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893389500972\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 451, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.888204795852\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 359, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.885288399222\n",
      "0.894361633182\n",
      "set([385, 706, 131, 667, 625, 457, 940, 396, 241, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891445236552\n",
      "0.894361633182\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895981853532\n",
      "0.894361633182\n",
      "set([385, 706, 131, 179, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892417368762\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 994, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894361633182\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 335, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 28, 1082, 446])\n",
      "0.891445236552\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 47, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895009721322\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 819, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893065456902\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 264, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 1090, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 463, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 1102, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894361633182\n",
      "0.895981853532\n",
      "set([385, 706, 131, 325, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894361633182\n",
      "0.895981853532\n",
      "set([1027, 385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 222, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892741412832\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 1002, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 683, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891121192482\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 727, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895009721322\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 760, 89, 218, 1115, 1082, 446])\n",
      "0.892417368762\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 413, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893065456902\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 827, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892741412832\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 977, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895009721322\n",
      "0.895981853532\n",
      "set([385, 706, 131, 1025, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892741412832\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 1063, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 308, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893065456902\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 655, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895657809462\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 595, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.896953985742\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 904, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893713545042\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 557, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895009721322\n",
      "0.895981853532\n",
      "set([385, 706, 131, 634, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 751, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.890797148412\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 524, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895009721322\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 936, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([897, 385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893065456902\n",
      "0.895981853532\n",
      "set([385, 706, 131, 763, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894361633182\n",
      "0.895981853532\n",
      "set([385, 706, 131, 566, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895981853532\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 496, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893389500972\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 765, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([385, 706, 131, 326, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893389500972\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 1098, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894361633182\n",
      "0.895981853532\n",
      "set([704, 385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895657809462\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 79, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894361633182\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 88, 89, 218, 1115, 1082, 446])\n",
      "0.890797148412\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 1022, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895657809462\n",
      "0.895981853532\n",
      "set([385, 706, 131, 1041, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893713545042\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 979, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895333765392\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 221, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446, 511])\n",
      "0.891445236552\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446, 287])\n",
      "0.889176928062\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 365, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895657809462\n",
      "0.895981853532\n",
      "set([385, 706, 131, 934, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894685677252\n",
      "0.895981853532\n",
      "set([385, 706, 131, 1061, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895981853532\n",
      "0.895981853532\n",
      "set([385, 706, 131, 420, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([385, 706, 131, 1075, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892417368762\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 911, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894685677252\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 1007, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893389500972\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 250, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894685677252\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 46, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 152, 89, 218, 1115, 1082, 446])\n",
      "0.895981853532\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 817, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895333765392\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 814, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.893065456902\n",
      "0.895981853532\n",
      "set([385, 706, 131, 630, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891445236552\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446, 575])\n",
      "0.892741412832\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 946, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895009721322\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446, 377])\n",
      "0.893389500972\n",
      "0.895981853532\n",
      "set([385, 706, 131, 918, 625, 457, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894037589112\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 302, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894685677252\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 50, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894361633182\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 489, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.895009721322\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 238, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892741412832\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 426, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.891769280622\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 303, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.894685677252\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 186, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.890797148412\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 711, 940, 396, 241, 146, 172, 598, 473, 89, 218, 1115, 1082, 446])\n",
      "0.892741412832\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 598, 473, 248, 89, 218, 1115, 1082, 446])\n",
      "0.895657809462\n",
      "0.895981853532\n",
      "set([385, 706, 131, 625, 457, 940, 396, 241, 146, 172, 629, 598, 473, 89, 218, 1115, 1082, 446])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-db38f467bc6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincluded\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_train2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincluded\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;31m# Simple optimisation to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"always\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "included =[imp[0][1]]\n",
    "print included\n",
    "X_train2=np.array([x[included] for x in X_train])\n",
    "grid_search.fit(X_train2, t_train)\n",
    "rate = grid_search.grid_scores_[0][1]\n",
    "print rate\n",
    "dif = 10\n",
    "i = 1\n",
    "for i in range(1,len(imp)):\n",
    "    print set(included + [imp[i][1]])\n",
    "    X_train2=np.array([x[list(set(included+ [imp[i][1]]))] for x in X_train])\n",
    "    grid_search.fit(X_train2, t_train)\n",
    "    print grid_search.grid_scores_[0][1]\n",
    "    print rate\n",
    "    dif = grid_search.grid_scores_[0][1] - rate\n",
    "    if dif >.001:\n",
    "        included = included + [imp[i][1]]\n",
    "        rate = grid_search.grid_scores_[0][1]\n",
    "    i+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[706, 218, 89, 241, 457, 940, 534, 385, 326]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100,max_features=None).fit(X_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=model.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "important = [i for i,x in enumerate(model.feature_importances_) if x>.005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['creationflags', 'query_value : data', 'address',\n",
       "       'vm_protect : target', 'vm_allocate : wantedaddress',\n",
       "       'show_window : hwnd', 'read_value : file_hash',\n",
       "       'create_directory : filetype',\n",
       "       'create_thread_remote : parameteraddress',\n",
       "       'create_thread_remote : targetpid', 'get_windows_directory',\n",
       "       'destroy_window : hwnd', 'apifunction', 'vm_allocate : protect',\n",
       "       'create_thread_remote : address', 'windowname', 'process : md5',\n",
       "       'md5', 'create_thread_remote : threadid', 'destroy_window',\n",
       "       'target', 'create_thread_remote', 'show_window', 'targetpid',\n",
       "       'create_thread_remote : creationflags', 'vm_allocate : wantedsize',\n",
       "       'show_window : snapshotfile', 'vm_allocate : allocationtype',\n",
       "       'vm_allocate : size', 'create_directory',\n",
       "       'create_directory : srcfile_hash', 'desiredaccess',\n",
       "       'read_value : value', 'snapshotfile', 'create_directory : srcfile'], \n",
       "      dtype='|S39')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(important)\n",
    "np.array(features)[important]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.110633727175\n",
      "0.0369410239793\n",
      "1\n",
      "0.016380236305\n",
      "0.0162022034997\n",
      "2\n",
      "0.0179914070892\n",
      "0.0119896305898\n",
      "3\n",
      "0.0110096670247\n",
      "0.0103694102398\n",
      "4\n",
      "0.0201396348013\n",
      "0.0132858068697\n",
      "5\n",
      "0.0236305048335\n",
      "0.0126377187297\n",
      "6\n",
      "0.0193340494092\n",
      "0.0171743357097\n",
      "7\n",
      "0.0198711063373\n",
      "0.0132858068697\n",
      "8\n",
      "0.33888292159\n",
      "0.52138690862\n",
      "9\n",
      "0.0332975295381\n",
      "0.00680492546986\n",
      "10\n",
      "0.182599355532\n",
      "0.175631885936\n",
      "11\n",
      "0.0198711063373\n",
      "0.0103694102398\n",
      "12\n",
      "0.135875402793\n",
      "0.121840570318\n",
      "13\n",
      "0.0402792696026\n",
      "0.0191186001296\n"
     ]
    }
   ],
   "source": [
    "wei =[]\n",
    "for i in range(0,14):\n",
    "    print i\n",
    "    #print float(list(huh.Prediction).count(i))/len(huh.Prediction)\n",
    "    wei.append(float(list(t_train).count(i))/len(t_train))\n",
    "    print float(list(pred).count(i))/len(pred)\n",
    "    print float(list(t_train).count(i))/len(t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0370569280344\n",
      "0.0369410239793\n",
      "1\n",
      "0.0126208378088\n",
      "0.0162022034997\n",
      "2\n",
      "0.015037593985\n",
      "0.0119896305898\n",
      "3\n",
      "0.00993555316864\n",
      "0.0103694102398\n",
      "4\n",
      "0.0112781954887\n",
      "0.0132858068697\n",
      "5\n",
      "0.0204081632653\n",
      "0.0126377187297\n",
      "6\n",
      "0.015843179377\n",
      "0.0171743357097\n",
      "7\n",
      "0.015843179377\n",
      "0.0132858068697\n",
      "8\n",
      "0.479323308271\n",
      "0.52138690862\n",
      "9\n",
      "0.0295381310419\n",
      "0.00680492546986\n",
      "10\n",
      "0.182867883996\n",
      "0.175631885936\n",
      "11\n",
      "0.0171858216971\n",
      "0.0103694102398\n",
      "12\n",
      "0.12701396348\n",
      "0.121840570318\n",
      "13\n",
      "0.0171858216971\n",
      "0.0191186001296\n"
     ]
    }
   ],
   "source": [
    "wei =[]\n",
    "for i in range(0,14):\n",
    "    print i\n",
    "    #print float(list(huh.Prediction).count(i))/len(huh.Prediction)\n",
    "    wei.append(float(list(t_train).count(i))/len(t_train))\n",
    "    print float(list(pred).count(i))/len(pred)\n",
    "    print float(list(t_train).count(i))/len(t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040010741138560686"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(list(pred).count(0))/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03694102397926118"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(list(t_train).count(0))/len(t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train2=np.array([x[included] for x in X_train])\n",
    "X_test2=np.array([x[included] for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  3.,  2.]])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=model.predict_proba(X_train2)\n",
    "pred1 = model.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100,max_features=None).fit(X_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_list(m):\n",
    "    huh=[0]*15\n",
    "    huh[m]=1\n",
    "    return huh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_tr=[get_list(x) for x in t_train]\n",
    "rmse = [z for z in zip(pred,t_tr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse1 = [sum([(x-y)**2 for x,y in zip(z,w)]) for z,w in rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr1=[x for x,y in zip(X_train2,rmse1) if y>.5]\n",
    "t_tr1=[x for x,y in zip(t_train,rmse1) if y>.5]\n",
    "y_tr=[x for x,y in zip(pred1,rmse1) if y>.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-538-b7fb553af3ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for x in rmse1 if x >.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "none\n",
      "0.823834196891\n",
      "10\n",
      "0.823834196891\n",
      "1\n",
      "0.821243523316\n",
      "10\n",
      "none\n",
      "0.831606217617\n",
      "10\n",
      "0.821243523316\n",
      "1\n",
      "0.826424870466\n",
      "0.1\n",
      "none\n",
      "0.834196891192\n",
      "10\n",
      "0.829015544041\n",
      "1\n",
      "0.841968911917\n",
      "10\n",
      "none\n",
      "0.836787564767\n",
      "10\n",
      "0.834196891192\n",
      "1\n",
      "0.839378238342\n",
      "0.1\n",
      "none\n",
      "0.836787564767\n",
      "10\n",
      "0.829015544041\n",
      "1\n",
      "0.831606217617\n",
      "10\n",
      "none\n",
      "0.839378238342\n",
      "10\n",
      "0.826424870466\n",
      "1\n",
      "0.836787564767\n",
      "0.1\n",
      "none\n",
      "0.810880829016\n",
      "10\n",
      "0.813471502591\n",
      "1\n",
      "0.818652849741\n",
      "10\n",
      "none\n",
      "0.821243523316\n",
      "10\n",
      "0.816062176166\n",
      "1\n",
      "0.823834196891\n",
      "0.1\n",
      "none\n",
      "0.870466321244\n",
      "10\n",
      "0.870466321244\n",
      "1\n",
      "0.867875647668\n",
      "10\n",
      "none\n",
      "0.873056994819\n",
      "10\n",
      "0.870466321244\n",
      "1\n",
      "0.867875647668\n"
     ]
    }
   ],
   "source": [
    "for o in range(0,5):\n",
    "    random.shuffle(index)\n",
    "    X_train1=X_train2[index[:2700]]\n",
    "    X_valid1=X_train2[index[2700:]]\n",
    "    t_train1 = t_train[index[:2700]]\n",
    "    t_valid1 = t_train[index[2700:]]\n",
    "    for cutoff in [.1,10]: \n",
    "        X_tr=[x for x,y in zip(X_train1,rmse1) if y<cutoff]\n",
    "        t_tr=[x for x,y in zip(t_train1,rmse1) if y<cutoff]\n",
    "        model=RandomForestClassifier(n_estimators=100,max_features=10).fit(X_tr,t_tr)\n",
    "        pred= model.predict(X_valid1)\n",
    "        print cutoff\n",
    "        print \"none\"\n",
    "        print float(sum([1 if x==y else 0 for x,y in zip(pred,t_valid1)]))/len(pred)\n",
    "        model=RandomForestClassifier(n_estimators=100,max_features=None).fit(X_tr,t_tr)\n",
    "        pred= model.predict(X_valid1)\n",
    "        print 10\n",
    "        print float(sum([1 if x==y else 0 for x,y in zip(pred,t_valid1)]))/len(pred)\n",
    "        model=RandomForestClassifier(n_estimators=100,max_features=1).fit(X_tr,t_tr)\n",
    "        pred= model.predict(X_valid1)\n",
    "        print 1\n",
    "        print float(sum([1 if x==y else 0 for x,y in zip(pred,t_valid1)]))/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1=X_train[:2700]\n",
    "X_valid1=X_train[2700:]\n",
    "t_train1 = t_train[:2700]\n",
    "t_valid1 = t_train[2700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in rmse1 if x>.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr=[x for x,y in zip(X_train,rmse1) if y<.15]\n",
    "t_tr=[x for x,y in zip(t_train,rmse1) if y<.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  6, 12, ...,  8,  8,  3])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index=range(0,3086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.columns = [\"Prediction\"]\n",
    "pred['Id']=test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb=zip(model.feature_importances_,range(0,len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp=[x[1] for x in comb if x[0]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_tr=pd.DataFrame(X_train)[imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "      <th>463</th>\n",
       "      <th>464</th>\n",
       "      <th>465</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011099</td>\n",
       "      <td>-0.006793</td>\n",
       "      <td>0.025501</td>\n",
       "      <td>0.504247</td>\n",
       "      <td>-0.006247</td>\n",
       "      <td>-0.008173</td>\n",
       "      <td>-0.004285</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004048</td>\n",
       "      <td>0.158463</td>\n",
       "      <td>-0.002776</td>\n",
       "      <td>0.239531</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>0.216884</td>\n",
       "      <td>0.185546</td>\n",
       "      <td>0.498418</td>\n",
       "      <td>0.218040</td>\n",
       "      <td>0.158463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011099</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000906</td>\n",
       "      <td>0.060721</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>0.591587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069388</td>\n",
       "      <td>0.042498</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.072210</td>\n",
       "      <td>0.022574</td>\n",
       "      <td>0.066367</td>\n",
       "      <td>0.042498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006793</td>\n",
       "      <td>-0.000906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045373</td>\n",
       "      <td>0.027705</td>\n",
       "      <td>-0.002121</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>0.127889</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>-0.003778</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>0.022499</td>\n",
       "      <td>0.088913</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.127889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025501</td>\n",
       "      <td>0.060721</td>\n",
       "      <td>0.045373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.083495</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>0.078888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050396</td>\n",
       "      <td>0.228814</td>\n",
       "      <td>0.021616</td>\n",
       "      <td>0.064737</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>0.090714</td>\n",
       "      <td>0.192030</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>0.088356</td>\n",
       "      <td>0.228814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.504247</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.027705</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>-0.003792</td>\n",
       "      <td>0.055015</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>0.019177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.075405</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>0.140941</td>\n",
       "      <td>0.108542</td>\n",
       "      <td>0.073474</td>\n",
       "      <td>0.145069</td>\n",
       "      <td>0.075405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.006247</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>-0.002121</td>\n",
       "      <td>0.083495</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002777</td>\n",
       "      <td>0.026821</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>0.181312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001818</td>\n",
       "      <td>0.118395</td>\n",
       "      <td>0.268871</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>0.162147</td>\n",
       "      <td>0.142082</td>\n",
       "      <td>0.091191</td>\n",
       "      <td>0.149922</td>\n",
       "      <td>0.118395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.008173</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>-0.003792</td>\n",
       "      <td>-0.002777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>-0.002512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001892</td>\n",
       "      <td>-0.018315</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>-0.012082</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>-0.009955</td>\n",
       "      <td>-0.018531</td>\n",
       "      <td>-0.015097</td>\n",
       "      <td>-0.009665</td>\n",
       "      <td>-0.018315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.004285</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>0.055015</td>\n",
       "      <td>0.026821</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065073</td>\n",
       "      <td>0.057566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.116424</td>\n",
       "      <td>0.093129</td>\n",
       "      <td>0.164670</td>\n",
       "      <td>0.065073</td>\n",
       "      <td>0.089699</td>\n",
       "      <td>0.105151</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.076581</td>\n",
       "      <td>0.116424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.005677</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>0.065073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063393</td>\n",
       "      <td>0.065658</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.065658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.591587</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.078888</td>\n",
       "      <td>0.019177</td>\n",
       "      <td>0.181312</td>\n",
       "      <td>-0.002512</td>\n",
       "      <td>0.057566</td>\n",
       "      <td>0.134776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042569</td>\n",
       "      <td>0.130797</td>\n",
       "      <td>0.556218</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>0.134776</td>\n",
       "      <td>0.185622</td>\n",
       "      <td>0.180484</td>\n",
       "      <td>0.110117</td>\n",
       "      <td>0.174147</td>\n",
       "      <td>0.130797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.002747</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>-0.000969</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937471</td>\n",
       "      <td>0.185812</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.159581</td>\n",
       "      <td>0.119235</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.169834</td>\n",
       "      <td>0.185812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.002737</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.688385</td>\n",
       "      <td>-0.001635</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>-0.007476</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.004046</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>-0.010370</td>\n",
       "      <td>-0.010397</td>\n",
       "      <td>-0.005056</td>\n",
       "      <td>-0.009996</td>\n",
       "      <td>-0.007476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.009963</td>\n",
       "      <td>0.158806</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>0.076264</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>-0.005273</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>0.095835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.118994</td>\n",
       "      <td>0.017877</td>\n",
       "      <td>0.062286</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>0.097285</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>0.030634</td>\n",
       "      <td>0.118994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011099</td>\n",
       "      <td>-0.006793</td>\n",
       "      <td>0.025435</td>\n",
       "      <td>0.504247</td>\n",
       "      <td>-0.006247</td>\n",
       "      <td>-0.008173</td>\n",
       "      <td>-0.004284</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004048</td>\n",
       "      <td>0.158465</td>\n",
       "      <td>-0.002776</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.005677</td>\n",
       "      <td>0.216885</td>\n",
       "      <td>0.185547</td>\n",
       "      <td>0.498419</td>\n",
       "      <td>0.218041</td>\n",
       "      <td>0.158465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.043175</td>\n",
       "      <td>-0.001754</td>\n",
       "      <td>0.806805</td>\n",
       "      <td>0.038343</td>\n",
       "      <td>0.018776</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>-0.006282</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>0.040031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001433</td>\n",
       "      <td>0.227814</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>0.062298</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>0.109136</td>\n",
       "      <td>0.197215</td>\n",
       "      <td>0.102391</td>\n",
       "      <td>0.098704</td>\n",
       "      <td>0.227814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.056079</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.038963</td>\n",
       "      <td>0.041502</td>\n",
       "      <td>-0.005172</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.038371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037202</td>\n",
       "      <td>0.142741</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.204210</td>\n",
       "      <td>0.187969</td>\n",
       "      <td>0.112729</td>\n",
       "      <td>0.196575</td>\n",
       "      <td>0.142741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.011285</td>\n",
       "      <td>0.377848</td>\n",
       "      <td>0.123574</td>\n",
       "      <td>0.044868</td>\n",
       "      <td>0.060995</td>\n",
       "      <td>-0.013328</td>\n",
       "      <td>0.034282</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.091118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055758</td>\n",
       "      <td>0.562650</td>\n",
       "      <td>0.098307</td>\n",
       "      <td>0.210933</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.267783</td>\n",
       "      <td>0.493788</td>\n",
       "      <td>0.290677</td>\n",
       "      <td>0.245221</td>\n",
       "      <td>0.562650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.047113</td>\n",
       "      <td>0.117979</td>\n",
       "      <td>0.049647</td>\n",
       "      <td>0.061631</td>\n",
       "      <td>0.046732</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024942</td>\n",
       "      <td>0.123159</td>\n",
       "      <td>0.072381</td>\n",
       "      <td>0.031363</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.248024</td>\n",
       "      <td>0.191889</td>\n",
       "      <td>0.081896</td>\n",
       "      <td>0.249968</td>\n",
       "      <td>0.123159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.025501</td>\n",
       "      <td>0.060721</td>\n",
       "      <td>0.045373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.083495</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>0.078888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050396</td>\n",
       "      <td>0.228814</td>\n",
       "      <td>0.021616</td>\n",
       "      <td>0.064737</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>0.090714</td>\n",
       "      <td>0.192030</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>0.088356</td>\n",
       "      <td>0.228814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.009963</td>\n",
       "      <td>0.158806</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>0.076264</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>-0.005273</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>0.095835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.118994</td>\n",
       "      <td>0.017877</td>\n",
       "      <td>0.062286</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>0.097285</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>0.030634</td>\n",
       "      <td>0.118994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.015704</td>\n",
       "      <td>0.026848</td>\n",
       "      <td>0.049492</td>\n",
       "      <td>0.284656</td>\n",
       "      <td>0.059367</td>\n",
       "      <td>0.112527</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>0.050311</td>\n",
       "      <td>-0.003969</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>0.617623</td>\n",
       "      <td>0.059202</td>\n",
       "      <td>0.190759</td>\n",
       "      <td>-0.003969</td>\n",
       "      <td>0.125318</td>\n",
       "      <td>0.475937</td>\n",
       "      <td>0.087805</td>\n",
       "      <td>0.113395</td>\n",
       "      <td>0.617623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.025969</td>\n",
       "      <td>0.066389</td>\n",
       "      <td>0.049498</td>\n",
       "      <td>0.975172</td>\n",
       "      <td>0.063754</td>\n",
       "      <td>0.091370</td>\n",
       "      <td>-0.005893</td>\n",
       "      <td>0.012434</td>\n",
       "      <td>-0.004416</td>\n",
       "      <td>0.086318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055168</td>\n",
       "      <td>0.251044</td>\n",
       "      <td>0.023749</td>\n",
       "      <td>0.065209</td>\n",
       "      <td>-0.004416</td>\n",
       "      <td>0.100633</td>\n",
       "      <td>0.210836</td>\n",
       "      <td>0.059360</td>\n",
       "      <td>0.097930</td>\n",
       "      <td>0.251044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.376756</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.101943</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.201830</td>\n",
       "      <td>-0.002512</td>\n",
       "      <td>0.053190</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>0.552586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026545</td>\n",
       "      <td>0.252544</td>\n",
       "      <td>0.354079</td>\n",
       "      <td>0.028870</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>0.287401</td>\n",
       "      <td>0.382823</td>\n",
       "      <td>0.106745</td>\n",
       "      <td>0.284078</td>\n",
       "      <td>0.252544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.178461</td>\n",
       "      <td>0.266399</td>\n",
       "      <td>0.076531</td>\n",
       "      <td>0.045150</td>\n",
       "      <td>0.052946</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>-0.016135</td>\n",
       "      <td>0.148116</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>0.190311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049731</td>\n",
       "      <td>0.453539</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>0.747185</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>0.543338</td>\n",
       "      <td>0.509386</td>\n",
       "      <td>0.395603</td>\n",
       "      <td>0.534786</td>\n",
       "      <td>0.453539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.518265</td>\n",
       "      <td>-0.002884</td>\n",
       "      <td>0.026587</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>-0.003109</td>\n",
       "      <td>0.125649</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>0.324255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036730</td>\n",
       "      <td>0.184991</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>0.475573</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>0.119939</td>\n",
       "      <td>0.151213</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>0.111962</td>\n",
       "      <td>0.184991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.001711</td>\n",
       "      <td>0.185972</td>\n",
       "      <td>0.164506</td>\n",
       "      <td>0.039058</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.074991</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.045949</td>\n",
       "      <td>0.108018</td>\n",
       "      <td>-0.000579</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>0.043516</td>\n",
       "      <td>0.049050</td>\n",
       "      <td>0.027462</td>\n",
       "      <td>0.037995</td>\n",
       "      <td>0.045949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.065103</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.474623</td>\n",
       "      <td>0.134692</td>\n",
       "      <td>0.038672</td>\n",
       "      <td>0.062453</td>\n",
       "      <td>-0.009223</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.018185</td>\n",
       "      <td>0.088007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145583</td>\n",
       "      <td>0.488476</td>\n",
       "      <td>0.081644</td>\n",
       "      <td>0.122746</td>\n",
       "      <td>0.018185</td>\n",
       "      <td>0.189451</td>\n",
       "      <td>0.390523</td>\n",
       "      <td>0.194789</td>\n",
       "      <td>0.175805</td>\n",
       "      <td>0.488476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.504236</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>0.058106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>-0.003793</td>\n",
       "      <td>0.055019</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>0.019193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.075414</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>-0.004358</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>0.140953</td>\n",
       "      <td>0.108553</td>\n",
       "      <td>0.073483</td>\n",
       "      <td>0.145077</td>\n",
       "      <td>0.075414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.002550</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>0.043855</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940748</td>\n",
       "      <td>0.181387</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>0.155630</td>\n",
       "      <td>0.114154</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.165758</td>\n",
       "      <td>0.181387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>-0.001664</td>\n",
       "      <td>0.185985</td>\n",
       "      <td>0.163893</td>\n",
       "      <td>0.039092</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.075009</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>-0.002454</td>\n",
       "      <td>0.128085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.108031</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>-0.002454</td>\n",
       "      <td>0.043424</td>\n",
       "      <td>0.049097</td>\n",
       "      <td>0.027438</td>\n",
       "      <td>0.037937</td>\n",
       "      <td>0.046054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.128649</td>\n",
       "      <td>-0.003302</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>-0.009854</td>\n",
       "      <td>-0.010170</td>\n",
       "      <td>-0.006009</td>\n",
       "      <td>-0.009778</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.093318</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057497</td>\n",
       "      <td>0.237147</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>0.192103</td>\n",
       "      <td>0.093318</td>\n",
       "      <td>0.326201</td>\n",
       "      <td>0.344360</td>\n",
       "      <td>0.282274</td>\n",
       "      <td>0.305731</td>\n",
       "      <td>0.237147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.078658</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.438231</td>\n",
       "      <td>0.129467</td>\n",
       "      <td>0.033318</td>\n",
       "      <td>0.055422</td>\n",
       "      <td>-0.010907</td>\n",
       "      <td>0.015368</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.076058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111059</td>\n",
       "      <td>0.584134</td>\n",
       "      <td>0.074004</td>\n",
       "      <td>0.165637</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.193697</td>\n",
       "      <td>0.466802</td>\n",
       "      <td>0.228768</td>\n",
       "      <td>0.178593</td>\n",
       "      <td>0.584134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>-0.005677</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>0.065073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063393</td>\n",
       "      <td>0.065658</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.065658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.056079</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.038963</td>\n",
       "      <td>0.041502</td>\n",
       "      <td>-0.005172</td>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.038371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037202</td>\n",
       "      <td>0.142741</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.204210</td>\n",
       "      <td>0.187969</td>\n",
       "      <td>0.112729</td>\n",
       "      <td>0.196575</td>\n",
       "      <td>0.142741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.003952</td>\n",
       "      <td>0.083137</td>\n",
       "      <td>0.031831</td>\n",
       "      <td>0.055630</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.029324</td>\n",
       "      <td>-0.003474</td>\n",
       "      <td>0.018705</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>0.079347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.114351</td>\n",
       "      <td>0.072879</td>\n",
       "      <td>0.013655</td>\n",
       "      <td>-0.001849</td>\n",
       "      <td>0.084603</td>\n",
       "      <td>0.141601</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>0.081153</td>\n",
       "      <td>0.114351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>-0.002776</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>0.021616</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.268871</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>0.093129</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.556218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001157</td>\n",
       "      <td>0.176790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.278679</td>\n",
       "      <td>0.234940</td>\n",
       "      <td>0.216605</td>\n",
       "      <td>0.236539</td>\n",
       "      <td>0.176790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.021131</td>\n",
       "      <td>0.118221</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.364097</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.069471</td>\n",
       "      <td>-0.007115</td>\n",
       "      <td>0.020602</td>\n",
       "      <td>-0.005331</td>\n",
       "      <td>0.129637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051104</td>\n",
       "      <td>0.179989</td>\n",
       "      <td>0.199587</td>\n",
       "      <td>0.117294</td>\n",
       "      <td>-0.005331</td>\n",
       "      <td>0.198875</td>\n",
       "      <td>0.205078</td>\n",
       "      <td>0.115081</td>\n",
       "      <td>0.189866</td>\n",
       "      <td>0.179989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>-0.024208</td>\n",
       "      <td>0.113416</td>\n",
       "      <td>0.118303</td>\n",
       "      <td>0.100299</td>\n",
       "      <td>0.014575</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>-0.012516</td>\n",
       "      <td>0.022979</td>\n",
       "      <td>0.054331</td>\n",
       "      <td>0.079947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025642</td>\n",
       "      <td>0.338638</td>\n",
       "      <td>0.045325</td>\n",
       "      <td>0.079728</td>\n",
       "      <td>0.054331</td>\n",
       "      <td>0.168698</td>\n",
       "      <td>0.371760</td>\n",
       "      <td>-0.006214</td>\n",
       "      <td>0.158676</td>\n",
       "      <td>0.338638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.061956</td>\n",
       "      <td>0.292987</td>\n",
       "      <td>0.250352</td>\n",
       "      <td>0.155287</td>\n",
       "      <td>0.137668</td>\n",
       "      <td>-0.008873</td>\n",
       "      <td>0.133226</td>\n",
       "      <td>0.077333</td>\n",
       "      <td>0.154731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.752608</td>\n",
       "      <td>0.225905</td>\n",
       "      <td>0.385569</td>\n",
       "      <td>0.077333</td>\n",
       "      <td>0.335537</td>\n",
       "      <td>0.642996</td>\n",
       "      <td>0.407043</td>\n",
       "      <td>0.312408</td>\n",
       "      <td>0.752608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-0.016111</td>\n",
       "      <td>0.016950</td>\n",
       "      <td>0.096267</td>\n",
       "      <td>0.107525</td>\n",
       "      <td>0.026080</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>-0.016466</td>\n",
       "      <td>-0.004642</td>\n",
       "      <td>-0.013452</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>0.103165</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>-0.021777</td>\n",
       "      <td>-0.013452</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>0.072024</td>\n",
       "      <td>-0.022385</td>\n",
       "      <td>-0.024996</td>\n",
       "      <td>0.103165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>-0.006836</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.045438</td>\n",
       "      <td>0.027673</td>\n",
       "      <td>-0.002137</td>\n",
       "      <td>-0.002697</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>0.128438</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>-0.003832</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.089312</td>\n",
       "      <td>-0.002640</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.128438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.393057</td>\n",
       "      <td>0.032736</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>0.087909</td>\n",
       "      <td>0.395809</td>\n",
       "      <td>0.030215</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>0.186263</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>0.045062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020195</td>\n",
       "      <td>0.290773</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>0.430745</td>\n",
       "      <td>0.009909</td>\n",
       "      <td>0.205548</td>\n",
       "      <td>0.254256</td>\n",
       "      <td>0.146835</td>\n",
       "      <td>0.195895</td>\n",
       "      <td>0.290773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>-0.002737</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.688385</td>\n",
       "      <td>-0.001635</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>-0.007476</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.004046</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>-0.010370</td>\n",
       "      <td>-0.010397</td>\n",
       "      <td>-0.005056</td>\n",
       "      <td>-0.009996</td>\n",
       "      <td>-0.007476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.216884</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.022499</td>\n",
       "      <td>0.090714</td>\n",
       "      <td>0.140941</td>\n",
       "      <td>0.162147</td>\n",
       "      <td>-0.009955</td>\n",
       "      <td>0.089699</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>0.185622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194072</td>\n",
       "      <td>0.478947</td>\n",
       "      <td>0.278679</td>\n",
       "      <td>0.366517</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779442</td>\n",
       "      <td>0.504811</td>\n",
       "      <td>0.994210</td>\n",
       "      <td>0.478947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-0.001606</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>-0.004979</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>0.021131</td>\n",
       "      <td>0.021788</td>\n",
       "      <td>-0.008514</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>0.024806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035489</td>\n",
       "      <td>0.023397</td>\n",
       "      <td>0.039256</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>-0.001659</td>\n",
       "      <td>0.141682</td>\n",
       "      <td>0.081753</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.151810</td>\n",
       "      <td>0.023397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.047113</td>\n",
       "      <td>0.117979</td>\n",
       "      <td>0.049647</td>\n",
       "      <td>0.061631</td>\n",
       "      <td>0.046732</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024942</td>\n",
       "      <td>0.123159</td>\n",
       "      <td>0.072381</td>\n",
       "      <td>0.031363</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>0.248024</td>\n",
       "      <td>0.191889</td>\n",
       "      <td>0.081896</td>\n",
       "      <td>0.249968</td>\n",
       "      <td>0.123159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>-0.011580</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.033842</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.013414</td>\n",
       "      <td>-0.009638</td>\n",
       "      <td>0.126460</td>\n",
       "      <td>-0.007423</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005581</td>\n",
       "      <td>0.057230</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>-0.007423</td>\n",
       "      <td>-0.011862</td>\n",
       "      <td>0.039835</td>\n",
       "      <td>-0.003457</td>\n",
       "      <td>-0.009045</td>\n",
       "      <td>0.057230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.011191</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>-0.004618</td>\n",
       "      <td>0.034904</td>\n",
       "      <td>0.860984</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081969</td>\n",
       "      <td>0.146409</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.097721</td>\n",
       "      <td>0.860984</td>\n",
       "      <td>0.216882</td>\n",
       "      <td>0.248086</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.197153</td>\n",
       "      <td>0.146409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-0.004048</td>\n",
       "      <td>0.069388</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>0.050396</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>-0.001818</td>\n",
       "      <td>-0.001892</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.063393</td>\n",
       "      <td>0.042569</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209308</td>\n",
       "      <td>-0.001157</td>\n",
       "      <td>0.014312</td>\n",
       "      <td>0.063393</td>\n",
       "      <td>0.194072</td>\n",
       "      <td>0.165302</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.199403</td>\n",
       "      <td>0.209308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.158463</td>\n",
       "      <td>0.042498</td>\n",
       "      <td>0.127889</td>\n",
       "      <td>0.228814</td>\n",
       "      <td>0.075405</td>\n",
       "      <td>0.118395</td>\n",
       "      <td>-0.018315</td>\n",
       "      <td>0.116424</td>\n",
       "      <td>0.065658</td>\n",
       "      <td>0.130797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176790</td>\n",
       "      <td>0.507743</td>\n",
       "      <td>0.065658</td>\n",
       "      <td>0.478947</td>\n",
       "      <td>0.886627</td>\n",
       "      <td>0.403158</td>\n",
       "      <td>0.445614</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>-0.002776</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>0.021616</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.268871</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>0.093129</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.556218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001157</td>\n",
       "      <td>0.176790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.278679</td>\n",
       "      <td>0.234940</td>\n",
       "      <td>0.216605</td>\n",
       "      <td>0.236539</td>\n",
       "      <td>0.176790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>-0.003778</td>\n",
       "      <td>0.064737</td>\n",
       "      <td>-0.004357</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>-0.012082</td>\n",
       "      <td>0.164670</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014312</td>\n",
       "      <td>0.507743</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>0.366517</td>\n",
       "      <td>0.463705</td>\n",
       "      <td>0.508431</td>\n",
       "      <td>0.351105</td>\n",
       "      <td>0.507743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>-0.005677</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>-0.002081</td>\n",
       "      <td>-0.002166</td>\n",
       "      <td>0.065073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063393</td>\n",
       "      <td>0.065658</td>\n",
       "      <td>0.080435</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.065658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.216884</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.022499</td>\n",
       "      <td>0.090714</td>\n",
       "      <td>0.140941</td>\n",
       "      <td>0.162147</td>\n",
       "      <td>-0.009955</td>\n",
       "      <td>0.089699</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>0.185622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194072</td>\n",
       "      <td>0.478947</td>\n",
       "      <td>0.278679</td>\n",
       "      <td>0.366517</td>\n",
       "      <td>0.122336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779442</td>\n",
       "      <td>0.504811</td>\n",
       "      <td>0.994210</td>\n",
       "      <td>0.478947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.185546</td>\n",
       "      <td>0.072210</td>\n",
       "      <td>0.088913</td>\n",
       "      <td>0.192030</td>\n",
       "      <td>0.108542</td>\n",
       "      <td>0.142082</td>\n",
       "      <td>-0.018531</td>\n",
       "      <td>0.105151</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.180484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165302</td>\n",
       "      <td>0.886627</td>\n",
       "      <td>0.234940</td>\n",
       "      <td>0.463705</td>\n",
       "      <td>0.131407</td>\n",
       "      <td>0.779442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.462942</td>\n",
       "      <td>0.757410</td>\n",
       "      <td>0.886627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.498418</td>\n",
       "      <td>0.022574</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>0.073474</td>\n",
       "      <td>0.091191</td>\n",
       "      <td>-0.015097</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.110117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.403158</td>\n",
       "      <td>0.216605</td>\n",
       "      <td>0.508431</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.504811</td>\n",
       "      <td>0.462942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.493341</td>\n",
       "      <td>0.403158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.218040</td>\n",
       "      <td>0.066367</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.088356</td>\n",
       "      <td>0.145069</td>\n",
       "      <td>0.149922</td>\n",
       "      <td>-0.009665</td>\n",
       "      <td>0.076581</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.174147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199403</td>\n",
       "      <td>0.445614</td>\n",
       "      <td>0.236539</td>\n",
       "      <td>0.351105</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.994210</td>\n",
       "      <td>0.757410</td>\n",
       "      <td>0.493341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.158463</td>\n",
       "      <td>0.042498</td>\n",
       "      <td>0.127889</td>\n",
       "      <td>0.228814</td>\n",
       "      <td>0.075405</td>\n",
       "      <td>0.118395</td>\n",
       "      <td>-0.018315</td>\n",
       "      <td>0.116424</td>\n",
       "      <td>0.065658</td>\n",
       "      <td>0.130797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176790</td>\n",
       "      <td>0.507743</td>\n",
       "      <td>0.065658</td>\n",
       "      <td>0.478947</td>\n",
       "      <td>0.886627</td>\n",
       "      <td>0.403158</td>\n",
       "      <td>0.445614</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows  466 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.011099 -0.006793  0.025501  0.504247 -0.006247 -0.008173   \n",
       "1    0.011099  1.000000 -0.000906  0.060721  0.016969 -0.001311 -0.001365   \n",
       "2   -0.006793 -0.000906  1.000000  0.045373  0.027705 -0.002121 -0.002681   \n",
       "3    0.025501  0.060721  0.045373  1.000000  0.058091  0.083495 -0.005636   \n",
       "4    0.504247  0.016969  0.027705  0.058091  1.000000  0.018868 -0.003792   \n",
       "5   -0.006247 -0.001311 -0.002121  0.083495  0.018868  1.000000 -0.002777   \n",
       "6   -0.008173 -0.001365 -0.002681 -0.005636 -0.003792 -0.002777  1.000000   \n",
       "7   -0.004285 -0.001662  0.000751  0.011390  0.055015  0.026821 -0.004864   \n",
       "8   -0.005677 -0.001023 -0.002009 -0.004223 -0.002590 -0.002081 -0.002166   \n",
       "9    0.002119  0.591587  0.008302  0.078888  0.019177  0.181312 -0.002512   \n",
       "10  -0.002747 -0.000493 -0.000969  0.043548  0.001884 -0.001004 -0.001045   \n",
       "11  -0.002737 -0.000457 -0.000898 -0.001887 -0.001458 -0.000930  0.688385   \n",
       "12  -0.009963  0.158806 -0.001045  0.076264  0.004389  0.019159 -0.005273   \n",
       "13   1.000000  0.011099 -0.006793  0.025435  0.504247 -0.006247 -0.008173   \n",
       "14   0.043175 -0.001754  0.806805  0.038343  0.018776  0.000995 -0.006282   \n",
       "15   0.056079  0.010530  0.010253  0.029570  0.038963  0.041502 -0.005172   \n",
       "16   0.106020  0.011285  0.377848  0.123574  0.044868  0.060995 -0.013328   \n",
       "17   0.016600  0.047113  0.117979  0.049647  0.061631  0.046732 -0.003247   \n",
       "18   0.025501  0.060721  0.045373  1.000000  0.058091  0.083495 -0.005636   \n",
       "19  -0.009963  0.158806 -0.001045  0.076264  0.004389  0.019159 -0.005273   \n",
       "20        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "21   0.015704  0.026848  0.049492  0.284656  0.059367  0.112527 -0.007077   \n",
       "22   0.025969  0.066389  0.049498  0.975172  0.063754  0.091370 -0.005893   \n",
       "23   0.001379  0.376756  0.002349  0.101943  0.021764  0.201830 -0.002512   \n",
       "24   0.178461  0.266399  0.076531  0.045150  0.052946  0.012853 -0.016135   \n",
       "25   0.000530  0.518265 -0.002884  0.026587  0.006537 -0.002987 -0.003109   \n",
       "26  -0.001711  0.185972  0.164506  0.039058  0.012505  0.074991 -0.003291   \n",
       "27   0.065103  0.009174  0.474623  0.134692  0.038672  0.062453 -0.009223   \n",
       "28   0.504236  0.016968  0.027704  0.058106  1.000000  0.018882 -0.003793   \n",
       "29  -0.002550 -0.000457 -0.000898  0.043855  0.001910 -0.000930 -0.000968   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "436 -0.001664  0.185985  0.163893  0.039092  0.012417  0.075009 -0.003275   \n",
       "437  0.128649 -0.003302  0.002596 -0.009854 -0.010170 -0.006009 -0.009778   \n",
       "438  0.078658  0.001369  0.438231  0.129467  0.033318  0.055422 -0.010907   \n",
       "439 -0.005677 -0.001023 -0.002009 -0.004223 -0.002590 -0.002081 -0.002166   \n",
       "440  0.056079  0.010530  0.010253  0.029570  0.038963  0.041502 -0.005172   \n",
       "441 -0.003952  0.083137  0.031831  0.055630  0.019650  0.029324 -0.003474   \n",
       "442 -0.002776 -0.000835  0.004646  0.021616  0.008918  0.268871 -0.001768   \n",
       "443  0.021131  0.118221  0.003435  0.364097  0.016987  0.069471 -0.007115   \n",
       "444 -0.024208  0.113416  0.118303  0.100299  0.014575  0.009065 -0.012516   \n",
       "445  0.223400  0.061956  0.292987  0.250352  0.155287  0.137668 -0.008873   \n",
       "446 -0.016111  0.016950  0.096267  0.107525  0.026080  0.034278 -0.016466   \n",
       "447 -0.006836 -0.000914  0.999987  0.045438  0.027673 -0.002137 -0.002697   \n",
       "448  0.393057  0.032736  0.009837  0.087909  0.395809  0.030215 -0.003739   \n",
       "449 -0.002737 -0.000457 -0.000898 -0.001887 -0.001458 -0.000930  0.688385   \n",
       "450  0.216884  0.064600  0.022499  0.090714  0.140941  0.162147 -0.009955   \n",
       "451 -0.001606  0.008120 -0.004979 -0.000943  0.021131  0.021788 -0.008514   \n",
       "452  0.016600  0.047113  0.117979  0.049647  0.061631  0.046732 -0.003247   \n",
       "453 -0.011580  0.003725  0.026389  0.033842  0.010528  0.013414 -0.009638   \n",
       "454  0.011191 -0.000159  0.008589  0.003745 -0.000523  0.004026 -0.004618   \n",
       "455       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "456 -0.004048  0.069388 -0.001043  0.050396  0.001992 -0.001818 -0.001892   \n",
       "457  0.158463  0.042498  0.127889  0.228814  0.075405  0.118395 -0.018315   \n",
       "458 -0.002776 -0.000835  0.004646  0.021616  0.008918  0.268871 -0.001768   \n",
       "459  0.239531  0.011686 -0.003778  0.064737 -0.004357  0.007482 -0.012082   \n",
       "460 -0.005677 -0.001023 -0.002009 -0.004223 -0.002590 -0.002081 -0.002166   \n",
       "461  0.216884  0.064600  0.022499  0.090714  0.140941  0.162147 -0.009955   \n",
       "462  0.185546  0.072210  0.088913  0.192030  0.108542  0.142082 -0.018531   \n",
       "463  0.498418  0.022574 -0.002580  0.053159  0.073474  0.091191 -0.015097   \n",
       "464  0.218040  0.066367  0.016596  0.088356  0.145069  0.149922 -0.009665   \n",
       "465  0.158463  0.042498  0.127889  0.228814  0.075405  0.118395 -0.018315   \n",
       "\n",
       "          7         8         9      ...          456       457       458  \\\n",
       "0   -0.004285 -0.005677  0.002119    ...    -0.004048  0.158463 -0.002776   \n",
       "1   -0.001662 -0.001023  0.591587    ...     0.069388  0.042498 -0.000835   \n",
       "2    0.000751 -0.002009  0.008302    ...    -0.001043  0.127889  0.004646   \n",
       "3    0.011390 -0.004223  0.078888    ...     0.050396  0.228814  0.021616   \n",
       "4    0.055015 -0.002590  0.019177    ...     0.001992  0.075405  0.008918   \n",
       "5    0.026821 -0.002081  0.181312    ...    -0.001818  0.118395  0.268871   \n",
       "6   -0.004864 -0.002166 -0.002512    ...    -0.001892 -0.018315 -0.001768   \n",
       "7    1.000000  0.065073  0.057566    ...     0.004850  0.116424  0.093129   \n",
       "8    0.065073  1.000000  0.134776    ...     0.063393  0.065658  0.080435   \n",
       "9    0.057566  0.134776  1.000000    ...     0.042569  0.130797  0.556218   \n",
       "10   0.008183  0.036393  0.024453    ...     0.937471  0.185812  0.014534   \n",
       "11  -0.001635 -0.000725 -0.000841    ...    -0.000634 -0.007476 -0.000592   \n",
       "12   0.000298 -0.003951  0.095835    ...     0.007985  0.118994  0.017877   \n",
       "13  -0.004284 -0.005677  0.002119    ...    -0.004048  0.158465 -0.002776   \n",
       "14   0.005142  0.010983  0.040031    ...    -0.001433  0.227814  0.031378   \n",
       "15   0.863597  0.031465  0.038371    ...     0.037202  0.142741  0.069952   \n",
       "16   0.034282  0.015556  0.091118    ...     0.055758  0.562650  0.098307   \n",
       "17   0.010243  0.009623  0.089260    ...     0.024942  0.123159  0.072381   \n",
       "18   0.011390 -0.004223  0.078888    ...     0.050396  0.228814  0.021616   \n",
       "19   0.000298 -0.003951  0.095835    ...     0.007985  0.118994  0.017877   \n",
       "20        NaN       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "21   0.050311 -0.003969  0.034037    ...    -0.003603  0.617623  0.059202   \n",
       "22   0.012434 -0.004416  0.086318    ...     0.055168  0.251044  0.023749   \n",
       "23   0.053190  0.056205  0.552586    ...     0.026545  0.252544  0.354079   \n",
       "24   0.148116  0.049777  0.190311    ...     0.049731  0.453539  0.027523   \n",
       "25   0.125649 -0.002330  0.324255    ...     0.036730  0.184991 -0.001902   \n",
       "26   0.007441 -0.002466  0.128068    ...     0.007260  0.045949  0.108018   \n",
       "27   0.014493  0.018185  0.088007    ...     0.145583  0.488476  0.081644   \n",
       "28   0.055019 -0.002591  0.019193    ...     0.001991  0.075414  0.008968   \n",
       "29  -0.000739 -0.000725 -0.000841    ...     0.940748  0.181387 -0.000592   \n",
       "..        ...       ...       ...    ...          ...       ...       ...   \n",
       "436  0.007468 -0.002454  0.128085    ...     0.007271  0.046054  0.108031   \n",
       "437  0.020945  0.093318  0.001120    ...     0.057497  0.237147  0.007135   \n",
       "438  0.015368  0.012479  0.076058    ...     0.111059  0.584134  0.074004   \n",
       "439  0.065073  1.000000  0.134776    ...     0.063393  0.065658  0.080435   \n",
       "440  0.863597  0.031465  0.038371    ...     0.037202  0.142741  0.069952   \n",
       "441  0.018705 -0.001849  0.079347    ...     0.003583  0.114351  0.072879   \n",
       "442  0.093129  0.080435  0.556218    ...    -0.001157  0.176790  1.000000   \n",
       "443  0.020602 -0.005331  0.129637    ...     0.051104  0.179989  0.199587   \n",
       "444  0.022979  0.054331  0.079947    ...     0.025642  0.338638  0.045325   \n",
       "445  0.133226  0.077333  0.154731    ...     0.012622  0.752608  0.225905   \n",
       "446 -0.004642 -0.013452  0.003174    ...    -0.010110  0.103165  0.036313   \n",
       "447  0.000732 -0.002021  0.008533    ...    -0.001054  0.128438  0.004783   \n",
       "448  0.186263  0.009909  0.045062    ...     0.020195  0.290773  0.060363   \n",
       "449 -0.001635 -0.000725 -0.000841    ...    -0.000634 -0.007476 -0.000592   \n",
       "450  0.089699  0.122336  0.185622    ...     0.194072  0.478947  0.278679   \n",
       "451  0.012306 -0.001659  0.024806    ...     0.035489  0.023397  0.039256   \n",
       "452  0.010243  0.009623  0.089260    ...     0.024942  0.123159  0.072381   \n",
       "453  0.126460 -0.007423 -0.000235    ...    -0.005581  0.057230  0.006524   \n",
       "454  0.034904  0.860984  0.006443    ...     0.081969  0.146409  0.009043   \n",
       "455       NaN       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "456  0.004850  0.063393  0.042569    ...     1.000000  0.209308 -0.001157   \n",
       "457  0.116424  0.065658  0.130797    ...     0.209308  1.000000  0.176790   \n",
       "458  0.093129  0.080435  0.556218    ...    -0.001157  0.176790  1.000000   \n",
       "459  0.164670  0.042821  0.007029    ...     0.014312  0.507743  0.011496   \n",
       "460  0.065073  1.000000  0.134776    ...     0.063393  0.065658  0.080435   \n",
       "461  0.089699  0.122336  0.185622    ...     0.194072  0.478947  0.278679   \n",
       "462  0.105151  0.131407  0.180484    ...     0.165302  0.886627  0.234940   \n",
       "463  0.022058  0.001708  0.110117    ...     0.005915  0.403158  0.216605   \n",
       "464  0.076581  0.113634  0.174147    ...     0.199403  0.445614  0.236539   \n",
       "465  0.116424  0.065658  0.130797    ...     0.209308  1.000000  0.176790   \n",
       "\n",
       "          459       460       461       462       463       464       465  \n",
       "0    0.239531 -0.005677  0.216884  0.185546  0.498418  0.218040  0.158463  \n",
       "1    0.011686 -0.001023  0.064600  0.072210  0.022574  0.066367  0.042498  \n",
       "2   -0.003778 -0.002009  0.022499  0.088913 -0.002580  0.016596  0.127889  \n",
       "3    0.064737 -0.004223  0.090714  0.192030  0.053159  0.088356  0.228814  \n",
       "4   -0.004357 -0.002590  0.140941  0.108542  0.073474  0.145069  0.075405  \n",
       "5    0.007482 -0.002081  0.162147  0.142082  0.091191  0.149922  0.118395  \n",
       "6   -0.012082 -0.002166 -0.009955 -0.018531 -0.015097 -0.009665 -0.018315  \n",
       "7    0.164670  0.065073  0.089699  0.105151  0.022058  0.076581  0.116424  \n",
       "8    0.042821  1.000000  0.122336  0.131407  0.001708  0.113634  0.065658  \n",
       "9    0.007029  0.134776  0.185622  0.180484  0.110117  0.174147  0.130797  \n",
       "10  -0.000165  0.036393  0.159581  0.119235  0.011455  0.169834  0.185812  \n",
       "11  -0.004046 -0.000725 -0.010370 -0.010397 -0.005056 -0.009996 -0.007476  \n",
       "12   0.062286 -0.003951  0.032495  0.097285 -0.000203  0.030634  0.118994  \n",
       "13   0.239528 -0.005677  0.216885  0.185547  0.498419  0.218041  0.158465  \n",
       "14   0.062298  0.010983  0.109136  0.197215  0.102391  0.098704  0.227814  \n",
       "15   0.077824  0.031465  0.204210  0.187969  0.112729  0.196575  0.142741  \n",
       "16   0.210933  0.015556  0.267783  0.493788  0.290677  0.245221  0.562650  \n",
       "17   0.031363  0.009623  0.248024  0.191889  0.081896  0.249968  0.123159  \n",
       "18   0.064737 -0.004223  0.090714  0.192030  0.053159  0.088356  0.228814  \n",
       "19   0.062286 -0.003951  0.032495  0.097285 -0.000203  0.030634  0.118994  \n",
       "20        NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "21   0.190759 -0.003969  0.125318  0.475937  0.087805  0.113395  0.617623  \n",
       "22   0.065209 -0.004416  0.100633  0.210836  0.059360  0.097930  0.251044  \n",
       "23   0.028870  0.056205  0.287401  0.382823  0.106745  0.284078  0.252544  \n",
       "24   0.747185  0.049777  0.543338  0.509386  0.395603  0.534786  0.453539  \n",
       "25   0.475573 -0.002330  0.119939  0.151213  0.020752  0.111962  0.184991  \n",
       "26  -0.000579 -0.002466  0.043516  0.049050  0.027462  0.037995  0.045949  \n",
       "27   0.122746  0.018185  0.189451  0.390523  0.194789  0.175805  0.488476  \n",
       "28  -0.004358 -0.002591  0.140953  0.108553  0.073483  0.145077  0.075414  \n",
       "29  -0.000236 -0.000725  0.155630  0.114154  0.009491  0.165758  0.181387  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "436 -0.000509 -0.002454  0.043424  0.049097  0.027438  0.037937  0.046054  \n",
       "437  0.192103  0.093318  0.326201  0.344360  0.282274  0.305731  0.237147  \n",
       "438  0.165637  0.012479  0.193697  0.466802  0.228768  0.178593  0.584134  \n",
       "439  0.042821  1.000000  0.122336  0.131407  0.001708  0.113634  0.065658  \n",
       "440  0.077824  0.031465  0.204210  0.187969  0.112729  0.196575  0.142741  \n",
       "441  0.013655 -0.001849  0.084603  0.141601  0.012914  0.081153  0.114351  \n",
       "442  0.011496  0.080435  0.278679  0.234940  0.216605  0.236539  0.176790  \n",
       "443  0.117294 -0.005331  0.198875  0.205078  0.115081  0.189866  0.179989  \n",
       "444  0.079728  0.054331  0.168698  0.371760 -0.006214  0.158676  0.338638  \n",
       "445  0.385569  0.077333  0.335537  0.642996  0.407043  0.312408  0.752608  \n",
       "446 -0.021777 -0.013452 -0.023361  0.072024 -0.022385 -0.024996  0.103165  \n",
       "447 -0.003832 -0.002021  0.022707  0.089312 -0.002640  0.016781  0.128438  \n",
       "448  0.430745  0.009909  0.205548  0.254256  0.146835  0.195895  0.290773  \n",
       "449 -0.004046 -0.000725 -0.010370 -0.010397 -0.005056 -0.009996 -0.007476  \n",
       "450  0.366517  0.122336  1.000000  0.779442  0.504811  0.994210  0.478947  \n",
       "451 -0.000408 -0.001659  0.141682  0.081753  0.019798  0.151810  0.023397  \n",
       "452  0.031363  0.009623  0.248024  0.191889  0.081896  0.249968  0.123159  \n",
       "453  0.001974 -0.007423 -0.011862  0.039835 -0.003457 -0.009045  0.057230  \n",
       "454  0.097721  0.860984  0.216882  0.248086  0.025070  0.197153  0.146409  \n",
       "455       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "456  0.014312  0.063393  0.194072  0.165302  0.005915  0.199403  0.209308  \n",
       "457  0.507743  0.065658  0.478947  0.886627  0.403158  0.445614  1.000000  \n",
       "458  0.011496  0.080435  0.278679  0.234940  0.216605  0.236539  0.176790  \n",
       "459  1.000000  0.042821  0.366517  0.463705  0.508431  0.351105  0.507743  \n",
       "460  0.042821  1.000000  0.122336  0.131407  0.001708  0.113634  0.065658  \n",
       "461  0.366517  0.122336  1.000000  0.779442  0.504811  0.994210  0.478947  \n",
       "462  0.463705  0.131407  0.779442  1.000000  0.462942  0.757410  0.886627  \n",
       "463  0.508431  0.001708  0.504811  0.462942  1.000000  0.493341  0.403158  \n",
       "464  0.351105  0.113634  0.994210  0.757410  0.493341  1.000000  0.445614  \n",
       "465  0.507743  0.065658  0.478947  0.886627  0.403158  0.445614  1.000000  \n",
       "\n",
       "[466 rows x 466 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=RFC(n_estimators=100,max_features=1,min_samples_split=1,max_depth=100,min_samples_leaf=1).fit(X_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "huh = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(pd.DataFrame(X_train).corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonchase/anaconda/lib/python2.7/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    }
   ],
   "source": [
    "corr = pd.DataFrame(X_train).corr()\n",
    "sns.set(style=\"white\")\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n",
    "            square=True, xticklabels=5, yticklabels=5,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "plt.savefig(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8893129770992366"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum([1 if x==y else 0 for x,y in zip(huh,t_valid)]))/len(huh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "resultFile = open(\"output.csv\",'wb')\n",
    "wr = csv.writer(resultFile, dialect='excel')\n",
    "wr.writerow(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for val in ['Id']+test_ids:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['Prediction'] = huh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.to_csv('output1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = None\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00269ea50001a6c699d0222032d45b74b2e7e8be9.None.xml\n",
      "<ElementTree object at 0x1089ecf50>\n",
      "00278ec420236020d6121dffe0cc20034422e7228.Lipler.xml\n"
     ]
    }
   ],
   "source": [
    "X = None\n",
    "classes = []\n",
    "ids = [] \n",
    "i = -1\n",
    "start_index=0\n",
    "end_index=1\n",
    "direc='train'\n",
    "for datafile in os.listdir(direc):\n",
    "    print datafile\n",
    "    if datafile == '.DS_Store':\n",
    "        continue\n",
    "\n",
    "    i += 1\n",
    "    if i < start_index:\n",
    "        continue \n",
    "    if i >= end_index:\n",
    "        break\n",
    "\n",
    "    # extract id and true class (if available) from filename\n",
    "    id_str, clazz = datafile.split('.')[:2]\n",
    "    ids.append(id_str)\n",
    "    # add target class if this is training data\n",
    "    try:\n",
    "        classes.append(util.malware_classes.index(clazz))\n",
    "\n",
    "    except ValueError:\n",
    "        # we should only fail to find the label in our list of malware classes\n",
    "        # if this is test data, which always has an \"X\" label\n",
    "        assert clazz == \"X\"\n",
    "        classes.append(-1)\n",
    "\n",
    "    # parse file as an xml document\n",
    "    tree = ET.parse(os.path.join(direc,datafile))\n",
    "    add_to_set(tree)\n",
    "    call_feats(tree)\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apifunction', 'NtTerminateProcess'), ('targetpid', '2224')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-0.4a30.tar.gz (753kB)\n",
      "\u001b[K    100% || 753kB 140kB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): numpy in /Users/harrisonchase/anaconda/lib/python2.7/site-packages (from xgboost)\n",
      "Requirement already satisfied (use --upgrade to upgrade): scipy in /Users/harrisonchase/anaconda/lib/python2.7/site-packages (from xgboost)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Running setup.py bdist_wheel for xgboost ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/harrisonchase/Library/Caches/pip/wheels/24/4f/7d/95352d4cf7b2a0350462332fbd8838d666e17762fe0c05f276\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.4a30\n",
      "\u001b[33mYou are using pip version 7.1.2, however version 8.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'bst:max_depth':2, 'bst:eta':1, 'silent':1, 'objective':'multi:softmax','num_class':15 }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "plst = param.items()\n",
    "plst += [('eval_metric', 'ams@0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_round = 10\n",
    "bst = xgb.train( plst,dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pct = []\n",
    "for i in range(0,15):\n",
    "    pct.append((float(list(t_train).count(i))/len(t_train),i))\n",
    "pct1= sorted(pct,reverse=True, key=lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accept = [8,10,12]\n",
    "X_wierd = [x for x,y in zip(X_train,t_train) if y in accept]\n",
    "t_wierd = [x for x,y in zip(t_train,t_train) if y in accept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.03694102397926118, 0),\n",
       " (0.016202203499675955, 1),\n",
       " (0.011989630589760207, 2),\n",
       " (0.010369410239792612, 3),\n",
       " (0.013285806869734284, 4),\n",
       " (0.012637718729747246, 5),\n",
       " (0.017174335709656513, 6),\n",
       " (0.013285806869734284, 7),\n",
       " (0.5213869086195723, 8),\n",
       " (0.006804925469863901, 9),\n",
       " (0.17563188593648738, 10),\n",
       " (0.010369410239792612, 11),\n",
       " (0.1218405703175632, 12),\n",
       " (0.01911860012961763, 13),\n",
       " (0.012961762799740765, 14)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 10, 12]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y for x,y in pct[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_weights = [1 if y in accept else 0 for x,y in zip(X_train,t_train) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(X_train), n_folds=5, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 43.971088836787246),\n",
       " (0.5, 44.622458078288822),\n",
       " (0.3, 44.669517395477655),\n",
       " (0.1, 44.966016794910111)]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_x = sorted(res.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<function inv at 0x1064e46e0>': 40.999999999999986,\n",
       " '<function one at 0x1064e4758>': 41.425675675675684,\n",
       " '<function same at 0x1064e4aa0>': 40.560810810810786,\n",
       " \"<ufunc 'sqrt'>\": 41.864864864864877,\n",
       " \"<ufunc 'square'>\": 41.912162162162161}"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train3=np.array([x[included] for x in X_train])\n",
    "X_test3=np.array([x[included] for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_eight = [1 if x ==8 else 0 for x in t_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=10,max_features=10).fit(X_train,t_eight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37620837808807733"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred)/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810810810811\n",
      "0.797297297297\n",
      "0.790540540541\n",
      "0.817567567568\n",
      "0.837837837838\n",
      "0.804054054054\n",
      "0.824324324324\n",
      "0.804054054054\n",
      "0.783783783784\n",
      "0.797297297297\n",
      "0.790540540541\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.804054054054\n",
      "0.797297297297\n",
      "0.817567567568\n",
      "0.810810810811\n",
      "0.817567567568\n",
      "0.790540540541\n",
      "0.804054054054\n",
      "0.783783783784\n",
      "0.783783783784\n",
      "0.804054054054\n",
      "0.824324324324\n",
      "0.783783783784\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.797297297297\n",
      "0.777027027027\n",
      "0.837837837838\n",
      "0.810810810811\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.790540540541\n",
      "0.804054054054\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.824324324324\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.783783783784\n",
      "0.817567567568\n",
      "0.77027027027\n",
      "0.790540540541\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.797297297297\n",
      "0.824324324324\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.790540540541\n",
      "0.790540540541\n",
      "0.824324324324\n",
      "0.790540540541\n",
      "0.783783783784\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.804054054054\n",
      "0.783783783784\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.790540540541\n",
      "0.810810810811\n",
      "0.824324324324\n",
      "0.777027027027\n",
      "0.824324324324\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.790540540541\n",
      "0.824324324324\n",
      "0.783783783784\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.817567567568\n",
      "0.824324324324\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.817567567568\n",
      "0.810810810811\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.804054054054\n",
      "0.804054054054\n",
      "0.817567567568\n",
      "0.817567567568\n",
      "0.810810810811\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.783783783784\n",
      "0.790540540541\n",
      "0.797297297297\n",
      "0.797297297297\n",
      "0.817567567568\n",
      "0.790540540541\n",
      "0.831081081081\n",
      "0.797297297297\n",
      "0.777027027027\n",
      "0.777027027027\n",
      "0.817567567568\n",
      "0.804054054054\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.810810810811\n",
      "0.783783783784\n",
      "0.790540540541\n",
      "0.790540540541\n",
      "0.763513513514\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.777027027027\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.804054054054\n",
      "0.817567567568\n",
      "0.790540540541\n",
      "0.824324324324\n",
      "0.777027027027\n",
      "0.817567567568\n",
      "0.783783783784\n",
      "0.810810810811\n",
      "0.824324324324\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.783783783784\n",
      "0.817567567568\n",
      "0.817567567568\n",
      "0.817567567568\n",
      "0.790540540541\n",
      "0.804054054054\n",
      "0.797297297297\n",
      "0.797297297297\n",
      "0.777027027027\n",
      "0.817567567568\n",
      "0.777027027027\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.790540540541\n",
      "0.790540540541\n",
      "0.817567567568\n",
      "0.804054054054\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.831081081081\n",
      "0.817567567568\n",
      "0.817567567568\n",
      "0.790540540541\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.797297297297\n",
      "0.844594594595\n",
      "0.783783783784\n",
      "0.824324324324\n",
      "0.831081081081\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.817567567568\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.810810810811\n",
      "0.824324324324\n",
      "0.797297297297\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.797297297297\n",
      "0.797297297297\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.797297297297\n",
      "0.817567567568\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.831081081081\n",
      "0.783783783784\n",
      "0.817567567568\n",
      "0.810810810811\n",
      "0.804054054054\n",
      "0.790540540541\n",
      "0.804054054054\n",
      "0.783783783784\n",
      "0.824324324324\n",
      "0.851351351351\n",
      "0.837837837838\n",
      "0.837837837838\n",
      "0.831081081081\n",
      "0.858108108108\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.797297297297\n",
      "0.790540540541\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.831081081081\n",
      "0.817567567568\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.804054054054\n",
      "0.783783783784\n",
      "0.783783783784\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.790540540541\n",
      "0.797297297297\n",
      "0.783783783784\n",
      "0.783783783784\n",
      "0.810810810811\n",
      "0.783783783784\n",
      "0.824324324324\n",
      "0.844594594595\n",
      "0.858108108108\n",
      "0.844594594595\n",
      "0.844594594595\n",
      "0.837837837838\n",
      "0.817567567568\n",
      "0.804054054054\n",
      "0.790540540541\n",
      "0.783783783784\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.804054054054\n",
      "0.804054054054\n",
      "0.783783783784\n",
      "0.810810810811\n",
      "0.797297297297\n",
      "0.810810810811\n",
      "0.817567567568\n",
      "0.790540540541\n",
      "0.790540540541\n",
      "0.804054054054\n",
      "0.797297297297\n",
      "0.797297297297\n",
      "0.783783783784\n",
      "0.817567567568\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.797297297297\n",
      "0.777027027027\n",
      "0.810810810811\n",
      "0.783783783784\n",
      "0.824324324324\n",
      "0.810810810811\n",
      "0.810810810811\n",
      "0.804054054054\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.804054054054\n",
      "0.804054054054\n",
      "0.817567567568\n",
      "0.817567567568\n",
      "0.817567567568\n",
      "0.777027027027\n",
      "0.817567567568\n",
      "0.797297297297\n",
      "0.804054054054\n",
      "0.817567567568\n",
      "0.810810810811\n",
      "0.783783783784\n",
      "0.824324324324\n",
      "0.864864864865\n",
      "0.851351351351\n",
      "0.864864864865\n",
      "0.844594594595\n",
      "0.858108108108\n",
      "0.804054054054\n",
      "0.797297297297\n",
      "0.790540540541\n",
      "0.817567567568\n",
      "0.804054054054\n",
      "0.783783783784\n",
      "0.797297297297\n",
      "0.797297297297\n",
      "0.817567567568\n",
      "0.810810810811\n",
      "0.817567567568\n",
      "0.783783783784\n",
      "0.810810810811\n",
      "0.790540540541\n",
      "0.804054054054\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-384-ab4bf24e8353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mX_wt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_weights_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mhuh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 290\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_weights = [(pct[y][0]) for x,y in zip(X_train,t_train) ]\n",
    "res={}\n",
    "X_tr = np.array([x for x,y in zip(X_train,t_train) if y != 8])\n",
    "t_tr = np.array([y for x,y in zip(X_train,t_train) if y != 8])\n",
    "kf = KFold(len(X_tr), n_folds=10, shuffle =True)\n",
    "for mn in range(0,100):\n",
    "    for train_index, test_index in kf:\n",
    "        X_train2, X_test2 = X_train[train_index], X_train[test_index]\n",
    "        y_train2, y_test2 = np.array(t_eight)[train_index], np.array(t_eight)[test_index]\n",
    "        y_train1, y_test1 = np.array(t_train)[train_index], np.array(t_train)[test_index]\n",
    "        X_weights2, X_weights_test = np.array(X_weights)[train_index],np.array(X_weights)[test_index]\n",
    "        clf = RandomForestClassifier(n_estimators=10,max_features=None)\n",
    "        clf.fit(X_train2,y_train1)\n",
    "        huh = clf.score(X_test2,y_test1)\n",
    "        if huh <.83:\n",
    "            print huh\n",
    "            for sqr in functions:\n",
    "                X_w = np.array([sqr(x) for x in X_weights2])\n",
    "                X_wt = np.array([sqr(x) for x in X_weights_test])\n",
    "                clf = RandomForestClassifier(n_estimators=10,max_features=None)\n",
    "                clf.fit(X_train2,y_train1,X_w)\n",
    "                huh = clf.score(X_test2,y_test1)\n",
    "                print(huh)\n",
    "                if str(sqr) not in res:\n",
    "                    res[str(sqr)]=0\n",
    "                res[str(sqr)]+=huh\n",
    "            \"\"\"for max_feat in [None,1,10,100]:\n",
    "                model=RandomForestClassifier(n_estimators=10,max_features=max_feat).fit(X_train2,y_train2,np.array(X_weights2)) \n",
    "                typ = str(max_feat)+\"-\" + str(sqr)\n",
    "                if typ not in res:\n",
    "                    res[typ]=0\n",
    "                res[typ]+=model.score(X_test2,y_test2)#,X_weights_test)\n",
    "                print typ + str(model.score(X_test2,y_test2))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "functions=[np.sqrt,np.square, inv,one,same]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inv(m):\n",
    "    return 1./m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one(m):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def same(m):\n",
    "    return(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=1000,max_features=1).fit(X_train,t_train,np.array([x for x in X_weights])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.03694102397926118, 0),\n",
       " (0.016202203499675955, 1),\n",
       " (0.011989630589760207, 2),\n",
       " (0.010369410239792612, 3),\n",
       " (0.013285806869734284, 4),\n",
       " (0.012637718729747246, 5),\n",
       " (0.017174335709656513, 6),\n",
       " (0.013285806869734284, 7),\n",
       " (0.5213869086195723, 8),\n",
       " (0.006804925469863901, 9),\n",
       " (0.17563188593648738, 10),\n",
       " (0.010369410239792612, 11),\n",
       " (0.1218405703175632, 12),\n",
       " (0.01911860012961763, 13),\n",
       " (0.012961762799740765, 14)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tru = [y for x,y in pct1[0:3]]\n",
    "tru=[8,12,10,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_weights = [1 if y in tru else 0 for x,y in zip(X_train,t_train) ]\n",
    "model=RandomForestClassifier(n_estimators=100,max_features=1).fit(X_train,t_train,np.array(X_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 0, 10, 12]\n",
      "0.939736346516\n",
      "0.92220113852\n",
      "0.945179584121\n",
      "0.92789373814\n",
      "0.944971537002\n",
      "[8, 10, 12, 13]\n",
      "0.955769230769\n",
      "0.954455445545\n",
      "0.959615384615\n",
      "0.945525291829\n",
      "0.946869070209\n",
      "[8, 10, 12, 6]\n",
      "0.971374045802\n",
      "0.968316831683\n",
      "0.973180076628\n",
      "0.968688845401\n",
      "0.984555984556\n",
      "[8, 1, 10, 12]\n",
      "0.959615384615\n",
      "0.960552268245\n",
      "0.971098265896\n",
      "0.960861056751\n",
      "0.976923076923\n",
      "[8, 4, 10, 12]\n",
      "0.955426356589\n",
      "0.954365079365\n",
      "0.971042471042\n",
      "0.964774951076\n",
      "0.976878612717\n",
      "[8, 10, 12, 7]\n",
      "0.96862745098\n",
      "0.968441814596\n",
      "0.972868217054\n",
      "0.974708171206\n",
      "0.975047984645\n",
      "[8, 10, 12, 14]\n",
      "0.978682170543\n",
      "0.962075848303\n",
      "0.980620155039\n",
      "0.961013645224\n",
      "0.978886756238\n",
      "[8, 10, 12, 5]\n",
      "0.972709551657\n",
      "0.958167330677\n",
      "0.963391136802\n",
      "0.955252918288\n",
      "0.976833976834\n",
      "[8, 10, 12, 2]\n",
      "0.963106796117\n",
      "0.970238095238\n",
      "0.978682170543\n",
      "0.966601178782\n",
      "0.982692307692\n",
      "[8, 10, 3, 12]\n",
      "0.968932038835\n",
      "0.96812749004\n",
      "0.975\n",
      "0.96449704142\n",
      "0.980582524272\n",
      "[8, 10, 11, 12]\n",
      "0.964912280702\n",
      "0.964143426295\n",
      "0.972972972973\n",
      "0.970530451866\n",
      "0.970986460348\n",
      "[8, 9, 10, 12]\n",
      "0.964912280702\n",
      "0.965725806452\n",
      "0.97859922179\n",
      "0.956862745098\n",
      "0.976699029126\n",
      "[8, 0, 10, 12, 5]\n",
      "0.938432835821\n",
      "0.928838951311\n",
      "0.940520446097\n",
      "0.934944237918\n",
      "0.960674157303\n",
      "[8, 10, 12, 5, 13]\n",
      "0.950476190476\n",
      "0.9453125\n",
      "0.948960302457\n",
      "0.937142857143\n",
      "0.943820224719\n",
      "[8, 10, 12, 5, 6]\n",
      "0.969754253308\n",
      "0.966796875\n",
      "0.964218455744\n",
      "0.95785440613\n",
      "0.977142857143\n",
      "[8, 1, 10, 12, 5]\n",
      "0.96\n",
      "0.953307392996\n",
      "0.948863636364\n",
      "0.954022988506\n",
      "0.981024667932\n",
      "[8, 4, 10, 12, 5]\n",
      "0.955854126679\n",
      "0.953033268102\n",
      "0.971537001898\n",
      "0.955938697318\n",
      "0.979087452471\n",
      "[8, 10, 12, 5, 7]\n",
      "0.968932038835\n",
      "0.966926070039\n",
      "0.96380952381\n",
      "0.96380952381\n",
      "0.975378787879\n",
      "[8, 10, 12, 5, 14]\n",
      "0.965451055662\n",
      "0.962598425197\n",
      "0.965714285714\n",
      "0.954198473282\n",
      "0.973484848485\n",
      "[8, 10, 12, 5]\n",
      "0.964912280702\n",
      "0.962151394422\n",
      "0.971098265896\n",
      "0.966926070039\n",
      "0.980694980695\n",
      "[8, 10, 2, 12, 5]\n",
      "0.963461538462\n",
      "0.956947162427\n",
      "0.969523809524\n",
      "0.951923076923\n",
      "0.977229601518\n",
      "[8, 10, 3, 12, 5]\n",
      "0.969230769231\n",
      "0.966601178782\n",
      "0.964083175803\n",
      "0.96332046332\n",
      "0.980842911877\n",
      "[8, 10, 11, 12, 5]\n",
      "0.967181467181\n",
      "0.958742632613\n",
      "0.96394686907\n",
      "0.963461538462\n",
      "0.977099236641\n",
      "[8, 9, 10, 12, 5]\n",
      "0.957528957529\n",
      "0.970178926441\n",
      "0.959847036329\n",
      "0.952015355086\n",
      "0.967432950192\n",
      "[8, 0, 10, 12, 5]\n",
      "0.94776119403\n",
      "0.932584269663\n",
      "0.938661710037\n",
      "0.920074349442\n",
      "0.951310861423\n",
      "[8, 10, 12, 5, 13]\n",
      "0.948571428571\n",
      "0.94921875\n",
      "0.948960302457\n",
      "0.940952380952\n",
      "0.949438202247\n",
      "[8, 10, 12, 5, 6]\n",
      "0.96786389414\n",
      "0.962890625\n",
      "0.969868173258\n",
      "0.961685823755\n",
      "0.979047619048\n",
      "[8, 1, 10, 12, 5]\n",
      "0.965714285714\n",
      "0.951361867704\n",
      "0.960227272727\n",
      "0.952107279693\n",
      "0.975332068311\n",
      "[8, 4, 10, 12, 5]\n",
      "0.961612284069\n",
      "0.953033268102\n",
      "0.965844402277\n",
      "0.959770114943\n",
      "0.973384030418\n",
      "[8, 10, 12, 5, 7]\n",
      "0.970873786408\n",
      "0.963035019455\n",
      "0.96380952381\n",
      "0.96380952381\n",
      "0.975378787879\n",
      "[8, 10, 12, 5, 14]\n",
      "0.965451055662\n",
      "0.96062992126\n",
      "0.967619047619\n",
      "0.961832061069\n",
      "0.977272727273\n",
      "[8, 10, 12, 5]\n",
      "0.972709551657\n",
      "0.966135458167\n",
      "0.971098265896\n",
      "0.963035019455\n",
      "0.974903474903\n",
      "[8, 10, 2, 12, 5]\n",
      "0.969230769231\n",
      "0.974559686888\n",
      "0.969523809524\n",
      "0.95\n",
      "0.977229601518\n",
      "[8, 10, 3, 12, 5]\n",
      "0.971153846154\n",
      "0.960707269155\n",
      "0.965973534972\n",
      "0.96138996139\n",
      "0.978927203065\n",
      "[8, 10, 11, 12, 5]\n",
      "0.959459459459\n",
      "0.960707269155\n",
      "0.95825426945\n",
      "0.955769230769\n",
      "0.971374045802\n",
      "[8, 9, 10, 12, 5]\n",
      "0.959459459459\n",
      "0.952286282306\n",
      "0.965583173996\n",
      "0.955854126679\n",
      "0.975095785441\n",
      "[8, 0, 10, 12, 5]\n",
      "0.936567164179\n",
      "0.919475655431\n",
      "0.940520446097\n",
      "0.925650557621\n",
      "0.953183520599\n",
      "[8, 10, 12, 5, 13]\n",
      "0.950476190476\n",
      "0.94921875\n",
      "0.95652173913\n",
      "0.937142857143\n",
      "0.953183520599\n",
      "[8, 10, 12, 5, 6]\n",
      "0.975425330813\n",
      "0.966796875\n",
      "0.967984934087\n",
      "0.963601532567\n",
      "0.973333333333\n",
      "[8, 1, 10, 12, 5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-3df608be7e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mX_weights2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_weights_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_weights2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_weights_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#*sum(X_weights_test)/len(X_weights_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 290\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tru = [y for x,y in pct1[0:3]]\n",
    "for o in range(0,5):\n",
    "    res=[0]*len(range(3,15))\n",
    "    for j in range(3,15):\n",
    "        accept = list(set(tru + [pct1[j][1]]))\n",
    "        print accept\n",
    "        X_weights = [1 if y in accept else 0 for x,y in zip(X_train,t_train) ]\n",
    "        for train_index, test_index in kf:\n",
    "            X_train2, X_test2 = X_train[train_index], X_train[test_index]\n",
    "            y_train2, y_test2 = t_train[train_index], t_train[test_index]\n",
    "            X_weights2, X_weights_test = np.array(X_weights)[train_index],np.array(X_weights)[test_index]\n",
    "            model=RandomForestClassifier(n_estimators=10,max_features=None).fit(X_train2,y_train2,np.array(X_weights2))\n",
    "            res[j-3]+= model.score(X_test2,y_test2)\n",
    "            print model.score(X_test2,y_test2,X_weights_test)#*sum(X_weights_test)/len(X_weights_test)\n",
    "    pos=[i for i,x in enumerate(res) if x == max(res)]\n",
    "    tru = tru+[pos[0]+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chng = [float(list(t_train).count(i))/len(t_train) for i in range(0,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def findsubsets(S,m):\n",
    "    return set(itertools.combinations(S, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 10, 12]\n",
      "0.0171589076737\n",
      "[8, 10, 12, 0]\n",
      "0.00858150896466\n",
      "[8, 10, 12, 0, 13]\n",
      "0.0078336275465\n",
      "[8, 10, 12, 0, 13, 6]\n",
      "0.00711876932362\n",
      "[8, 10, 12, 0, 13, 6, 1]\n",
      "0.00701507588295\n",
      "[8, 10, 12, 0, 13, 6, 1, 4]\n",
      "0.0063233055304\n",
      "[8, 10, 12, 0, 13, 6, 1, 4, 7]\n",
      "0.00455203760398\n",
      "[8, 10, 12, 0, 13, 6, 1, 4, 7, 14]\n",
      "0.00444991837877\n",
      "[8, 10, 12, 0, 13, 6, 1, 4, 7, 14, 5]\n",
      "0.00677864074009\n",
      "[8, 10, 12, 0, 13, 6, 1, 4, 7, 14, 5, 2]\n",
      "0.00590432382801\n",
      "[8, 10, 12, 0, 13, 6, 1, 4, 7, 14, 5, 2, 3]\n",
      "0.00699620744839\n",
      "[8, 10, 12, 0, 13, 6, 1, 4, 7, 14, 5, 2, 3, 11]\n",
      "0.00790616828849\n",
      "[8, 10, 12, 0, 13, 6, 1, 4, 7, 14, 5, 2, 3, 11, 9]\n",
      "0.00781632033591\n"
     ]
    }
   ],
   "source": [
    "for x in range(3,16):\n",
    "    accept = [y for x,y in pct1[0:x]]\n",
    "    print accept\n",
    "    X_weights = [1 if y in accept else 0 for x,y in zip(X_train,t_train) ]\n",
    "    model=RandomForestClassifier(n_estimators=100,max_features=None).fit(X_train,t_train,np.array(X_weights))\n",
    "    pred = model.predict(X_test)\n",
    "    pred_p=[float(list(pred).count(i))/len(pred) for i in range(0,15)]\n",
    "    act_p=[float(list(t_train).count(i))/len(t_train) for i in range(0,15)]\n",
    "    print sum([(x-y)**2 for x,y in zip(pred_p,act_p)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100,max_features=100).fit(X_train,t_train,np.array(X_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "huh=pd.read_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "huh.Prediction=[x if x!=9 else 8 for x in huh.Prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tr=[x for x,y in zip(X_train,t_train) if y!=9]\n",
    "t_tr=[y for x,y in zip(X_train,t_train) if y!=9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=2.0):\n",
    "\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers(model,X_train,t_train):\n",
    "    pred = model.predict_proba(X_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_weights = np.array([(1/(pct[y][0]))**5 for x,y in zip(X_train,t_train) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes=[1]*15\n",
    "classes[8]=18\n",
    "classes[10]=6\n",
    "classes[12]=6\n",
    "cl={}\n",
    "for index,x in enumerate(classes):\n",
    "    cl[index]=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl={}\n",
    "for index,x in enumerate(classes):\n",
    "    cl[index]=x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0592909632\n",
      "22.1581328382\n"
     ]
    }
   ],
   "source": [
    "res={}\n",
    "for cutoff in [.13]:\n",
    "    cut_bal = str(cutoff)+\"_bal\"\n",
    "    cut_nb = str(cutoff)+\"_nb\"\n",
    "    for mn in range(0,5):\n",
    "        kf = KFold(len(X_train), n_folds=5, shuffle =True)\n",
    "        for train_index, test_index in kf:\n",
    "            X_train2, X_test2 = X_train[train_index], X_train[test_index]\n",
    "            y_train2, y_test2 = np.array(t_train)[train_index], np.array(t_train)[test_index]\n",
    "            X_weights = np.array([(1-(pct[y][0])) for x,y in zip(X_train2,y_train2) ])\n",
    "            mse_t = np.array(rmse1)[train_index]\n",
    "            #mse_t=np.array([2 - x for x in mse_t])\n",
    "            #X_train2 = np.array([x for x,y in zip(X_train2,mse_t) if y <cutoff])\n",
    "            #y_train2 = np.array([x for x,y in zip(y_train2,mse_t) if y <cutoff])\n",
    "            mse_t2 = np.array([y for x,y in zip(y_train2,mse_t) if y <cutoff])\n",
    "            model=RandomForestClassifier(n_estimators=10,max_features=1#,class_weight = 'balanced'\n",
    "                                        ).fit(X_train2,y_train2)\n",
    "            if cut_nb not in res:\n",
    "                res[cut_nb]=0\n",
    "            res[cut_nb]+=model.score(X_test2,y_test2)\n",
    "            model=RandomForestClassifier(n_estimators=10,max_features=1,class_weight = cl\n",
    "                                        ).fit(X_train2,y_train2)\n",
    "            if cut_bal not in res:\n",
    "                res[cut_bal]=0\n",
    "            res[cut_bal]+=model.score(X_test2,y_test2)\n",
    "    print res[cut_bal]\n",
    "    print res[cut_nb]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoff=.13\n",
    "X_train2 = np.array([x for x,y in zip(X_train,rmse1) if y <cutoff])\n",
    "y_train2 = np.array([x for x,y in zip(t_train,rmse1) if y <cutoff])\n",
    "model=RandomForestClassifier(n_estimators=10000,max_features=1,class_weight = 'balanced').fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_weights = np.array([(1/(pct[y][0])) for x,y in zip(X_train,t_train) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=[100]*15\n",
    "#classes[8]=1\n",
    "#classes[10]=1\n",
    "#classes[12]=1\n",
    "#classes = [.46,.607,.569,.764,.33,.611,.923,.72,.93,.33,.999,.388,.896,.083,.736]\n",
    "cl={}\n",
    "for index,x in enumerate(classes):\n",
    "    cl[index]=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6,\n",
       " 1: 29,\n",
       " 2: 10,\n",
       " 3: 8,\n",
       " 4: 41,\n",
       " 5: 10,\n",
       " 6: 31,\n",
       " 7: 19,\n",
       " 8: 20,\n",
       " 9: 4,\n",
       " 10: 20,\n",
       " 11: 23,\n",
       " 12: 10,\n",
       " 13: 20,\n",
       " 14: 3}"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 91,\n",
       " 1: 70,\n",
       " 2: 65,\n",
       " 3: 70,\n",
       " 4: 71,\n",
       " 5: 75,\n",
       " 6: 83,\n",
       " 7: 65,\n",
       " 8: 87,\n",
       " 9: 77,\n",
       " 10: 65,\n",
       " 11: 63,\n",
       " 12: 93,\n",
       " 13: 79,\n",
       " 14: 79}"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: 2.60691675452\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 1, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0}\n",
      "10: 3.47538722181\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 1, 9: 0, 10: 1, 11: 0, 12: 0, 13: 0, 14: 0}\n",
      "12: 3.99708895218\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 1, 9: 0, 10: 1, 11: 0, 12: 1, 13: 0, 14: 0}\n",
      "6: 4.07972074921\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: 0, 8: 1, 9: 0, 10: 1, 11: 0, 12: 1, 13: 0, 14: 0}\n",
      "7: 4.12666991865\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 0, 10: 1, 11: 0, 12: 1, 13: 0, 14: 0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-659-9199e01cfaee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtr_cl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtr_cl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_cl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mhuh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmax_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;31m# Simple optimisation to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                     \u001b[0;31m# if the parameter is deprecated, don't show it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/warnings.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot exit %r without entering first\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowwarning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showwarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for o in range(0,1000):\n",
    "    data=X_train\n",
    "    kf = KFold(len(data), n_folds=5, shuffle =True)\n",
    "    for train_index, test_index in kf:\n",
    "        X_train2, X_test2 = data[train_index], data[test_index]\n",
    "        y_train2, y_test2 = np.array(t_train)[train_index], np.array(t_train)[test_index]\n",
    "        for j in range(0,15):\n",
    "            tr_change = change.copy()\n",
    "            tr_cl[j]+=1\n",
    "            model=RandomForestClassifier(n_estimators=10,max_features=1,class_weight = tr_cl).fit(X_train2,y_train2)\n",
    "            huh[j]+=model.score(X_test2,y_test2)\n",
    "    max_h = [i for i,x in enumerate(huh) if x==max(huh)][0]\n",
    "    cl[max_h]+=1\n",
    "    print str(max_h) +\": \"+ str(max(huh))\n",
    "    print cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 11, 1: 41, 2: 6, 3: 17, 4: 33, 5: 6, 6: -11, 7: 24, 8: 3, 9: 32, 10: 1, 11: 23, 12: 10, 13: 17, 14: 14}\n",
      "0.836569579288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tr_cl[8]+=1\n",
    "print tr_cl\n",
    "model=RandomForestClassifier(n_estimators=10,max_features=1,class_weight = tr_cl).fit(X_train2,y_train2)\n",
    "print model.score(X_test2,y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=10,max_features=1).fit(X_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_a = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change = [0]*15\n",
    "change[8]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_b = [[x+z for z,x in zip(change,y)] for y in pred_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[i for i,x in enumerate(y) if x==max(y)][0] for y in pred_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 38,\n",
       " 1: 120,\n",
       " 2: 85,\n",
       " 3: 122,\n",
       " 4: 63,\n",
       " 5: 112,\n",
       " 6: 157,\n",
       " 7: 112,\n",
       " 8: 92,\n",
       " 9: 25,\n",
       " 10: 109,\n",
       " 11: 61,\n",
       " 12: 107,\n",
       " 13: 71,\n",
       " 14: 47}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl={}\n",
    "cl[0]=38\n",
    "cl[1]=120\n",
    "cl[2]=85\n",
    "cl[3]=122\n",
    "cl[4]=63\n",
    "cl[5]=112\n",
    "cl[6]=157\n",
    "cl[7]=112\n",
    "cl[8]=92\n",
    "cl[9]=25\n",
    "cl[10]=109\n",
    "cl[11]=61\n",
    "cl[12]=107\n",
    "cl[13]=71\n",
    "cl[14]=47\n",
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change=[0]*15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=10,max_features=1).fit(X_train2,y_train2)\n",
    "pred_a = model.predict_proba(X_test2)\n",
    "pred_b = [[x+z for z,x in zip(change,y)] for y in pred_a]\n",
    "preds = [[i for i,x in enumerate(y) if x==max(y)][0] for y in pred_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.3859577347327345, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.387581102841287, 4.3892018483842365, 4.3908225939271865, 4.3908225939271865, 4.3908225939271865, 4.3908225939271865, 4.3908225939271865, 4.3908225939271865, 4.3908225939271865, 4.3908225939271865, 4.385968224995148, 4.385968224995148]\n"
     ]
    }
   ],
   "source": [
    "print huh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for o in range(0,10):\n",
    "    for ind in [9]:\n",
    "        data=X_train\n",
    "        kf = KFold(len(data), n_folds=5, shuffle =True)\n",
    "        huh =[0]*101\n",
    "        for train_index, test_index in kf:\n",
    "            X_train2, X_test2 = data[train_index], data[test_index]\n",
    "            y_train2, y_test2 = np.array(t_train)[train_index], np.array(t_train)[test_index]\n",
    "            model=RandomForestClassifier(n_estimators=10,max_features=1).fit(X_train2,y_train2)\n",
    "            pred_a = model.predict_proba(X_test2)\n",
    "            for index,j in enumerate(range(-50,51)):\n",
    "                tr_change = change\n",
    "                tr_change[ind]=j*.01\n",
    "                #print tr_cl\n",
    "                pred_b = [[x+z for z,x in zip(change,y)] for y in pred_a]\n",
    "                preds = [[i for i,x in enumerate(y) if x==max(y)][0] for y in pred_b]\n",
    "                #print model.score(X_test2,y_test2)\n",
    "                huh[index]+=float(sum([1 if x==y else 0 for x,y in zip(preds,y_test2)]))/len(preds)\n",
    "                #print j\n",
    "        #print huh\n",
    "        \"\"\"max_h = [i for i,x in enumerate(huh) if x==max(huh)][(len(([i for i,x in enumerate(huh) if x==max(huh)]))-1)/2]\n",
    "        change[ind]+=range(-5,6)[max_h]*.01\n",
    "        print str(range(-5,6)[max_h]) +\": \"+ str(max(huh))\n",
    "        print change\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0=0.23: 22.2082789151\n",
      "[0.23, 0.23, 0.26, 0.02, 0.22, 0.28, 0.13, 0.37, 0.32, 0.42, 0.16, 0.42, 0.08, 0.09, 0.25]\n",
      "1=0.14: 22.2909710311\n",
      "[0.23, 0.14, 0.26, 0.02, 0.22, 0.28, 0.13, 0.37, 0.32, 0.42, 0.16, 0.42, 0.08, 0.09, 0.25]\n",
      "2=0.22: 22.2390914384\n",
      "[0.23, 0.14, 0.22, 0.02, 0.22, 0.28, 0.13, 0.37, 0.32, 0.42, 0.16, 0.42, 0.08, 0.09, 0.25]\n",
      "3=0.25: 22.2910208599\n",
      "[0.23, 0.14, 0.22, 0.25, 0.22, 0.28, 0.13, 0.37, 0.32, 0.42, 0.16, 0.42, 0.08, 0.09, 0.25]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-b72396e0d19d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search =[float(x)/100 for x in range(-50,51)]\n",
    "data=X_train\n",
    "for o in range(0,100):\n",
    "    for ind in range(0,15):\n",
    "        huh =[0]*len(search)\n",
    "        for iterations in range(0,5):\n",
    "            kf = KFold(len(data), n_folds=5, shuffle =True)\n",
    "\n",
    "            for train_index, test_index in kf:\n",
    "                X_train2, X_test2 = data[train_index], data[test_index]\n",
    "                y_train2, y_test2 = np.array(t_train)[train_index], np.array(t_train)[test_index]\n",
    "                model=RandomForestClassifier(n_estimators=10,max_features=1).fit(X_train2,y_train2)\n",
    "                pred_a = model.predict_proba(X_test2)\n",
    "                for index,j in enumerate(search):\n",
    "                    tr_change = change\n",
    "                    tr_change[ind]=j\n",
    "                    #print tr_cl\n",
    "                    pred_b = [[x+z for z,x in zip(change,y)] for y in pred_a]\n",
    "                    preds = [[i for i,x in enumerate(y) if x==max(y)][0] for y in pred_b]\n",
    "                    #print model.score(X_test2,y_test2)\n",
    "                    huh[index]+=float(sum([1 if x==y else 0 for x,y in zip(preds,y_test2)]))/len(preds)\n",
    "                    #print j\n",
    "            #print huh\n",
    "        max_h = [i for i,x in enumerate(huh) if x==max(huh)][(len(([i for i,x in enumerate(huh) if x==max(huh)]))-1)/2]\n",
    "        change[ind]=search[max_h]\n",
    "        print str(ind)+ \"=\"+str(search[max_h]) +\": \"+ str(max(huh))\n",
    "        print change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23,\n",
       " 0.14,\n",
       " 0.22,\n",
       " 0.25,\n",
       " 0.5,\n",
       " 0.28,\n",
       " 0.13,\n",
       " 0.37,\n",
       " 0.32,\n",
       " 0.42,\n",
       " 0.16,\n",
       " 0.42,\n",
       " 0.08,\n",
       " 0.09,\n",
       " 0.25]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 38,\n",
       " 1: 120,\n",
       " 2: 85,\n",
       " 3: 122,\n",
       " 4: 63,\n",
       " 5: 112,\n",
       " 6: 157,\n",
       " 7: 112,\n",
       " 8: 92,\n",
       " 9: 25,\n",
       " 10: 109,\n",
       " 11: 61,\n",
       " 12: 107,\n",
       " 13: 71,\n",
       " 14: 47}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=10000,max_features=1,class_weight=cl).fit(X_train,t_train)\n",
    "pred_a = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_b = [[x-z for z,x in zip(chng,y)] for y in pred_a]\n",
    "pred = [[i for i,x in enumerate(y) if x==max(y)][0] for y in pred_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 4.45399757675\n",
      "{0: 41, 1: 120, 2: 85, 3: 122, 4: 63, 5: 112, 6: 157, 7: 112, 8: 92, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "-2: 4.4750830042\n",
      "{0: 41, 1: 118, 2: 85, 3: 122, 4: 63, 5: 112, 6: 157, 7: 112, 8: 92, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "3: 4.45723906784\n",
      "{0: 41, 1: 118, 2: 88, 3: 122, 4: 63, 5: 112, 6: 157, 7: 112, 8: 92, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "-5: 4.4620986819\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 112, 6: 157, 7: 112, 8: 92, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "0: 4.46856330611\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 112, 6: 157, 7: 112, 8: 92, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "3: 4.49451359276\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 157, 7: 112, 8: 92, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "3: 4.45401593471\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 112, 8: 92, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "-2: 4.46694518313\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 92, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "3: 4.48967758178\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 25, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "2: 4.46854757072\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 109, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "-1: 4.44428359375\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 61, 12: 107, 13: 71, 14: 47}\n",
      "-1: 4.47828777937\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 107, 13: 71, 14: 47}\n",
      "-4: 4.48152402532\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 71, 14: 47}\n",
      "5: 4.4847891195\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 47}\n",
      "4: 4.46534279555\n",
      "{0: 41, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "-3: 4.47666703383\n",
      "{0: 38, 1: 118, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "-3: 4.46531919246\n",
      "{0: 38, 1: 115, 2: 88, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "-3: 4.45396086083\n",
      "{0: 38, 1: 115, 2: 85, 3: 117, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "3: 4.4766460533\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 63, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "-2: 4.49121965036\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 115, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "-4: 4.47178381667\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 160, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "4: 4.45558947407\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 110, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "-1: 4.46211179473\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 95, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "4: 4.47665916613\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 27, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "-1: 4.46537164377\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 108, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "1: 4.46372729514\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 60, 12: 103, 13: 76, 14: 51}\n",
      "1: 4.48476027128\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 103, 13: 76, 14: 51}\n",
      "2: 4.47665654356\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 76, 14: 51}\n",
      "2: 4.45398970905\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 51}\n",
      "-4: 4.47827204398\n",
      "{0: 38, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "5: 4.46694518313\n",
      "{0: 43, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "0: 4.44913009499\n",
      "{0: 43, 1: 115, 2: 85, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "-3: 4.46695305083\n",
      "{0: 43, 1: 115, 2: 82, 3: 120, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "1: 4.47183626798\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 61, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "4: 4.47829564707\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 111, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "2: 4.47505415598\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 164, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "4: 4.47019454192\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 109, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "5: 4.48314739343\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 99, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "4: 4.45723120014\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 26, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "-5: 4.47180741976\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 109, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "5: 4.46695305083\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 61, 12: 105, 13: 78, 14: 47}\n",
      "2: 4.49122489549\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 105, 13: 78, 14: 47}\n",
      "4: 4.46693731544\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 78, 14: 47}\n",
      "-1: 4.46696354109\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 47}\n",
      "4: 4.47827204398\n",
      "{0: 43, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "2: 4.46370631461\n",
      "{0: 45, 1: 115, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "-2: 4.46368795665\n",
      "{0: 45, 1: 113, 2: 82, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "3: 4.46208556907\n",
      "{0: 45, 1: 113, 2: 85, 3: 121, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "-4: 4.46695042826\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 65, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "-3: 4.49775770641\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 113, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "-3: 4.48315263856\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 168, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "5: 4.46698452162\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 114, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "-5: 4.4750148175\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 103, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "-1: 4.47181266489\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 21, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "4: 4.46697403136\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 114, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "4: 4.48477600667\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 63, 12: 109, 13: 77, 14: 51}\n",
      "3: 4.46536115351\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 109, 13: 77, 14: 51}\n",
      "3: 4.45721546474\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 77, 14: 51}\n",
      "-2: 4.48638888452\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 51}\n",
      "-1: 4.48477862924\n",
      "{0: 45, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-1: 4.46369844692\n",
      "{0: 44, 1: 113, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-4: 4.47505153341\n",
      "{0: 44, 1: 109, 2: 85, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-4: 4.46693207031\n",
      "{0: 44, 1: 109, 2: 81, 3: 117, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-2: 4.44591482956\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 62, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-2: 4.45400019931\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 110, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "5: 4.45400282188\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 173, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "4: 4.48153713815\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 109, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-4: 4.45561569973\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 102, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-3: 4.47829564707\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 25, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-3: 4.47020503218\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 118, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "2: 4.47830613733\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 66, 12: 112, 13: 75, 14: 50}\n",
      "-5: 4.46691108978\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 112, 13: 75, 14: 50}\n",
      "1: 4.48156074124\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 75, 14: 50}\n",
      "4: 4.47991639261\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 50}\n",
      "-1: 4.49123276319\n",
      "{0: 44, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "2: 4.47181791003\n",
      "{0: 46, 1: 109, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "-4: 4.46855806098\n",
      "{0: 46, 1: 105, 2: 81, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "-5: 4.46368271152\n",
      "{0: 46, 1: 105, 2: 76, 3: 115, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "5: 4.48152664789\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 60, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "-4: 4.47990852491\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 115, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "1: 4.4750148175\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 177, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "2: 4.47017618396\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 105, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "-2: 4.48478387437\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 99, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "2: 4.46694256057\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 22, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "-3: 4.46855806098\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 120, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "3: 4.45559996433\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 61, 12: 113, 13: 79, 14: 49}\n",
      "-4: 4.50096772671\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 113, 13: 79, 14: 49}\n",
      "5: 4.49286924412\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 79, 14: 49}\n",
      "-2: 4.47826942141\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 49}\n",
      "4: 4.44910911446\n",
      "{0: 46, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "4: 4.47341767504\n",
      "{0: 50, 1: 105, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "-4: 4.4702260127\n",
      "{0: 50, 1: 101, 2: 76, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "5: 4.47991114748\n",
      "{0: 50, 1: 101, 2: 81, 3: 120, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "1: 4.46858428664\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 56, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "5: 4.44747787866\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 116, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "4: 4.4766460533\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 179, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "-4: 4.46693731544\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 103, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "5: 4.47830613733\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "0: 4.46368008896\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 19, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "2: 4.46371418231\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 123, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "-5: 4.46856592868\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 57, 12: 118, 13: 77, 14: 53}\n",
      "-2: 4.4572495581\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 118, 13: 77, 14: 53}\n",
      "-5: 4.47503579802\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 77, 14: 53}\n",
      "-5: 4.48315788369\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 53}\n",
      "-2: 4.48152927045\n",
      "{0: 50, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "-4: 4.47343341044\n",
      "{0: 46, 1: 101, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "2: 4.46691895748\n",
      "{0: 46, 1: 103, 2: 81, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "-4: 4.45884932312\n",
      "{0: 46, 1: 103, 2: 77, 3: 121, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "5: 4.45559209664\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 61, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "-4: 4.48475240358\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 120, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "5: 4.47663294047\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 175, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "-1: 4.47018142909\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 108, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "-3: 4.46204623059\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 101, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "3: 4.47180217463\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 21, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "-2: 4.46690584465\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 118, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "-1: 4.49451621532\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 55, 12: 113, 13: 72, 14: 51}\n",
      "5: 4.46532706016\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 113, 13: 72, 14: 51}\n",
      "5: 4.47340980735\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 72, 14: 51}\n",
      "4: 4.45885456825\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 51}\n",
      "5: 4.47502006263\n",
      "{0: 46, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "1: 4.47829040193\n",
      "{0: 47, 1: 103, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "5: 4.46206983368\n",
      "{0: 47, 1: 108, 2: 77, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "-4: 4.45399495418\n",
      "{0: 47, 1: 108, 2: 73, 3: 126, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "-3: 4.47826679884\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 57, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "3: 4.46693731544\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 125, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "-3: 4.47666441126\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 174, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "-5: 4.47508824933\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 105, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "3: 4.466939938\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 104, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "1: 4.460443843\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 19, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "2: 4.4782930245\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 117, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "4: 4.47991114748\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 60, 12: 118, 13: 76, 14: 56}\n",
      "3: 4.46532181503\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 118, 13: 76, 14: 56}\n",
      "3: 4.47504628828\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 76, 14: 56}\n",
      "-3: 4.48472093279\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 56}\n",
      "-1: 4.45722857757\n",
      "{0: 47, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "4: 4.45885719081\n",
      "{0: 51, 1: 108, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "-5: 4.46207770137\n",
      "{0: 51, 1: 103, 2: 73, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "-5: 4.46691108978\n",
      "{0: 51, 1: 103, 2: 68, 3: 123, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "3: 4.46368795665\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 60, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "-2: 4.48960939508\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 122, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "3: 4.483150016\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 169, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "5: 4.47341242991\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 108, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "-5: 4.45721546474\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 105, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "-1: 4.47667752409\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 21, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "4: 4.45724693553\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 121, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "3: 4.48476813897\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 63, 12: 121, 13: 73, 14: 55}\n",
      "-3: 4.4604517107\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 73, 14: 55}\n",
      "0: 4.46535066325\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 73, 14: 55}\n",
      "3: 4.48478387437\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 55}\n",
      "3: 4.48965135613\n",
      "{0: 51, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "-2: 4.476653921\n",
      "{0: 49, 1: 103, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "4: 4.49124325345\n",
      "{0: 49, 1: 107, 2: 68, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "-4: 4.47665916613\n",
      "{0: 49, 1: 107, 2: 64, 3: 126, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "3: 4.48313165804\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 58, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "-1: 4.47017093883\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 125, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "-1: 4.46689797695\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 174, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "2: 4.48154500585\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 103, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "1: 4.47018667422\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 104, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "2: 4.4783008922\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 25, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "-2: 4.4961343383\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "0: 4.47178381667\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 60, 12: 121, 13: 76, 14: 58}\n",
      "5: 4.4734439007\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 121, 13: 76, 14: 58}\n",
      "-2: 4.46370369205\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 58}\n",
      "0: 4.48638363939\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 58}\n",
      "2: 4.46046220096\n",
      "{0: 49, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "5: 4.46208556907\n",
      "{0: 54, 1: 107, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "-4: 4.45723906784\n",
      "{0: 54, 1: 103, 2: 64, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "-4: 4.48963562074\n",
      "{0: 54, 1: 103, 2: 60, 3: 129, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "-2: 4.47181266489\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 57, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "4: 4.48962513047\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 124, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "1: 4.47341505248\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 176, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "-4: 4.46533492785\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 104, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "2: 4.46855543841\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 106, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "3: 4.47178381667\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 23, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "3: 4.46046482353\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 124, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "4: 4.45399757675\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 65, 12: 119, 13: 76, 14: 60}\n",
      "3: 4.47502006263\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 119, 13: 76, 14: 60}\n",
      "4: 4.46698452162\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 76, 14: 60}\n",
      "1: 4.46369844692\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 60}\n",
      "-1: 4.46691371235\n",
      "{0: 54, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "-5: 4.45722857757\n",
      "{0: 49, 1: 103, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "-4: 4.45721546474\n",
      "{0: 49, 1: 99, 2: 60, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "5: 4.47992163774\n",
      "{0: 49, 1: 99, 2: 65, 3: 127, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "3: 4.48802012032\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 61, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "-4: 4.45398446392\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 125, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "5: 4.47993475057\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "0: 4.49121965036\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "0: 4.48153713815\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 109, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "5: 4.47993475057\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 26, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "-3: 4.46208556907\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 128, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "1: 4.48474715845\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 68, 12: 123, 13: 77, 14: 59}\n",
      "4: 4.473436033\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 123, 13: 77, 14: 59}\n",
      "5: 4.45883096516\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 77, 14: 59}\n",
      "-5: 4.46371680488\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 59}\n",
      "-1: 4.46852921276\n",
      "{0: 49, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "3: 4.45560520946\n",
      "{0: 52, 1: 99, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "-2: 4.46210917216\n",
      "{0: 52, 1: 97, 2: 65, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "-2: 4.4734439007\n",
      "{0: 52, 1: 97, 2: 63, 3: 130, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "-4: 4.47506202368\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 57, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "-5: 4.46855281585\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "0: 4.45883621029\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 172, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "-2: 4.46692420261\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 106, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "2: 4.46859215433\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 114, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "2: 4.47664343074\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "0: 4.46536115351\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 129, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "-2: 4.47668014665\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 72, 12: 128, 13: 72, 14: 58}\n",
      "3: 4.47504891085\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 128, 13: 72, 14: 58}\n",
      "-1: 4.48641511017\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 72, 14: 58}\n",
      "4: 4.47343865557\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 58}\n",
      "2: 4.44429408402\n",
      "{0: 52, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "5: 4.46205672085\n",
      "{0: 57, 1: 97, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "5: 4.47992426031\n",
      "{0: 57, 1: 102, 2: 63, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "5: 4.47021027731\n",
      "{0: 57, 1: 102, 2: 68, 3: 126, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "-1: 4.48965135613\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 52, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "-5: 4.47826942141\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 130, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "2: 4.47507251394\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "0: 4.47502268519\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 108, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "-5: 4.47021289988\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "0: 4.46856592868\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 23, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "-5: 4.46532706016\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 127, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "-2: 4.46368795665\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 75, 12: 127, 13: 76, 14: 60}\n",
      "-1: 4.46695305083\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 127, 13: 76, 14: 60}\n",
      "-3: 4.46532181503\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 76, 14: 60}\n",
      "4: 4.47184938081\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 60}\n",
      "-3: 4.48478649693\n",
      "{0: 57, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "1: 4.49123276319\n",
      "{0: 58, 1: 102, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "-2: 4.48153976072\n",
      "{0: 58, 1: 100, 2: 68, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "-1: 4.47019454192\n",
      "{0: 58, 1: 100, 2: 67, 3: 125, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "-1: 4.47017356139\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 47, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "4: 4.45722333244\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "0: 4.49125374371\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 170, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "1: 4.48801749776\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 103, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "4: 4.48148993197\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 116, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "1: 4.46370106948\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "0: 4.45235060555\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 125, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "-4: 4.49123800832\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 74, 12: 124, 13: 80, 14: 57}\n",
      "2: 4.47670112718\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 124, 13: 80, 14: 57}\n",
      "1: 4.47181791003\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 80, 14: 57}\n",
      "-4: 4.47347274892\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 57}\n",
      "-3: 4.4879912721\n",
      "{0: 58, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "2: 4.46855806098\n",
      "{0: 60, 1: 100, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "3: 4.47019978705\n",
      "{0: 60, 1: 103, 2: 67, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "-5: 4.46214064295\n",
      "{0: 60, 1: 103, 2: 62, 3: 124, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "-5: 4.47828777937\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 51, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "-4: 4.47177070384\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 132, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "1: 4.47502530776\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 171, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "4: 4.47505677855\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 107, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "-3: 4.47828253424\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 117, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "3: 4.49126423397\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 18, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "3: 4.46368795665\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 121, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "-2: 4.48153976072\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 76, 12: 125, 13: 76, 14: 54}\n",
      "3: 4.47182577772\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 125, 13: 76, 14: 54}\n",
      "4: 4.47830613733\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 76, 14: 54}\n",
      "2: 4.47503842059\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 54}\n",
      "-4: 4.48477600667\n",
      "{0: 60, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "-3: 4.47181791003\n",
      "{0: 57, 1: 103, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "-3: 4.47987967669\n",
      "{0: 57, 1: 100, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "0: 4.46857379637\n",
      "{0: 57, 1: 100, 2: 62, 3: 119, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "2: 4.46531394733\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 47, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "-5: 4.47018142909\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 133, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "-3: 4.46855806098\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 175, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "4: 4.46209605933\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 104, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "-4: 4.46528247654\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 120, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "1: 4.47993475057\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 21, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "-3: 4.46049367175\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 119, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "-5: 4.46697403136\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 79, 12: 129, 13: 78, 14: 50}\n",
      "3: 4.47827466654\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 129, 13: 78, 14: 50}\n",
      "4: 4.46693731544\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 50}\n",
      "0: 4.45236634094\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 50}\n",
      "3: 4.44591220699\n",
      "{0: 57, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "2: 4.47669588205\n",
      "{0: 59, 1: 100, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "4: 4.47342816531\n",
      "{0: 59, 1: 104, 2: 62, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "4: 4.47991901517\n",
      "{0: 59, 1: 104, 2: 66, 3: 121, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "-3: 4.47664080817\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 42, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "-3: 4.46531394733\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 130, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "-2: 4.47503317545\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 179, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "-2: 4.4620908142\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 100, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "-1: 4.46691895748\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 121, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "5: 4.46692420261\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 18, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "3: 4.45885194568\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 114, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "2: 4.46695829596\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 82, 12: 133, 13: 78, 14: 53}\n",
      "2: 4.47344914583\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 133, 13: 78, 14: 53}\n",
      "-3: 4.45719186165\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 78, 14: 53}\n",
      "1: 4.47342292017\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 53}\n",
      "5: 4.4621065496\n",
      "{0: 59, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "-2: 4.47019716448\n",
      "{0: 57, 1: 104, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "-5: 4.46368533409\n",
      "{0: 57, 1: 99, 2: 66, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "-4: 4.47181266489\n",
      "{0: 57, 1: 99, 2: 62, 3: 118, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "5: 4.46855281585\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 39, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "-2: 4.46857641894\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 128, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "-5: 4.47992163774\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 177, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "-5: 4.47665129843\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 99, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "1: 4.4685869092\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 126, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "-4: 4.47666965639\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 21, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "-3: 4.47181004233\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 116, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "4: 4.473436033\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 84, 12: 130, 13: 79, 14: 58}\n",
      "5: 4.48804634598\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 79, 14: 58}\n",
      "0: 4.47183889055\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 79, 14: 58}\n",
      "4: 4.46370631461\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 58}\n",
      "3: 4.47668276922\n",
      "{0: 57, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "-1: 4.47668801435\n",
      "{0: 56, 1: 99, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "5: 4.45724693553\n",
      "{0: 56, 1: 104, 2: 62, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "1: 4.47016569369\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "0: 4.47506464624\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "0: 4.47506202368\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 123, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "-1: 4.47668539179\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 172, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "1: 4.46208032394\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 100, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "-3: 4.49286137643\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 122, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "-2: 4.47991377004\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 18, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "-3: 4.46697403136\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 120, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "3: 4.45886243594\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 89, 12: 130, 13: 83, 14: 61}\n",
      "1: 4.473436033\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 130, 13: 83, 14: 61}\n",
      "2: 4.48154500585\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 83, 14: 61}\n",
      "4: 4.47990065721\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 61}\n",
      "2: 4.48476551641\n",
      "{0: 56, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "-5: 4.47342292017\n",
      "{0: 51, 1: 104, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "-2: 4.48475502615\n",
      "{0: 51, 1: 102, 2: 63, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "-2: 4.48961726278\n",
      "{0: 51, 1: 102, 2: 61, 3: 123, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "-2: 4.45236634094\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "0: 4.47670637231\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 122, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "-1: 4.48315788369\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 173, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "1: 4.45395299313\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 97, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "-5: 4.47833760812\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "0: 4.47179955207\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 15, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "1: 4.47181528746\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 123, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "-2: 4.47668801435\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 90, 12: 132, 13: 87, 14: 63}\n",
      "5: 4.45076919849\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 132, 13: 87, 14: 63}\n",
      "-2: 4.47988754439\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 87, 14: 63}\n",
      "2: 4.45076395336\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 63}\n",
      "2: 4.46046482353\n",
      "{0: 51, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "-3: 4.47180741976\n",
      "{0: 48, 1: 102, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "-3: 4.48316575139\n",
      "{0: 48, 1: 99, 2: 61, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "-2: 4.47021289988\n",
      "{0: 48, 1: 99, 2: 59, 3: 121, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "5: 4.46855806098\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 37, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "-2: 4.48960677251\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 121, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "1: 4.47667227896\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 174, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "5: 4.46532443759\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 92, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "-4: 4.4686026446\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 120, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "-4: 4.48152664789\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 16, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "1: 4.46371942744\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 121, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "2: 4.47667227896\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "0: 4.48151878019\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 130, 13: 89, 14: 65}\n",
      "-1: 4.45722070988\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 89, 14: 65}\n",
      "-2: 4.48636265886\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 65}\n",
      "2: 4.47180741976\n",
      "{0: 48, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "1: 4.48153451559\n",
      "{0: 49, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "0: 4.46373516284\n",
      "{0: 49, 1: 99, 2: 59, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "-5: 4.46692944774\n",
      "{0: 49, 1: 99, 2: 54, 3: 126, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "-3: 4.47341242991\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 35, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "-3: 4.47185200338\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 122, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "-1: 4.48311592264\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 179, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "5: 4.47177857154\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 88, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "-5: 4.47506202368\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 116, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "5: 4.47991639261\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 17, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "-5: 4.46858166407\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 123, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "-3: 4.47178381667\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 95, 12: 129, 13: 87, 14: 67}\n",
      "-1: 4.47828253424\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 129, 13: 87, 14: 67}\n",
      "-4: 4.47341242991\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 87, 14: 67}\n",
      "4: 4.4556025869\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 67}\n",
      "-5: 4.49125374371\n",
      "{0: 49, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "-5: 4.46860788973\n",
      "{0: 44, 1: 99, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "2: 4.48800438493\n",
      "{0: 44, 1: 101, 2: 54, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "2: 4.47509349446\n",
      "{0: 44, 1: 101, 2: 56, 3: 123, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "4: 4.48479960976\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 32, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "-2: 4.46044908813\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 121, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "3: 4.48154762841\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 184, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "-4: 4.46856068355\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "0: 4.46529821193\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 121, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "-3: 4.47019716448\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 12, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "1: 4.46692420261\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 120, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "1: 4.46532181503\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 94, 12: 125, 13: 91, 14: 62}\n",
      "-1: 4.46369844692\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 125, 13: 91, 14: 62}\n",
      "-3: 4.48634954603\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 91, 14: 62}\n",
      "3: 4.47340980735\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 62}\n",
      "-2: 4.47346225866\n",
      "{0: 44, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "5: 4.48152927045\n",
      "{0: 49, 1: 101, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "3: 4.48312641291\n",
      "{0: 49, 1: 104, 2: 56, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "-1: 4.46693469287\n",
      "{0: 49, 1: 104, 2: 55, 3: 127, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "2: 4.47017880652\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 30, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "-3: 4.43779798902\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 124, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "-5: 4.45881522976\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 180, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "2: 4.47988492182\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 83, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "-1: 4.49937058426\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 118, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "-1: 4.476653921\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "0: 4.45562618999\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 121, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "4: 4.48641511017\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 93, 12: 122, 13: 94, 14: 60}\n",
      "3: 4.46046220096\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 122, 13: 94, 14: 60}\n",
      "-4: 4.46857379637\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 94, 14: 60}\n",
      "-1: 4.47829564707\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 60}\n",
      "-3: 4.47827991167\n",
      "{0: 49, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "-5: 4.45397397366\n",
      "{0: 44, 1: 104, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "-1: 4.47663556304\n",
      "{0: 44, 1: 103, 2: 55, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "5: 4.49772099049\n",
      "{0: 44, 1: 103, 2: 60, 3: 129, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "-3: 4.46047006866\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 27, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "-5: 4.4572338227\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 119, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "-5: 4.47349110688\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 182, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "-2: 4.47827991167\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 82, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "1: 4.46859215433\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 117, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "-4: 4.47016307113\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 13, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "2: 4.47505940111\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 125, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "4: 4.46047006866\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "0: 4.46208556907\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 118, 13: 93, 14: 57}\n",
      "-5: 4.48148468684\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 93, 14: 57}\n",
      "-2: 4.46855281585\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 57}\n",
      "-4: 4.48317099652\n",
      "{0: 44, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-1: 4.49772099049\n",
      "{0: 43, 1: 103, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-4: 4.48151878019\n",
      "{0: 43, 1: 99, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "0: 4.47341242991\n",
      "{0: 43, 1: 99, 2: 60, 3: 126, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-3: 4.4539556157\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 22, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-3: 4.48475764871\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 114, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-5: 4.45078493389\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 180, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-1: 4.45562356742\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 83, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-2: 4.4686026446\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 113, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "4: 4.45401593471\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 15, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-2: 4.48640724248\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 129, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "5: 4.46855019328\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 96, 12: 113, 13: 91, 14: 53}\n",
      "-4: 4.49607926442\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 113, 13: 91, 14: 53}\n",
      "-2: 4.45395823827\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 91, 14: 53}\n",
      "-2: 4.46370369205\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 53}\n",
      "2: 4.460443843\n",
      "{0: 43, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "3: 4.46045433327\n",
      "{0: 46, 1: 99, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "-4: 4.46693207031\n",
      "{0: 46, 1: 95, 2: 60, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "-4: 4.47017880652\n",
      "{0: 46, 1: 95, 2: 56, 3: 123, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "-5: 4.47667752409\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 19, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "4: 4.48316050626\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "0: 4.47506989137\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 179, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "-5: 4.47503579802\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 81, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "-4: 4.46531656989\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 117, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "2: 4.47669588205\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 13, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "5: 4.47505940111\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 134, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "4: 4.46692944774\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 92, 12: 111, 13: 89, 14: 55}\n",
      "4: 4.4620986819\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 111, 13: 89, 14: 55}\n",
      "-3: 4.47018667422\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 55}\n",
      "0: 4.47666178869\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 55}\n",
      "-4: 4.4815030448\n",
      "{0: 46, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "4: 4.46856855124\n",
      "{0: 50, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "0: 4.46856592868\n",
      "{0: 50, 1: 95, 2: 56, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "3: 4.47017356139\n",
      "{0: 50, 1: 95, 2: 59, 3: 118, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "5: 4.45722333244\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 23, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "-1: 4.47017880652\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 109, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "-4: 4.46532443759\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 174, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "-5: 4.45076395336\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 77, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "-5: 4.47343865557\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 119, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "2: 4.47504366572\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 18, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "-4: 4.45885981338\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 138, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "-5: 4.46693207031\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 96, 12: 108, 13: 89, 14: 51}\n",
      "2: 4.48477600667\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 108, 13: 89, 14: 51}\n",
      "-3: 4.46048580405\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 89, 14: 51}\n",
      "-4: 4.47831662759\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 51}\n",
      "2: 4.46047531379\n",
      "{0: 50, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "-4: 4.45886505851\n",
      "{0: 46, 1: 95, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "-3: 4.47826417628\n",
      "{0: 46, 1: 92, 2: 59, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "-1: 4.46695829596\n",
      "{0: 46, 1: 92, 2: 58, 3: 123, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "1: 4.47182053259\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 22, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "2: 4.48476813897\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 105, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "-1: 4.47666703383\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 169, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "1: 4.47988754439\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "0: 4.47021027731\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 121, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "2: 4.45398446392\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 14, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "1: 4.44750410432\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 133, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "4: 4.47181266489\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "0: 4.45887817134\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 105, 13: 85, 14: 53}\n",
      "-2: 4.46208556907\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 85, 14: 53}\n",
      "3: 4.47018667422\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "0: 4.46371155974\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "0: 4.47827991167\n",
      "{0: 46, 1: 92, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "5: 4.47182053259\n",
      "{0: 46, 1: 97, 2: 58, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "5: 4.48151878019\n",
      "{0: 46, 1: 97, 2: 63, 3: 124, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "-5: 4.46048318149\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 24, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "3: 4.46856330611\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 104, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "5: 4.47180217463\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 170, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "-2: 4.47342816531\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "0: 4.49453719585\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 123, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "2: 4.47991639261\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 15, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "-5: 4.46855019328\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 137, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "2: 4.46207245624\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "0: 4.47828777937\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 103, 13: 88, 14: 53}\n",
      "5: 4.47182053259\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 88, 14: 53}\n",
      "-5: 4.47503055289\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 53}\n",
      "-3: 4.46858953177\n",
      "{0: 46, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "-4: 4.47344652326\n",
      "{0: 42, 1: 97, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "-2: 4.47181791003\n",
      "{0: 42, 1: 95, 2: 63, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "3: 4.48318148678\n",
      "{0: 42, 1: 95, 2: 66, 3: 119, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "-3: 4.45236896351\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "0: 4.45396872853\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 109, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "1: 4.48477862924\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 168, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "-3: 4.45883358772\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 72, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "3: 4.46208819164\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 125, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "-4: 4.49611598034\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 10, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "5: 4.47020765474\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "0: 4.47181791003\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "0: 4.47664867587\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 108, 13: 83, 14: 50}\n",
      "-2: 4.45236896351\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 83, 14: 50}\n",
      "3: 4.4572495581\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 50}\n",
      "4: 4.47667227896\n",
      "{0: 42, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "-1: 4.47666965639\n",
      "{0: 41, 1: 95, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "5: 4.46206721111\n",
      "{0: 41, 1: 100, 2: 66, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "5: 4.48151353506\n",
      "{0: 41, 1: 100, 2: 71, 3: 116, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "5: 4.48639412965\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 27, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "1: 4.47669325948\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 110, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "-3: 4.44587549108\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 165, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "-5: 4.46856855124\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 75, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "-3: 4.47505153341\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "0: 4.48316575139\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "0: 4.48316837396\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 139, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "4: 4.46209343677\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 98, 12: 106, 13: 86, 14: 54}\n",
      "1: 4.47507251394\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 106, 13: 86, 14: 54}\n",
      "3: 4.45563930282\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 86, 14: 54}\n",
      "5: 4.47663556304\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 54}\n",
      "4: 4.48962513047\n",
      "{0: 41, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "4: 4.47181266489\n",
      "{0: 45, 1: 100, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "5: 4.46044122044\n",
      "{0: 45, 1: 105, 2: 71, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "3: 4.4879912721\n",
      "{0: 45, 1: 105, 2: 74, 3: 121, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "-1: 4.48152927045\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 28, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "4: 4.45563143512\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 107, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "-5: 4.48316312883\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 160, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "5: 4.47503579802\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "0: 4.45398184136\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 121, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "4: 4.45075608566\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 15, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "1: 4.4621065496\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 143, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "4: 4.47340193965\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 99, 12: 109, 13: 91, 14: 58}\n",
      "-3: 4.47991901517\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 109, 13: 91, 14: 58}\n",
      "-3: 4.45238207634\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 91, 14: 58}\n",
      "5: 4.48315526113\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 58}\n",
      "4: 4.47181266489\n",
      "{0: 45, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "5: 4.4604595784\n",
      "{0: 50, 1: 105, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "-2: 4.46371418231\n",
      "{0: 50, 1: 103, 2: 74, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "-5: 4.45886505851\n",
      "{0: 50, 1: 103, 2: 69, 3: 120, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "-3: 4.46693731544\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 32, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "3: 4.45397921879\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 102, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "2: 4.48477076154\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 165, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "-4: 4.46696091853\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 72, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "-2: 4.47177857154\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "0: 4.46532181503\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 16, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "-4: 4.4945031025\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 147, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "-5: 4.47020503218\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 96, 12: 106, 13: 96, 14: 62}\n",
      "-2: 4.4896382433\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 106, 13: 96, 14: 62}\n",
      "5: 4.47668801435\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 96, 14: 62}\n",
      "3: 4.4588807939\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 62}\n",
      "-1: 4.46857379637\n",
      "{0: 50, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "5: 4.44102898984\n",
      "{0: 55, 1: 103, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "-4: 4.49289022465\n",
      "{0: 55, 1: 99, 2: 69, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "2: 4.49774197102\n",
      "{0: 55, 1: 99, 2: 71, 3: 117, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "1: 4.45397921879\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 35, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "-1: 4.47019454192\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 104, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "2: 4.47016569369\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 161, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "1: 4.47343078787\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "0: 4.47019191935\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 125, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "1: 4.50419610497\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 12, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "3: 4.45395823827\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 142, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "2: 4.46859739946\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 94, 12: 111, 13: 99, 14: 61}\n",
      "3: 4.45884670055\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 111, 13: 99, 14: 61}\n",
      "2: 4.4734439007\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 61}\n",
      "0: 4.47019191935\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 61}\n",
      "-4: 4.45885194568\n",
      "{0: 55, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "-4: 4.47987443156\n",
      "{0: 51, 1: 99, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "2: 4.46696354109\n",
      "{0: 51, 1: 101, 2: 71, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "-3: 4.45071150205\n",
      "{0: 51, 1: 101, 2: 68, 3: 118, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "-4: 4.45721808731\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 34, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "4: 4.47668276922\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 106, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "-3: 4.47991639261\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 162, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "-1: 4.47668276922\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "0: 4.44587024594\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 126, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "-3: 4.45076133079\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 15, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "4: 4.47345439096\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 144, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "1: 4.50420397266\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 97, 12: 113, 13: 99, 14: 57}\n",
      "-1: 4.489646111\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 113, 13: 99, 14: 57}\n",
      "-3: 4.48315263856\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 99, 14: 57}\n",
      "1: 4.48799389467\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 57}\n",
      "5: 4.46536377607\n",
      "{0: 51, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "-5: 4.45886768108\n",
      "{0: 46, 1: 101, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "1: 4.45562094486\n",
      "{0: 46, 1: 102, 2: 68, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "2: 4.45238994403\n",
      "{0: 46, 1: 102, 2: 70, 3: 114, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "1: 4.4718047972\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 38, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "-2: 4.48642297787\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 103, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "-3: 4.45886243594\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 161, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "-4: 4.47669325948\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 70, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "-1: 4.44589122647\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 123, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "3: 4.47342029761\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 19, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "-3: 4.48152927045\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 145, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "1: 4.46856592868\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 96, 12: 110, 13: 100, 14: 62}\n",
      "-1: 4.47500957236\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 110, 13: 100, 14: 62}\n",
      "2: 4.46532968272\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 100, 14: 62}\n",
      "5: 4.46854757072\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "0: 4.45073248257\n",
      "{0: 46, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "-3: 4.45398446392\n",
      "{0: 43, 1: 102, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "3: 4.4620829465\n",
      "{0: 43, 1: 105, 2: 70, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "-1: 4.47182315516\n",
      "{0: 43, 1: 105, 2: 69, 3: 115, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "2: 4.46532968272\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 36, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "4: 4.48964086587\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 100, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "-5: 4.47831662759\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 157, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "-1: 4.45882834259\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 69, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "-5: 4.48477076154\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 126, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "-1: 4.46695305083\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 16, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "-1: 4.4847812518\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 146, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "4: 4.45558947407\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 95, 12: 112, 13: 105, 14: 62}\n",
      "4: 4.47179168437\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 112, 13: 105, 14: 62}\n",
      "-1: 4.47345963609\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 105, 14: 62}\n",
      "5: 4.47994261826\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 62}\n",
      "-5: 4.48640724248\n",
      "{0: 43, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "-3: 4.46368795665\n",
      "{0: 40, 1: 105, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "-3: 4.48473929075\n",
      "{0: 40, 1: 102, 2: 69, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "-5: 4.46858166407\n",
      "{0: 40, 1: 102, 2: 64, 3: 117, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "5: 4.44915107551\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 40, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "1: 4.47990327978\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 95, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "-3: 4.47017618396\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 156, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "5: 4.47342816531\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "0: 4.46047793636\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 125, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "-5: 4.48316575139\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 15, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "-5: 4.49289284721\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 150, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "3: 4.47826942141\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 99, 12: 111, 13: 110, 14: 57}\n",
      "-3: 4.46693207031\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 111, 13: 110, 14: 57}\n",
      "-5: 4.46856068355\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 110, 14: 57}\n",
      "5: 4.47179168437\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 57}\n",
      "-2: 4.48640986504\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "0: 4.46696616366\n",
      "{0: 40, 1: 102, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "-3: 4.47667490152\n",
      "{0: 40, 1: 99, 2: 64, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "3: 4.46694256057\n",
      "{0: 40, 1: 99, 2: 67, 3: 122, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "4: 4.45560520946\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 41, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "-4: 4.47989278952\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 92, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "-3: 4.476653921\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 161, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "1: 4.46534279555\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 64, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "-2: 4.45883621029\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 120, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "-2: 4.47991639261\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 10, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "-4: 4.45883883285\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "0: 4.45073248257\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 96, 12: 106, 13: 115, 14: 55}\n",
      "2: 4.4572338227\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 106, 13: 115, 14: 55}\n",
      "2: 4.45562356742\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 115, 14: 55}\n",
      "-5: 4.47179430693\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 55}\n",
      "-4: 4.47341242991\n",
      "{0: 40, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "2: 4.46369844692\n",
      "{0: 42, 1: 99, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "3: 4.46210130446\n",
      "{0: 42, 1: 102, 2: 67, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "2: 4.46693469287\n",
      "{0: 42, 1: 102, 2: 69, 3: 126, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "5: 4.44753295254\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "0: 4.45561832229\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 89, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "-1: 4.46532706016\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 162, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "-3: 4.44589384903\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 62, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "-3: 4.47990590235\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 118, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "1: 4.48479174207\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 6, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "-3: 4.47181528746\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 153, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "5: 4.47344652326\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 98, 12: 108, 13: 110, 14: 51}\n",
      "-5: 4.46374827566\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 108, 13: 110, 14: 51}\n",
      "-5: 4.47342554274\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 110, 14: 51}\n",
      "3: 4.49610286751\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 51}\n",
      "-1: 4.47180217463\n",
      "{0: 42, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "-1: 4.47668801435\n",
      "{0: 41, 1: 102, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "-1: 4.48155549611\n",
      "{0: 41, 1: 101, 2: 69, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "1: 4.48315263856\n",
      "{0: 41, 1: 101, 2: 70, 3: 131, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "-1: 4.4847891195\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 37, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "-3: 4.48477600667\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 88, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "-4: 4.47506726881\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "0: 4.4799399957\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 59, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "5: 4.46856855124\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 119, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "5: 4.46211441729\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 3, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "5: 4.4944873671\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 158, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "-2: 4.49127472424\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 93, 12: 103, 13: 113, 14: 50}\n",
      "2: 4.47018667422\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 103, 13: 113, 14: 50}\n",
      "-4: 4.46044122044\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 50}\n",
      "0: 4.47991114748\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 50}\n",
      "-4: 4.46693731544\n",
      "{0: 41, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "4: 4.49126161141\n",
      "{0: 45, 1: 101, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "5: 4.48801225263\n",
      "{0: 45, 1: 106, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "0: 4.43620346913\n",
      "{0: 45, 1: 106, 2: 70, 3: 130, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "3: 4.44752246227\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 34, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "-1: 4.47667227896\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 84, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "-1: 4.47016307113\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "0: 4.46855281585\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 64, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "-3: 4.44912747242\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 124, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "-5: 4.48315526113\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 8, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "-3: 4.45072723744\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 156, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "-2: 4.48316837396\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "0: 4.47510398473\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "0: 4.47668276922\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 113, 14: 46}\n",
      "3: 4.46534541812\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "0: 4.48474978102\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "0: 4.45401331214\n",
      "{0: 45, 1: 106, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "2: 4.46860788973\n",
      "{0: 45, 1: 108, 2: 70, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "-3: 4.46208819164\n",
      "{0: 45, 1: 108, 2: 67, 3: 133, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "4: 4.48476027128\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 33, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "3: 4.4734439007\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "0: 4.46692944774\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 159, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "5: 4.4653087022\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 61, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "1: 4.46048580405\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 119, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "-4: 4.46856592868\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 5, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "5: 4.46694256057\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 154, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "2: 4.48800438493\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 95, 12: 99, 13: 116, 14: 46}\n",
      "3: 4.4717969295\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 99, 13: 116, 14: 46}\n",
      "5: 4.47669325948\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 116, 14: 46}\n",
      "-3: 4.47185462594\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 46}\n",
      "2: 4.46046482353\n",
      "{0: 45, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "4: 4.48639937478\n",
      "{0: 49, 1: 108, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "3: 4.48640986504\n",
      "{0: 49, 1: 111, 2: 67, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "-4: 4.48314739343\n",
      "{0: 49, 1: 111, 2: 63, 3: 137, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "4: 4.45883358772\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "0: 4.47663294047\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 83, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "-4: 4.47827728911\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 164, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "2: 4.46529821193\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 62, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "-1: 4.48638626195\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 115, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "4: 4.44592531982\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 10, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "4: 4.4766381856\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 156, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "4: 4.47176808128\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "0: 4.46205934341\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 104, 13: 113, 14: 48}\n",
      "2: 4.48474715845\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 113, 14: 48}\n",
      "-1: 4.47179430693\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 48}\n",
      "2: 4.46696616366\n",
      "{0: 49, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "-3: 4.46531656989\n",
      "{0: 46, 1: 111, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "-3: 4.46210130446\n",
      "{0: 46, 1: 108, 2: 63, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "-5: 4.47503579802\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "0: 4.48314739343\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 36, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "3: 4.46696616366\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 79, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "-1: 4.45399495418\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 166, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "-1: 4.47015258087\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 61, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "-5: 4.47017356139\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 119, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "4: 4.4685869092\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 14, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "-1: 4.45887292621\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 160, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "-1: 4.46371418231\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 98, 12: 106, 13: 112, 14: 50}\n",
      "4: 4.46536902121\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 106, 13: 112, 14: 50}\n",
      "2: 4.48961726278\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 112, 14: 50}\n",
      "2: 4.47342554274\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 50}\n",
      "1: 4.46046744609\n",
      "{0: 46, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "-4: 4.46207507881\n",
      "{0: 42, 1: 108, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "-1: 4.47017880652\n",
      "{0: 42, 1: 107, 2: 58, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "5: 4.48473666819\n",
      "{0: 42, 1: 107, 2: 63, 3: 141, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "-4: 4.45236371838\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 39, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "5: 4.46529558937\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 78, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "-4: 4.45721546474\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "0: 4.46209343677\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 56, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "-5: 4.47021027731\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 123, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "-1: 4.46855281585\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 13, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "-1: 4.46857117381\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 159, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "2: 4.45236371838\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 102, 12: 108, 13: 114, 14: 51}\n",
      "-3: 4.47016569369\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 114, 14: 51}\n",
      "0: 4.47666178869\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 114, 14: 51}\n",
      "3: 4.48317099652\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 51}\n",
      "-1: 4.45557373868\n",
      "{0: 42, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "-2: 4.50418036957\n",
      "{0: 40, 1: 107, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "4: 4.46045695583\n",
      "{0: 40, 1: 111, 2: 63, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "1: 4.47018142909\n",
      "{0: 40, 1: 111, 2: 64, 3: 137, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "3: 4.4604517107\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 44, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "-4: 4.47020765474\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 74, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "2: 4.49609762238\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 165, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "-5: 4.46206196598\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 51, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "-1: 4.48154238328\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 122, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "-1: 4.45078755645\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 12, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "-4: 4.46371418231\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 161, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "-5: 4.47828777937\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 99, 12: 108, 13: 117, 14: 50}\n",
      "-5: 4.48154762841\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 108, 13: 117, 14: 50}\n",
      "4: 4.49284301847\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 117, 14: 50}\n",
      "3: 4.47667490152\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 50}\n",
      "-4: 4.47020503218\n",
      "{0: 40, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "-5: 4.46208556907\n",
      "{0: 35, 1: 111, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "3: 4.47019716448\n",
      "{0: 35, 1: 114, 2: 64, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "2: 4.46211441729\n",
      "{0: 35, 1: 114, 2: 66, 3: 140, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "-4: 4.47665916613\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 40, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "2: 4.48961464021\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "0: 4.45394250287\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 160, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "1: 4.46042548504\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 50, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "-1: 4.47018667422\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 121, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "1: 4.47342292017\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "0: 4.46368795665\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 156, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "4: 4.47832974042\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 94, 12: 112, 13: 120, 14: 46}\n",
      "1: 4.47505153341\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 120, 14: 46}\n",
      "0: 4.47016831626\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 120, 14: 46}\n",
      "5: 4.46534541812\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 46}\n",
      "2: 4.46045433327\n",
      "{0: 35, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "3: 4.47345701353\n",
      "{0: 38, 1: 114, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "2: 4.4701499583\n",
      "{0: 38, 1: 116, 2: 66, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "-2: 4.48638363939\n",
      "{0: 38, 1: 116, 2: 64, 3: 136, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "1: 4.47992688287\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "0: 4.46211441729\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 76, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "-1: 4.47019191935\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 161, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "4: 4.45559734177\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 49, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "2: 4.47019978705\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 122, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "-2: 4.44914845295\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 8, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "4: 4.49124063088\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 160, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "-5: 4.45398446392\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 95, 12: 112, 13: 125, 14: 48}\n",
      "-1: 4.48477600667\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 112, 13: 125, 14: 48}\n",
      "-4: 4.46205147572\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 125, 14: 48}\n",
      "2: 4.47181791003\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 48}\n",
      "4: 4.47990327978\n",
      "{0: 38, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "4: 4.4717969295\n",
      "{0: 42, 1: 116, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "3: 4.46693731544\n",
      "{0: 42, 1: 119, 2: 64, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "1: 4.46206196598\n",
      "{0: 42, 1: 119, 2: 65, 3: 137, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "4: 4.47508038164\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "0: 4.44913534012\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 75, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "4: 4.47504628828\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 165, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "1: 4.48475764871\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 51, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "-1: 4.47339931708\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 120, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "-1: 4.47665129843\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 12, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "4: 4.45723644527\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 155, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "1: 4.47668539179\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 94, 12: 108, 13: 127, 14: 52}\n",
      "-3: 4.45558685151\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 127, 14: 52}\n",
      "0: 4.45237420864\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 127, 14: 52}\n",
      "5: 4.47502530776\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 52}\n",
      "-1: 4.45722070988\n",
      "{0: 42, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "-2: 4.45558422894\n",
      "{0: 40, 1: 119, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "3: 4.47177594898\n",
      "{0: 40, 1: 122, 2: 65, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "1: 4.47993737313\n",
      "{0: 40, 1: 122, 2: 66, 3: 141, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "-1: 4.44750148175\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 42, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "1: 4.4685790415\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 79, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "-5: 4.45721808731\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 166, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "-1: 4.47667752409\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 50, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "-4: 4.46692158004\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 119, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "-4: 4.47670374974\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 16, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "2: 4.46858166407\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 156, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "-1: 4.48964348843\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 91, 12: 108, 13: 132, 14: 51}\n",
      "-4: 4.46531656989\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 108, 13: 132, 14: 51}\n",
      "-4: 4.47506202368\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 132, 14: 51}\n",
      "3: 4.48800963006\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 51}\n",
      "-4: 4.48154238328\n",
      "{0: 40, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "1: 4.45716825856\n",
      "{0: 41, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "0: 4.47990327978\n",
      "{0: 41, 1: 122, 2: 66, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "5: 4.48316050626\n",
      "{0: 41, 1: 122, 2: 71, 3: 140, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "1: 4.4620986819\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 43, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "4: 4.48478649693\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 74, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "-3: 4.47506202368\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 165, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "-2: 4.4523846989\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 46, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "3: 4.46206458855\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 115, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "-4: 4.47017880652\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "0: 4.46531394733\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 155, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "-3: 4.47666703383\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 87, 12: 104, 13: 135, 14: 47}\n",
      "2: 4.4782930245\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 104, 13: 135, 14: 47}\n",
      "-4: 4.48637577169\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 135, 14: 47}\n",
      "3: 4.47019454192\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 47}\n",
      "-1: 4.46694256057\n",
      "{0: 41, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "3: 4.48475240358\n",
      "{0: 44, 1: 122, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "4: 4.46861837999\n",
      "{0: 44, 1: 126, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "0: 4.4588886616\n",
      "{0: 44, 1: 126, 2: 71, 3: 141, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "5: 4.47338358169\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 47, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "-2: 4.46370369205\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "0: 4.44430195171\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 163, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "-4: 4.46527985398\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 49, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "5: 4.47992426031\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 111, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "-5: 4.47990852491\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 18, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "-2: 4.46697665392\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 152, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "5: 4.46694256057\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 89, 12: 100, 13: 138, 14: 46}\n",
      "-5: 4.46857117381\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 138, 14: 46}\n",
      "0: 4.48314739343\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 138, 14: 46}\n",
      "4: 4.49775508384\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "0: 4.48154762841\n",
      "{0: 44, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "-4: 4.47668276922\n",
      "{0: 40, 1: 126, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "1: 4.46531656989\n",
      "{0: 40, 1: 127, 2: 71, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "-4: 4.46691633491\n",
      "{0: 40, 1: 127, 2: 67, 3: 146, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "-3: 4.46369320179\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 45, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "3: 4.46049891688\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 71, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "-4: 4.47502530776\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 159, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "-1: 4.45236634094\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 54, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "1: 4.45398446392\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 106, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "4: 4.47666441126\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 16, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "1: 4.46210130446\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 157, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "-1: 4.47505153341\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 84, 12: 100, 13: 142, 14: 46}\n",
      "-5: 4.48317624165\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 100, 13: 142, 14: 46}\n",
      "-1: 4.45721021961\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 142, 14: 46}\n",
      "2: 4.47182053259\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 46}\n",
      "-4: 4.46050416201\n",
      "{0: 40, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "-4: 4.47992163774\n",
      "{0: 36, 1: 127, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "-2: 4.4620829465\n",
      "{0: 36, 1: 125, 2: 67, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "3: 4.46534017298\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "0: 4.466939938\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 48, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "-1: 4.47180217463\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 67, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "-4: 4.48636265886\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 158, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "4: 4.46367484383\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 55, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "1: 4.46532706016\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "0: 4.48478649693\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 17, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "-1: 4.45884670055\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 156, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "-5: 4.47992950544\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 79, 12: 99, 13: 144, 14: 42}\n",
      "-2: 4.45883621029\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 99, 13: 144, 14: 42}\n",
      "-2: 4.49445589631\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 144, 14: 42}\n",
      "-2: 4.45884407798\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 42}\n",
      "1: 4.48315526113\n",
      "{0: 36, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "4: 4.48803061059\n",
      "{0: 40, 1: 125, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "-1: 4.47506726881\n",
      "{0: 40, 1: 124, 2: 70, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "-5: 4.47181528746\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "0: 4.46859215433\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "0: 4.46695042826\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 63, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "2: 4.46369844692\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 162, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "-2: 4.48314739343\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 56, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "1: 4.4442573681\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 110, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "4: 4.47180741976\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 16, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "-2: 4.49450834763\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 151, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "2: 4.46211966242\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 77, 12: 97, 13: 142, 14: 43}\n",
      "-5: 4.49608975469\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "0: 4.45236896351\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "0: 4.4717969295\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "0: 4.45886768108\n",
      "{0: 40, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "-1: 4.4815109125\n",
      "{0: 39, 1: 124, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "2: 4.47504366572\n",
      "{0: 39, 1: 126, 2: 65, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "1: 4.46856068355\n",
      "{0: 39, 1: 126, 2: 66, 3: 143, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "-1: 4.46532968272\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 47, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "3: 4.48800963006\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 65, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "-3: 4.48318148678\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 160, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "-3: 4.47183889055\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 57, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "-3: 4.48637577169\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 114, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "2: 4.47992950544\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "0: 4.48801749776\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 153, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "2: 4.4669556734\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 72, 12: 97, 13: 142, 14: 43}\n",
      "-4: 4.46046482353\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 97, 13: 142, 14: 43}\n",
      "1: 4.46696878622\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 142, 14: 43}\n",
      "-4: 4.47991377004\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 43}\n",
      "-1: 4.46855019328\n",
      "{0: 39, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "5: 4.47181791003\n",
      "{0: 44, 1: 126, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "-1: 4.4831421483\n",
      "{0: 44, 1: 125, 2: 66, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "5: 4.47017093883\n",
      "{0: 44, 1: 125, 2: 71, 3: 142, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "1: 4.48799651723\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 50, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "3: 4.46693207031\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 62, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "-3: 4.49125112115\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 157, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "1: 4.46532443759\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 54, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "-2: 4.48155025098\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 116, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "2: 4.47506202368\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 14, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "5: 4.47023650297\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 155, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "4: 4.44750934945\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 68, 12: 98, 13: 138, 14: 42}\n",
      "-2: 4.44586237825\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 98, 13: 138, 14: 42}\n",
      "2: 4.48153451559\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 138, 14: 42}\n",
      "4: 4.46530345707\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 42}\n",
      "-5: 4.46854232559\n",
      "{0: 44, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "2: 4.4653087022\n",
      "{0: 46, 1: 125, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "-3: 4.46695829596\n",
      "{0: 46, 1: 122, 2: 71, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "-2: 4.45401593471\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "0: 4.46207507881\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 53, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "3: 4.46855281585\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 59, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "-4: 4.44748312379\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 158, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "-5: 4.47015520343\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 52, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "4: 4.45398184136\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 118, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "1: 4.44912222729\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "0: 4.46534279555\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 159, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "5: 4.4815869669\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 164, 11: 66, 12: 100, 13: 142, 14: 37}\n",
      "2: 4.45559209664\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 164, 11: 68, 12: 100, 13: 142, 14: 37}\n",
      "-4: 4.47503317545\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 164, 11: 68, 12: 96, 13: 142, 14: 37}\n",
      "-5: 4.46693207031\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 164, 11: 68, 12: 96, 13: 137, 14: 37}\n",
      "-4: 4.46534279555\n",
      "{0: 46, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 164, 11: 68, 12: 96, 13: 137, 14: 33}\n",
      "-4: 4.48152402532\n",
      "{0: 42, 1: 122, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 164, 11: 68, 12: 96, 13: 137, 14: 33}\n",
      "-5: 4.47664343074\n",
      "{0: 42, 1: 117, 2: 69, 3: 143, 4: 56, 5: 55, 6: 153, 7: 56, 8: 119, 9: 19, 10: 164, 11: 68, 12: 96, 13: 137, 14: 33}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-cbd30ce2d97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mtr_cl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;31m#print tr_cl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_cl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;31m#print model.score(X_test2,y_test2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mhuh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 290\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harrisonchase/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for o in range(0,100):\n",
    "    for ind in range(0,15):\n",
    "        data=X_train\n",
    "        kf = KFold(len(data), n_folds=5, shuffle =True)\n",
    "        huh =[0]*11\n",
    "        for train_index, test_index in kf:\n",
    "            X_train2, X_test2 = data[train_index], data[test_index]\n",
    "            y_train2, y_test2 = np.array(t_train)[train_index], np.array(t_train)[test_index]\n",
    "            for j in range(-5,6):\n",
    "                tr_cl = cl.copy()\n",
    "                tr_cl[ind]+=j\n",
    "                #print tr_cl\n",
    "                model=RandomForestClassifier(n_estimators=10,max_features=1,class_weight = tr_cl).fit(X_train2,y_train2)\n",
    "                #print model.score(X_test2,y_test2)\n",
    "                huh[j+5]+=model.score(X_test2,y_test2)\n",
    "        #print huh\n",
    "        max_h = [i for i,x in enumerate(huh) if x==max(huh)][len(([i for i,x in enumerate(huh) if x==max(huh)]))-1]\n",
    "        cl[ind]+=range(-5,6)[max_h]\n",
    "        print str(range(-5,6)[max_h]) +\": \"+ str(max(huh))\n",
    "        print cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i,x in enumerate(huh) if x==max(huh)][len(([i for i,x in enumerate(huh) if x==max(huh)]))-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr=pd.DataFrame(X_train)\n",
    "X_tr[\"sum\"]=X_tr.apply(sum, axis=1).values\n",
    "X_tr=X_tr.div(X_tr[\"sum\"],axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print range(-5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847699287103\n",
      "0\n",
      "0.240740740741\n",
      "1\n",
      "0.652173913043\n",
      "2\n",
      "0.571428571429\n",
      "3\n",
      "0.705882352941\n",
      "4\n",
      "0.388888888889\n",
      "5\n",
      "0.7\n",
      "6\n",
      "0.962962962963\n",
      "7\n",
      "0.75\n",
      "8\n",
      "0.914215686275\n",
      "9\n",
      "0.416666666667\n",
      "10\n",
      "0.976923076923\n",
      "11\n",
      "0.52380952381\n",
      "12\n",
      "0.846560846561\n",
      "13\n",
      "0.148148148148\n",
      "14\n",
      "0.772727272727\n",
      "0.861309138043\n",
      "0\n",
      "0.283333333333\n",
      "1\n",
      "0.62962962963\n",
      "2\n",
      "0.5\n",
      "3\n",
      "0.733333333333\n",
      "4\n",
      "0.434782608696\n",
      "5\n",
      "0.684210526316\n",
      "6\n",
      "0.923076923077\n",
      "7\n",
      "0.8\n",
      "8\n",
      "0.930643127364\n",
      "9\n",
      "0.222222222222\n",
      "10\n",
      "0.985815602837\n",
      "11\n",
      "0.727272727273\n",
      "12\n",
      "0.871657754011\n",
      "13\n",
      "0.125\n",
      "14\n",
      "0.888888888889\n"
     ]
    }
   ],
   "source": [
    "data=X_train\n",
    "kf = KFold(len(data), n_folds=2, shuffle =True)\n",
    "for train_index, test_index in kf:\n",
    "    X_train2, X_test2 = data[train_index], data[test_index]\n",
    "    y_train2, y_test2 = np.array(t_train)[train_index], np.array(t_train)[test_index]\n",
    "    model=RandomForestClassifier(n_estimators=10,max_features=None,class_weight = cl).fit(X_train2,y_train2)\n",
    "    print model.score(X_test2,y_test2)\n",
    "    huh=model.predict(X_test2)\n",
    "    cor=[1 if x==y else 0 for x,y in zip(huh,y_test2)]\n",
    "    for i in range(0,15):\n",
    "        print i\n",
    "        print float(sum([x for x,y in zip(cor,y_test2) if y==i]))/len([x for x,y in zip(cor,y_test2) if y==i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " model=RandomForestClassifier(n_estimators=50000,max_features=1,class_weight = cl).fit(X_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03694102397926118,\n",
       " 0.016202203499675955,\n",
       " 0.011989630589760207,\n",
       " 0.010369410239792612,\n",
       " 0.013285806869734284,\n",
       " 0.012637718729747246,\n",
       " 0.017174335709656513,\n",
       " 0.013285806869734284,\n",
       " 0.5213869086195723,\n",
       " 0.006804925469863901,\n",
       " 0.17563188593648738,\n",
       " 0.010369410239792612,\n",
       " 0.1218405703175632,\n",
       " 0.01911860012961763]"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr=pd.DataFrame(X_train)\n",
    "X_tst=pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tr  = (X_train - X_train.mean()) / (X_train.max() - X_train.min())\n",
    "X_tst  = (X_test - X_train.mean()) / (X_train.max() - X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63050010477438045"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_tr.ix[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classes = [.46,.607,.569,.764,.33,.611,.923,.72,.93,.33,.999,.388,.896,.083,.736]\n",
    "cla={}\n",
    "for index,x in enumerate(wei):\n",
    "    cla[index]=1-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=X_train\n",
    "kf = KFold(len(data), n_folds=2, shuffle =True)\n",
    "for train_index, test_index in kf:\n",
    "    X_train2, X_test2 = data[train_index], data[test_index]\n",
    "    y_train2, y_test2 = np.array(t_train)[train_index], np.array(t_train)[test_index]\n",
    "    model=RandomForestClassifier(n_estimators=1000,max_features=1,class_weight=\"balanced\").fit(X_train2,y_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=model.predict(X_test2)\n",
    "preda=model.predict_proba(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb = 8\n",
    "eights =[(x,y,z) for x,y,z in zip(pred,preda,y_test2) if z ==8]\n",
    "c_eights =[(x,y,z) for x,y,z in zip(pred,preda,y_test2) if x ==8]\n",
    "mis = [(x,y,z) for x,y,z in zip(pred,preda,y_test2) if ((x ==8)|(z==8))&(x!=z)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, array([ 0.144     ,  0.011     ,  0.009     ,  0.133     ,  0.05      ,\n",
       "          0.        ,  0.        ,  0.021     ,  0.29825659,  0.008     ,\n",
       "          0.001     ,  0.065     ,  0.017     ,  0.24174341,  0.001     ]), 13),\n",
       " (8, array([ 0.058,  0.005,  0.008,  0.007,  0.023,  0.024,  0.003,  0.012,\n",
       "          0.78 ,  0.012,  0.018,  0.013,  0.032,  0.003,  0.002]), 13),\n",
       " (8, array([ 0.084     ,  0.12804751,  0.01      ,  0.001     ,  0.033     ,\n",
       "          0.019     ,  0.006     ,  0.025     ,  0.529     ,  0.005     ,\n",
       "          0.012     ,  0.004     ,  0.12595249,  0.018     ,  0.        ]), 0),\n",
       " (8, array([ 0.002     ,  0.        ,  0.001     ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.826     ,  0.02401431,\n",
       "          0.        ,  0.        ,  0.14098569,  0.005     ,  0.001     ]), 12),\n",
       " (8, array([ 0.157,  0.084,  0.038,  0.023,  0.028,  0.004,  0.002,  0.041,\n",
       "          0.449,  0.023,  0.012,  0.029,  0.101,  0.007,  0.002]), 1),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.234,  0.001,  0.001,  0.   ,  0.004,  0.   ,  0.004,  0.004,\n",
       "          0.699,  0.   ,  0.   ,  0.004,  0.032,  0.015,  0.002]), 4),\n",
       " (6, array([ 0.2       ,  0.01967003,  0.101     ,  0.06      ,  0.039     ,\n",
       "          0.044     ,  0.226     ,  0.003     ,  0.192     ,  0.        ,\n",
       "          0.012     ,  0.012     ,  0.07532997,  0.009     ,  0.007     ]), 8),\n",
       " (8, array([ 0.143,  0.046,  0.007,  0.008,  0.026,  0.009,  0.   ,  0.027,\n",
       "          0.558,  0.015,  0.014,  0.099,  0.025,  0.023,  0.   ]), 0),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.018,  0.001,  0.053,  0.009,  0.004,  0.015,  0.009,  0.003,\n",
       "          0.869,  0.001,  0.005,  0.004,  0.009,  0.   ,  0.   ]), 3),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (11, array([ 0.028,  0.002,  0.001,  0.006,  0.008,  0.004,  0.   ,  0.005,\n",
       "          0.041,  0.   ,  0.   ,  0.901,  0.001,  0.003,  0.   ]), 8),\n",
       " (12, array([ 0.012     ,  0.016     ,  0.001     ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.433     ,  0.02527156,\n",
       "          0.        ,  0.        ,  0.50272844,  0.009     ,  0.001     ]), 8),\n",
       " (8, array([ 0.10613872,  0.013     ,  0.01      ,  0.009     ,  0.04435665,\n",
       "          0.0015812 ,  0.001     ,  0.019     ,  0.30208261,  0.00767367,\n",
       "          0.004     ,  0.27013344,  0.01403371,  0.187     ,  0.011     ]), 7),\n",
       " (12, array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  0.]), 8),\n",
       " (8, array([ 0.113     ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.375     ,  0.17117633,\n",
       "          0.        ,  0.        ,  0.34082367,  0.        ,  0.        ]), 1),\n",
       " (13, array([ 0.054     ,  0.003     ,  0.013     ,  0.025     ,  0.004     ,\n",
       "          0.008     ,  0.        ,  0.137     ,  0.07403102,  0.019     ,\n",
       "          0.005     ,  0.241     ,  0.007     ,  0.40996898,  0.        ]), 8),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.023     ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.551     ,  0.19780156,\n",
       "          0.        ,  0.        ,  0.22819844,  0.        ,  0.        ]), 9),\n",
       " (8, array([ 0.047     ,  0.013     ,  0.057     ,  0.018     ,  0.009     ,\n",
       "          0.013     ,  0.        ,  0.122     ,  0.38103102,  0.01      ,\n",
       "          0.016     ,  0.036     ,  0.007     ,  0.27096898,  0.        ]), 13),\n",
       " (8, array([ 0.022     ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.428     ,  0.23290893,\n",
       "          0.        ,  0.        ,  0.30709107,  0.009     ,  0.001     ]), 9),\n",
       " (6, array([ 0.043,  0.002,  0.066,  0.006,  0.   ,  0.002,  0.808,  0.001,\n",
       "          0.045,  0.   ,  0.01 ,  0.002,  0.014,  0.001,  0.   ]), 8),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.275,  0.089,  0.007,  0.012,  0.046,  0.005,  0.   ,  0.019,\n",
       "          0.435,  0.009,  0.009,  0.047,  0.026,  0.02 ,  0.001]), 4),\n",
       " (8, array([ 0.011     ,  0.        ,  0.        ,  0.        ,  0.001     ,\n",
       "          0.001     ,  0.        ,  0.        ,  0.97503102,  0.        ,\n",
       "          0.        ,  0.        ,  0.001     ,  0.01096898,  0.        ]), 13),\n",
       " (8, array([ 0.185     ,  0.03536049,  0.048     ,  0.058     ,  0.026     ,\n",
       "          0.025     ,  0.002     ,  0.055     ,  0.282     ,  0.039     ,\n",
       "          0.07      ,  0.019     ,  0.11763951,  0.034     ,  0.004     ]), 12),\n",
       " (0, array([ 0.612,  0.013,  0.001,  0.005,  0.011,  0.   ,  0.   ,  0.003,\n",
       "          0.329,  0.   ,  0.   ,  0.016,  0.006,  0.003,  0.001]), 8),\n",
       " (8, array([ 0.208     ,  0.01065767,  0.051     ,  0.005     ,  0.019     ,\n",
       "          0.009     ,  0.001     ,  0.034     ,  0.441     ,  0.056     ,\n",
       "          0.031     ,  0.011     ,  0.11834233,  0.005     ,  0.        ]), 4),\n",
       " (8, array([ 0.039     ,  0.02387054,  0.005     ,  0.        ,  0.022     ,\n",
       "          0.002     ,  0.115     ,  0.003     ,  0.707     ,  0.002     ,\n",
       "          0.009     ,  0.003     ,  0.05212946,  0.017     ,  0.        ]), 0),\n",
       " (8, array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.008     ,\n",
       "          0.019     ,  0.        ,  0.002     ,  0.90301575,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.06698425,  0.001     ]), 4),\n",
       " (8, array([ 0.198,  0.018,  0.003,  0.048,  0.061,  0.001,  0.   ,  0.012,\n",
       "          0.535,  0.003,  0.007,  0.04 ,  0.033,  0.041,  0.   ]), 4),\n",
       " (8, array([ 0.126     ,  0.06862863,  0.026     ,  0.102     ,  0.048     ,\n",
       "          0.039     ,  0.002     ,  0.083     ,  0.273     ,  0.05      ,\n",
       "          0.089     ,  0.028     ,  0.02537137,  0.031     ,  0.009     ]), 0),\n",
       " (8, array([ 0.15066065,  0.        ,  0.04      ,  0.        ,  0.001     ,\n",
       "          0.        ,  0.        ,  0.        ,  0.76737037,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.02496898,  0.016     ]), 14),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.184     ,  0.06129758,  0.03      ,  0.01      ,  0.015     ,\n",
       "          0.036     ,  0.014     ,  0.058     ,  0.346     ,  0.027     ,\n",
       "          0.045     ,  0.023     ,  0.11470242,  0.028     ,  0.008     ]), 0),\n",
       " (8, array([ 0.20017232,  0.        ,  0.124     ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.49919569,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.17363199,  0.003     ]), 13),\n",
       " (8, array([ 0.159,  0.01 ,  0.003,  0.094,  0.13 ,  0.008,  0.   ,  0.048,\n",
       "          0.22 ,  0.014,  0.027,  0.218,  0.009,  0.059,  0.001]), 4),\n",
       " (13, array([ 0.089     ,  0.007     ,  0.016     ,  0.045     ,  0.024     ,\n",
       "          0.001     ,  0.001     ,  0.119     ,  0.21201575,  0.039     ,\n",
       "          0.005     ,  0.103     ,  0.007     ,  0.33098425,  0.001     ]), 8),\n",
       " (8, array([ 0.22      ,  0.04118144,  0.04      ,  0.009     ,  0.006     ,\n",
       "          0.019     ,  0.003     ,  0.075     ,  0.318     ,  0.063     ,\n",
       "          0.043     ,  0.023     ,  0.11181856,  0.026     ,  0.002     ]), 13),\n",
       " (8, array([ 0.011,  0.042,  0.001,  0.002,  0.007,  0.001,  0.   ,  0.014,\n",
       "          0.512,  0.336,  0.011,  0.002,  0.054,  0.007,  0.   ]), 12),\n",
       " (8, array([ 0.01 ,  0.   ,  0.   ,  0.   ,  0.   ,  0.001,  0.   ,  0.   ,\n",
       "          0.988,  0.   ,  0.   ,  0.   ,  0.001,  0.   ,  0.   ]), 4),\n",
       " (8, array([ 0.189     ,  0.02673711,  0.016     ,  0.04      ,  0.043     ,\n",
       "          0.048     ,  0.005     ,  0.03      ,  0.29      ,  0.005     ,\n",
       "          0.052     ,  0.034     ,  0.19126289,  0.024     ,  0.006     ]), 12),\n",
       " (6, array([ 0.148,  0.001,  0.137,  0.034,  0.002,  0.018,  0.297,  0.   ,\n",
       "          0.296,  0.001,  0.015,  0.006,  0.038,  0.002,  0.005]), 8),\n",
       " (8, array([ 0.101,  0.028,  0.011,  0.021,  0.053,  0.036,  0.   ,  0.08 ,\n",
       "          0.393,  0.03 ,  0.071,  0.051,  0.048,  0.077,  0.   ]), 13),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.141     ,  0.06696473,  0.01      ,  0.024     ,  0.076     ,\n",
       "          0.023     ,  0.009     ,  0.065     ,  0.431     ,  0.011     ,\n",
       "          0.038     ,  0.034     ,  0.04203527,  0.027     ,  0.002     ]), 0),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.022     ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.587     ,  0.16973643,\n",
       "          0.        ,  0.        ,  0.21526357,  0.005     ,  0.001     ]), 12),\n",
       " (8, array([ 0.122,  0.011,  0.016,  0.052,  0.043,  0.018,  0.   ,  0.072,\n",
       "          0.437,  0.019,  0.107,  0.013,  0.073,  0.015,  0.002]), 0),\n",
       " (8, array([ 0.111     ,  0.03307831,  0.03      ,  0.012     ,  0.011     ,\n",
       "          0.026     ,  0.001     ,  0.041     ,  0.346     ,  0.029     ,\n",
       "          0.227     ,  0.027     ,  0.06292169,  0.031     ,  0.012     ]), 9),\n",
       " (8, array([ 0.023     ,  0.        ,  0.        ,  0.        ,  0.001     ,\n",
       "          0.001     ,  0.        ,  0.        ,  0.886     ,  0.00491176,\n",
       "          0.        ,  0.        ,  0.01208824,  0.072     ,  0.        ]), 10),\n",
       " (8, array([ 0.114     ,  0.03602477,  0.014     ,  0.02      ,  0.025     ,\n",
       "          0.017     ,  0.027     ,  0.084     ,  0.392     ,  0.02      ,\n",
       "          0.062     ,  0.041     ,  0.09497523,  0.047     ,  0.006     ]), 0),\n",
       " (6, array([ 0.086,  0.022,  0.183,  0.163,  0.002,  0.018,  0.339,  0.   ,\n",
       "          0.136,  0.   ,  0.013,  0.01 ,  0.012,  0.002,  0.014]), 8),\n",
       " (8, array([ 0.055     ,  0.004     ,  0.03      ,  0.        ,  0.008     ,\n",
       "          0.003     ,  0.015     ,  0.005     ,  0.622     ,  0.00995588,\n",
       "          0.021     ,  0.        ,  0.09504412,  0.132     ,  0.        ]), 13),\n",
       " (8, array([ 0.191     ,  0.05594313,  0.037     ,  0.037     ,  0.027     ,\n",
       "          0.064     ,  0.035     ,  0.009     ,  0.441     ,  0.008     ,\n",
       "          0.01      ,  0.026     ,  0.05205687,  0.007     ,  0.        ]), 12),\n",
       " (10, array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "          0.,  0.]), 8),\n",
       " (8, array([ 0.121,  0.015,  0.043,  0.112,  0.134,  0.065,  0.002,  0.024,\n",
       "          0.209,  0.017,  0.072,  0.116,  0.027,  0.036,  0.007]), 5),\n",
       " (8, array([ 0.172,  0.078,  0.017,  0.008,  0.021,  0.006,  0.002,  0.05 ,\n",
       "          0.482,  0.029,  0.009,  0.014,  0.105,  0.007,  0.   ]), 12),\n",
       " (8, array([ 0.275,  0.084,  0.007,  0.012,  0.043,  0.005,  0.   ,  0.022,\n",
       "          0.44 ,  0.008,  0.008,  0.047,  0.027,  0.021,  0.001]), 4),\n",
       " (8, array([ 0.216     ,  0.01284856,  0.061     ,  0.125     ,  0.037     ,\n",
       "          0.078     ,  0.        ,  0.069     ,  0.263     ,  0.012     ,\n",
       "          0.034     ,  0.039     ,  0.02815144,  0.02      ,  0.005     ]), 2),\n",
       " (13, array([ 0.06883271,  0.        ,  0.092     ,  0.        ,  0.004     ,\n",
       "          0.        ,  0.        ,  0.001     ,  0.2943983 ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.53776899,  0.002     ]), 8),\n",
       " (8, array([ 0.03868091,  0.        ,  0.        ,  0.006     ,  0.055     ,\n",
       "          0.014     ,  0.        ,  0.008     ,  0.4383035 ,  0.008     ,\n",
       "          0.        ,  0.002     ,  0.008     ,  0.42001559,  0.002     ]), 13),\n",
       " (0, array([ 0.3543158 ,  0.        ,  0.        ,  0.        ,  0.00620258,\n",
       "          0.00603103,  0.        ,  0.        ,  0.31289442,  0.01182043,\n",
       "          0.        ,  0.02614154,  0.00159419,  0.241     ,  0.04      ]), 8),\n",
       " (8, array([  3.52173796e-01,   0.00000000e+00,   7.80000000e-02,\n",
       "           0.00000000e+00,   0.00000000e+00,   1.55267691e-04,\n",
       "           0.00000000e+00,   0.00000000e+00,   4.95230720e-01,\n",
       "           0.00000000e+00,   0.00000000e+00,   6.70756423e-04,\n",
       "           2.86648044e-05,   7.27407954e-02,   1.00000000e-03]), 13),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.081     ,  0.02069149,  0.014     ,  0.007     ,  0.018     ,\n",
       "          0.01      ,  0.001     ,  0.042     ,  0.523     ,  0.005     ,\n",
       "          0.001     ,  0.244     ,  0.02330851,  0.009     ,  0.001     ]), 11),\n",
       " (9, array([ 0.086     ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.228     ,  0.42613136,\n",
       "          0.        ,  0.        ,  0.24986864,  0.01      ,  0.        ]), 8),\n",
       " (8, array([ 0.166     ,  0.03345667,  0.05      ,  0.12      ,  0.067     ,\n",
       "          0.048     ,  0.035     ,  0.024     ,  0.168     ,  0.006     ,\n",
       "          0.074     ,  0.154     ,  0.02354333,  0.013     ,  0.018     ]), 11),\n",
       " (8, array([ 0.087     ,  0.        ,  0.001     ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.373     ,  0.34641717,\n",
       "          0.        ,  0.        ,  0.17658283,  0.016     ,  0.        ]), 12),\n",
       " (8, array([ 0.244,  0.025,  0.085,  0.006,  0.014,  0.075,  0.161,  0.001,\n",
       "          0.269,  0.001,  0.027,  0.021,  0.047,  0.005,  0.019]), 0),\n",
       " (8, array([ 0.022     ,  0.018     ,  0.001     ,  0.        ,  0.002     ,\n",
       "          0.        ,  0.        ,  0.        ,  0.685     ,  0.01398485,\n",
       "          0.004     ,  0.001     ,  0.22801515,  0.025     ,  0.        ]), 13),\n",
       " (8, array([ 0.13      ,  0.009     ,  0.002     ,  0.013     ,  0.02      ,\n",
       "          0.009     ,  0.001     ,  0.087     ,  0.37640692,  0.005     ,\n",
       "          0.013     ,  0.125     ,  0.017     ,  0.19259308,  0.        ]), 0),\n",
       " (8, array([ 0.25      ,  0.00777075,  0.047     ,  0.001     ,  0.007     ,\n",
       "          0.022     ,  0.002     ,  0.051     ,  0.352     ,  0.077     ,\n",
       "          0.023     ,  0.012     ,  0.14422925,  0.004     ,  0.        ]), 0),\n",
       " (8, array([ 0.134     ,  0.00665767,  0.08      ,  0.037     ,  0.064     ,\n",
       "          0.035     ,  0.017     ,  0.038     ,  0.401     ,  0.009     ,\n",
       "          0.065     ,  0.015     ,  0.08134233,  0.009     ,  0.008     ]), 0),\n",
       " (8, array([ 0.049,  0.001,  0.001,  0.   ,  0.008,  0.   ,  0.   ,  0.   ,\n",
       "          0.746,  0.001,  0.003,  0.   ,  0.005,  0.186,  0.   ]), 13),\n",
       " (8, array([ 0.065,  0.097,  0.015,  0.018,  0.024,  0.054,  0.   ,  0.021,\n",
       "          0.266,  0.072,  0.212,  0.078,  0.023,  0.05 ,  0.005]), 9),\n",
       " (8, array([  7.19699427e-05,   0.00000000e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   1.33243898e-01,\n",
       "           0.00000000e+00,   0.00000000e+00,   8.03026232e-01,\n",
       "           6.50395038e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "           7.50455813e-06,   5.50000000e-02,   8.00000000e-03]), 14),\n",
       " (8, array([ 0.116,  0.168,  0.002,  0.02 ,  0.009,  0.003,  0.   ,  0.   ,\n",
       "          0.306,  0.04 ,  0.031,  0.036,  0.263,  0.006,  0.   ]), 12),\n",
       " (8, array([ 0.073,  0.047,  0.006,  0.001,  0.032,  0.003,  0.008,  0.015,\n",
       "          0.72 ,  0.02 ,  0.008,  0.006,  0.06 ,  0.001,  0.   ]), 0),\n",
       " (8, array([ 0.101,  0.008,  0.024,  0.013,  0.032,  0.058,  0.   ,  0.105,\n",
       "          0.314,  0.004,  0.248,  0.019,  0.036,  0.037,  0.001]), 12),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.01477258,  0.        ,  0.        ,  0.        ,  0.105     ,\n",
       "          0.024     ,  0.        ,  0.001     ,  0.63063383,  0.        ,\n",
       "          0.        ,  0.        ,  0.003     ,  0.21859359,  0.003     ]), 13),\n",
       " (11, array([ 0.204,  0.006,  0.009,  0.016,  0.157,  0.016,  0.   ,  0.031,\n",
       "          0.17 ,  0.019,  0.039,  0.277,  0.015,  0.04 ,  0.001]), 8),\n",
       " (8, array([ 0.04592755,  0.004     ,  0.081     ,  0.025     ,  0.003     ,\n",
       "          0.001     ,  0.        ,  0.001     ,  0.58714837,  0.002     ,\n",
       "          0.        ,  0.        ,  0.004     ,  0.20192408,  0.044     ]), 13),\n",
       " (8, array([ 0.19      ,  0.03483452,  0.023     ,  0.012     ,  0.016     ,\n",
       "          0.025     ,  0.002     ,  0.051     ,  0.415     ,  0.014     ,\n",
       "          0.044     ,  0.023     ,  0.11316548,  0.036     ,  0.001     ]), 12),\n",
       " (8, array([ 0.106,  0.008,  0.109,  0.129,  0.007,  0.078,  0.013,  0.002,\n",
       "          0.435,  0.001,  0.054,  0.018,  0.026,  0.006,  0.008]), 5),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.084,  0.055,  0.011,  0.02 ,  0.026,  0.074,  0.   ,  0.017,\n",
       "          0.462,  0.045,  0.082,  0.07 ,  0.022,  0.028,  0.004]), 9),\n",
       " (8, array([ 0.261     ,  0.001     ,  0.        ,  0.        ,  0.004     ,\n",
       "          0.004     ,  0.        ,  0.004     ,  0.45239121,  0.        ,\n",
       "          0.        ,  0.        ,  0.036     ,  0.23760879,  0.        ]), 13),\n",
       " (8, array([ 0.153,  0.004,  0.014,  0.003,  0.029,  0.002,  0.004,  0.042,\n",
       "          0.479,  0.001,  0.015,  0.053,  0.045,  0.154,  0.002]), 2),\n",
       " (8, array([ 0.08 ,  0.001,  0.01 ,  0.   ,  0.055,  0.002,  0.   ,  0.005,\n",
       "          0.681,  0.004,  0.05 ,  0.004,  0.073,  0.032,  0.003]), 13),\n",
       " (5, array([ 0.122     ,  0.07525675,  0.004     ,  0.024     ,  0.041     ,\n",
       "          0.304     ,  0.003     ,  0.024     ,  0.139     ,  0.036     ,\n",
       "          0.075     ,  0.015     ,  0.07074325,  0.05      ,  0.017     ]), 8),\n",
       " (8, array([  1.53875267e-01,   0.00000000e+00,   2.20000000e-01,\n",
       "           0.00000000e+00,   3.13564998e-03,   1.28113872e-04,\n",
       "           0.00000000e+00,   1.00000000e-03,   2.66235773e-01,\n",
       "           2.56227745e-04,   0.00000000e+00,   1.33689680e-02,\n",
       "           3.00000000e-03,   2.00000000e-01,   1.39000000e-01]), 13),\n",
       " (8, array([ 0.115,  0.015,  0.011,  0.003,  0.081,  0.003,  0.   ,  0.018,\n",
       "          0.438,  0.001,  0.003,  0.067,  0.024,  0.219,  0.002]), 4),\n",
       " (8, array([ 0.105     ,  0.06736049,  0.016     ,  0.019     ,  0.047     ,\n",
       "          0.079     ,  0.        ,  0.027     ,  0.329     ,  0.044     ,\n",
       "          0.14      ,  0.057     ,  0.02963951,  0.036     ,  0.004     ]), 0),\n",
       " (8, array([ 0.067     ,  0.003     ,  0.007     ,  0.        ,  0.001     ,\n",
       "          0.002     ,  0.002     ,  0.        ,  0.791     ,  0.02796769,\n",
       "          0.005     ,  0.        ,  0.03303231,  0.061     ,  0.        ]), 13),\n",
       " (8, array([ 0.219,  0.024,  0.011,  0.023,  0.014,  0.001,  0.   ,  0.001,\n",
       "          0.55 ,  0.008,  0.006,  0.006,  0.046,  0.09 ,  0.001]), 4),\n",
       " (0, array([ 0.694,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "          0.295,  0.   ,  0.   ,  0.   ,  0.002,  0.009,  0.   ]), 8),\n",
       " (8, array([ 0.085     ,  0.01769149,  0.008     ,  0.007     ,  0.02      ,\n",
       "          0.008     ,  0.001     ,  0.054     ,  0.543     ,  0.01      ,\n",
       "          0.003     ,  0.212     ,  0.02330851,  0.007     ,  0.001     ]), 11),\n",
       " (8, array([ 0.06 ,  0.073,  0.01 ,  0.001,  0.049,  0.002,  0.002,  0.016,\n",
       "          0.552,  0.052,  0.016,  0.005,  0.149,  0.013,  0.   ]), 12),\n",
       " (8, array([ 0.038,  0.02 ,  0.011,  0.001,  0.008,  0.002,  0.057,  0.001,\n",
       "          0.77 ,  0.001,  0.02 ,  0.003,  0.039,  0.029,  0.   ]), 6),\n",
       " (0, array([  5.57110114e-01,   0.00000000e+00,   1.00000000e-03,\n",
       "           0.00000000e+00,   3.40633269e-04,   1.55267691e-04,\n",
       "           0.00000000e+00,   0.00000000e+00,   4.26146176e-01,\n",
       "           2.14472799e-04,   0.00000000e+00,   1.05680746e-03,\n",
       "           3.85635490e-05,   1.39379653e-02,   0.00000000e+00]), 8),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (12, array([ 0.183,  0.015,  0.02 ,  0.007,  0.055,  0.01 ,  0.007,  0.018,\n",
       "          0.288,  0.003,  0.023,  0.004,  0.332,  0.032,  0.003]), 8),\n",
       " (8, array([ 0.144     ,  0.08974063,  0.021     ,  0.032     ,  0.044     ,\n",
       "          0.054     ,  0.015     ,  0.02      ,  0.267     ,  0.017     ,\n",
       "          0.104     ,  0.04      ,  0.11825937,  0.017     ,  0.017     ]), 12),\n",
       " (8, array([ 0.198     ,  0.02945902,  0.137     ,  0.058     ,  0.007     ,\n",
       "          0.042     ,  0.036     ,  0.002     ,  0.244     ,  0.025     ,\n",
       "          0.066     ,  0.01      ,  0.12654098,  0.011     ,  0.008     ]), 0),\n",
       " (13, array([ 0.06183876,  0.        ,  0.029     ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.23486136,  0.        ,\n",
       "          0.        ,  0.001     ,  0.        ,  0.61829988,  0.055     ]), 8),\n",
       " (8, array([ 0.089,  0.039,  0.008,  0.154,  0.068,  0.014,  0.   ,  0.049,\n",
       "          0.351,  0.013,  0.024,  0.03 ,  0.131,  0.03 ,  0.   ]), 0),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.005,  0.   ,  0.008,  0.   ,  0.001,  0.   ,  0.   ,  0.   ,\n",
       "          0.926,  0.   ,  0.002,  0.   ,  0.   ,  0.058,  0.   ]), 13),\n",
       " (8, array([ 0.181     ,  0.01059116,  0.035     ,  0.082     ,  0.026     ,\n",
       "          0.034     ,  0.001     ,  0.005     ,  0.408     ,  0.009     ,\n",
       "          0.071     ,  0.006     ,  0.12640884,  0.005     ,  0.        ]), 12),\n",
       " (8, array([ 0.138,  0.008,  0.005,  0.02 ,  0.024,  0.016,  0.   ,  0.04 ,\n",
       "          0.352,  0.011,  0.273,  0.016,  0.071,  0.025,  0.001]), 0),\n",
       " (8, array([ 0.042,  0.016,  0.013,  0.01 ,  0.013,  0.017,  0.002,  0.057,\n",
       "          0.663,  0.01 ,  0.023,  0.009,  0.101,  0.024,  0.   ]), 13),\n",
       " (8, array([ 0.126     ,  0.002     ,  0.        ,  0.        ,  0.019     ,\n",
       "          0.002     ,  0.        ,  0.004     ,  0.54703102,  0.        ,\n",
       "          0.        ,  0.001     ,  0.027     ,  0.27196898,  0.        ]), 13),\n",
       " (8, array([ 0.055,  0.014,  0.023,  0.011,  0.023,  0.002,  0.001,  0.042,\n",
       "          0.653,  0.045,  0.027,  0.018,  0.049,  0.036,  0.001]), 13),\n",
       " (0, array([ 0.211,  0.044,  0.116,  0.022,  0.014,  0.048,  0.092,  0.001,\n",
       "          0.166,  0.004,  0.1  ,  0.019,  0.094,  0.011,  0.058]), 8),\n",
       " (8, array([ 0.138     ,  0.07062701,  0.022     ,  0.003     ,  0.03      ,\n",
       "          0.006     ,  0.002     ,  0.108     ,  0.511     ,  0.01      ,\n",
       "          0.02      ,  0.038     ,  0.03537299,  0.006     ,  0.        ]), 3),\n",
       " (8, array([ 0.077     ,  0.05308368,  0.013     ,  0.007     ,  0.053     ,\n",
       "          0.011     ,  0.008     ,  0.012     ,  0.545     ,  0.019     ,\n",
       "          0.03      ,  0.004     ,  0.11791632,  0.05      ,  0.        ]), 13),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.437,  0.013,  0.002,  0.005,  0.01 ,  0.   ,  0.   ,  0.003,\n",
       "          0.505,  0.   ,  0.   ,  0.016,  0.005,  0.003,  0.001]), 0),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.158    ,  0.0289319,  0.03     ,  0.027    ,  0.079    ,\n",
       "          0.041    ,  0.001    ,  0.032    ,  0.375    ,  0.029    ,\n",
       "          0.072    ,  0.027    ,  0.0960681,  0.004    ,  0.       ]), 12),\n",
       " (8, array([ 0.197     ,  0.04746853,  0.052     ,  0.014     ,  0.047     ,\n",
       "          0.031     ,  0.004     ,  0.025     ,  0.322     ,  0.065     ,\n",
       "          0.053     ,  0.021     ,  0.10353147,  0.018     ,  0.        ]), 12),\n",
       " (8, array([ 0.194,  0.128,  0.002,  0.004,  0.005,  0.   ,  0.001,  0.003,\n",
       "          0.57 ,  0.012,  0.004,  0.   ,  0.052,  0.025,  0.   ]), 12),\n",
       " (8, array([ 0.24      ,  0.03489965,  0.057     ,  0.012     ,  0.023     ,\n",
       "          0.12      ,  0.        ,  0.05      ,  0.353     ,  0.017     ,\n",
       "          0.01      ,  0.009     ,  0.06810035,  0.006     ,  0.        ]), 5),\n",
       " (8, array([ 0.153     ,  0.02347528,  0.02      ,  0.03      ,  0.047     ,\n",
       "          0.028     ,  0.002     ,  0.058     ,  0.45      ,  0.017     ,\n",
       "          0.077     ,  0.01      ,  0.06352472,  0.019     ,  0.002     ]), 13),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (13, array([ 0.06183876,  0.        ,  0.029     ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.23486136,  0.        ,\n",
       "          0.        ,  0.001     ,  0.        ,  0.61829988,  0.055     ]), 8),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (8, array([ 0.103,  0.008,  0.108,  0.13 ,  0.008,  0.081,  0.013,  0.003,\n",
       "          0.432,  0.001,  0.054,  0.019,  0.026,  0.006,  0.008]), 5),\n",
       " (0, array([ 0.65852328,  0.005     ,  0.        ,  0.003     ,  0.00722236,\n",
       "          0.00528618,  0.007     ,  0.006     ,  0.19814163,  0.00564233,\n",
       "          0.001     ,  0.02205004,  0.01313419,  0.061     ,  0.007     ]), 8),\n",
       " (11, array([ 0.0446264 ,  0.        ,  0.        ,  0.        ,  0.14087175,\n",
       "          0.12972988,  0.        ,  0.        ,  0.04279638,  0.2206147 ,\n",
       "          0.        ,  0.4075913 ,  0.0137696 ,  0.        ,  0.        ]), 8),\n",
       " (12, array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  0.]), 8),\n",
       " (0, array([ 0.242,  0.023,  0.018,  0.033,  0.045,  0.028,  0.001,  0.112,\n",
       "          0.192,  0.016,  0.155,  0.034,  0.062,  0.03 ,  0.009]), 8),\n",
       " (8, array([ 0.047     ,  0.027     ,  0.001     ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.505     ,  0.01366152,\n",
       "          0.        ,  0.        ,  0.37933848,  0.026     ,  0.001     ]), 12),\n",
       " (8, array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.576     ,  0.00388921,\n",
       "          0.        ,  0.        ,  0.15811079,  0.262     ,  0.        ]), 12)]"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
